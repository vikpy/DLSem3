{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 6 hyper-parameter tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6x6KLDuTE4/0nLzShO7O2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikpy/DLSem3/blob/master/Assignment_6_hyper_parameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILkrczRTKHOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "fc792b76-0e99-4ca0-e084-a18ef3e75960"
      },
      "source": [
        "!pip install pyforest \n",
        "from pyforest import * "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyforest\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/85/77a9d2d9ff240822039f3dfd7a3b374d0621a0df5feb5d270a2151f6bb6d/pyforest-1.0.3.tar.gz\n",
            "Building wheels for collected packages: pyforest\n",
            "  Building wheel for pyforest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyforest: filename=pyforest-1.0.3-py2.py3-none-any.whl size=13716 sha256=a26d1ed14d166b9cc7a6571dd60dec563d2189b351774b7fc0bd0c497356da85\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/0b/39/340a7f15fc8d4ff5ab50847b28789afea04452a9d51b9721b5\n",
            "Successfully built pyforest\n",
            "Installing collected packages: pyforest\n",
            "Successfully installed pyforest-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUcZ2dCAB1z4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Some methods of hyperparameter tuning:\n",
        "\n",
        "1.Batch size\n",
        "\n",
        "2.Learning rate decay\n",
        "\n",
        "3.Batch norm\n",
        "\n",
        "4.Adam, RMSProp, Momentum\n",
        "\n",
        "5.Normalize features\n",
        "\n",
        "6.Use L1, L2 regularization, Dropout, Data augmentation, Early stopping\n",
        "\n",
        "\n",
        "#Assignment 6: \n",
        "\n",
        "Use __Concepts 1-6__ to improve accuracy on CIFAR100 to +90%\n",
        "\n",
        "Ans:\n",
        "\n",
        "References:\n",
        "1. https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n",
        "2. https://docs.google.com/document/d/18JYvbD4L5NhQ8RYSq1xbLVL0bTISk8-0PYF8L3QQ7SY/edit\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_uHixZvGFG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar100\n",
        "from keras.models import Sequential                         \n",
        "from keras.layers import Dense, Dropout, Activation, Flatten,Conv2D,MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from matplotlib import pyplot\n",
        "\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar100.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN7fhxLMI2VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Dense(100, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\t\n",
        "\treturn model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5seqovBJ9kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jozKbsMKS-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# fit model\n",
        "\thistory = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_-xBKc4K-P_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b40bd2cf-d2a9-4450-ef95-2342f5bc9960"
      },
      "source": [
        "run_test_harness()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 11s 0us/step\n",
            "Epoch 1/100\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 4.6016 - accuracy: 0.0144 - val_loss: 4.5607 - val_accuracy: 0.0282\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 4.4474 - accuracy: 0.0313 - val_loss: 4.3038 - val_accuracy: 0.0573\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 4.2439 - accuracy: 0.0525 - val_loss: 4.1046 - val_accuracy: 0.0865\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 4.0652 - accuracy: 0.0773 - val_loss: 3.9426 - val_accuracy: 0.1183\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.9116 - accuracy: 0.1011 - val_loss: 3.7449 - val_accuracy: 0.1491\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.7665 - accuracy: 0.1218 - val_loss: 3.6269 - val_accuracy: 0.1646\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.6543 - accuracy: 0.1392 - val_loss: 3.4656 - val_accuracy: 0.1883\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.5626 - accuracy: 0.1553 - val_loss: 3.3854 - val_accuracy: 0.2078\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.4691 - accuracy: 0.1712 - val_loss: 3.3444 - val_accuracy: 0.2149\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.3835 - accuracy: 0.1844 - val_loss: 3.2081 - val_accuracy: 0.2344\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.3144 - accuracy: 0.1980 - val_loss: 3.1947 - val_accuracy: 0.2364\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.2486 - accuracy: 0.2083 - val_loss: 3.1090 - val_accuracy: 0.2506\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.1798 - accuracy: 0.2233 - val_loss: 2.9967 - val_accuracy: 0.2715\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.1101 - accuracy: 0.2346 - val_loss: 2.9168 - val_accuracy: 0.2828\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.0462 - accuracy: 0.2494 - val_loss: 2.8911 - val_accuracy: 0.2869\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.9958 - accuracy: 0.2561 - val_loss: 2.8526 - val_accuracy: 0.2965\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.9344 - accuracy: 0.2685 - val_loss: 2.7556 - val_accuracy: 0.3145\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.8765 - accuracy: 0.2784 - val_loss: 2.7104 - val_accuracy: 0.3211\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.8157 - accuracy: 0.2903 - val_loss: 2.6909 - val_accuracy: 0.3249\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.7612 - accuracy: 0.3004 - val_loss: 2.5957 - val_accuracy: 0.3374\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.7098 - accuracy: 0.3122 - val_loss: 2.5689 - val_accuracy: 0.3464\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.6600 - accuracy: 0.3220 - val_loss: 2.4888 - val_accuracy: 0.3667\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.6071 - accuracy: 0.3321 - val_loss: 2.4967 - val_accuracy: 0.3581\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.5720 - accuracy: 0.3380 - val_loss: 2.4181 - val_accuracy: 0.3737\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.5196 - accuracy: 0.3511 - val_loss: 2.3973 - val_accuracy: 0.3844\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.4850 - accuracy: 0.3545 - val_loss: 2.3605 - val_accuracy: 0.3900\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.4495 - accuracy: 0.3655 - val_loss: 2.3367 - val_accuracy: 0.3896\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.4131 - accuracy: 0.3741 - val_loss: 2.2780 - val_accuracy: 0.4046\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.3705 - accuracy: 0.3802 - val_loss: 2.2473 - val_accuracy: 0.4133\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.3470 - accuracy: 0.3892 - val_loss: 2.2079 - val_accuracy: 0.4205\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.3099 - accuracy: 0.3940 - val_loss: 2.1914 - val_accuracy: 0.4298\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.2820 - accuracy: 0.4023 - val_loss: 2.2514 - val_accuracy: 0.4133\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.2522 - accuracy: 0.4043 - val_loss: 2.1850 - val_accuracy: 0.4252\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.2192 - accuracy: 0.4126 - val_loss: 2.1374 - val_accuracy: 0.4355\n",
            "Epoch 35/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.1911 - accuracy: 0.4194 - val_loss: 2.1089 - val_accuracy: 0.4419\n",
            "Epoch 36/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.1677 - accuracy: 0.4242 - val_loss: 2.1557 - val_accuracy: 0.4336\n",
            "Epoch 37/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.1414 - accuracy: 0.4301 - val_loss: 2.0939 - val_accuracy: 0.4456\n",
            "Epoch 38/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.1166 - accuracy: 0.4345 - val_loss: 2.0684 - val_accuracy: 0.4540\n",
            "Epoch 39/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.0885 - accuracy: 0.4385 - val_loss: 2.1203 - val_accuracy: 0.4401\n",
            "Epoch 40/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.0690 - accuracy: 0.4416 - val_loss: 2.0435 - val_accuracy: 0.4579\n",
            "Epoch 41/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.0482 - accuracy: 0.4491 - val_loss: 2.0600 - val_accuracy: 0.4531\n",
            "Epoch 42/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.0184 - accuracy: 0.4527 - val_loss: 2.0209 - val_accuracy: 0.4644\n",
            "Epoch 43/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.0041 - accuracy: 0.4577 - val_loss: 2.0190 - val_accuracy: 0.4654\n",
            "Epoch 44/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.9773 - accuracy: 0.4653 - val_loss: 1.9850 - val_accuracy: 0.4657\n",
            "Epoch 45/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.9537 - accuracy: 0.4687 - val_loss: 1.9787 - val_accuracy: 0.4708\n",
            "Epoch 46/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.9251 - accuracy: 0.4752 - val_loss: 1.9759 - val_accuracy: 0.4732\n",
            "Epoch 47/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.9052 - accuracy: 0.4790 - val_loss: 1.9572 - val_accuracy: 0.4745\n",
            "Epoch 48/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.8891 - accuracy: 0.4822 - val_loss: 1.9658 - val_accuracy: 0.4694\n",
            "Epoch 49/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.8736 - accuracy: 0.4874 - val_loss: 1.9504 - val_accuracy: 0.4786\n",
            "Epoch 50/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.8539 - accuracy: 0.4913 - val_loss: 1.9790 - val_accuracy: 0.4745\n",
            "Epoch 51/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.8345 - accuracy: 0.4951 - val_loss: 1.9522 - val_accuracy: 0.4781\n",
            "Epoch 52/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.8144 - accuracy: 0.4987 - val_loss: 1.9736 - val_accuracy: 0.4740\n",
            "Epoch 53/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.7953 - accuracy: 0.5050 - val_loss: 1.9215 - val_accuracy: 0.4874\n",
            "Epoch 54/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.7735 - accuracy: 0.5107 - val_loss: 1.9955 - val_accuracy: 0.4734\n",
            "Epoch 55/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.7702 - accuracy: 0.5098 - val_loss: 1.9314 - val_accuracy: 0.4832\n",
            "Epoch 56/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.7434 - accuracy: 0.5168 - val_loss: 1.9278 - val_accuracy: 0.4855\n",
            "Epoch 57/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.7261 - accuracy: 0.5200 - val_loss: 1.9192 - val_accuracy: 0.4905\n",
            "Epoch 58/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.7108 - accuracy: 0.5225 - val_loss: 1.8889 - val_accuracy: 0.4946\n",
            "Epoch 59/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.6879 - accuracy: 0.5288 - val_loss: 1.8823 - val_accuracy: 0.4970\n",
            "Epoch 60/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.6712 - accuracy: 0.5359 - val_loss: 1.9078 - val_accuracy: 0.4919\n",
            "Epoch 61/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.6614 - accuracy: 0.5345 - val_loss: 1.8695 - val_accuracy: 0.5011\n",
            "Epoch 62/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.6494 - accuracy: 0.5372 - val_loss: 1.8627 - val_accuracy: 0.5011\n",
            "Epoch 63/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.6275 - accuracy: 0.5430 - val_loss: 1.8654 - val_accuracy: 0.4983\n",
            "Epoch 64/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.6019 - accuracy: 0.5455 - val_loss: 1.8779 - val_accuracy: 0.4986\n",
            "Epoch 65/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.6023 - accuracy: 0.5485 - val_loss: 1.8590 - val_accuracy: 0.5080\n",
            "Epoch 66/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.5913 - accuracy: 0.5504 - val_loss: 1.8543 - val_accuracy: 0.5094\n",
            "Epoch 67/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.5617 - accuracy: 0.5568 - val_loss: 1.8509 - val_accuracy: 0.5047\n",
            "Epoch 68/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.5464 - accuracy: 0.5596 - val_loss: 1.8507 - val_accuracy: 0.5103\n",
            "Epoch 69/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.5361 - accuracy: 0.5642 - val_loss: 1.8565 - val_accuracy: 0.5153\n",
            "Epoch 70/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.5205 - accuracy: 0.5678 - val_loss: 1.8431 - val_accuracy: 0.5114\n",
            "Epoch 71/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.5090 - accuracy: 0.5700 - val_loss: 1.8839 - val_accuracy: 0.5106\n",
            "Epoch 72/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.4997 - accuracy: 0.5735 - val_loss: 1.8405 - val_accuracy: 0.5136\n",
            "Epoch 73/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.4790 - accuracy: 0.5757 - val_loss: 1.8477 - val_accuracy: 0.5108\n",
            "Epoch 74/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.4755 - accuracy: 0.5761 - val_loss: 1.8579 - val_accuracy: 0.5099\n",
            "Epoch 75/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.4600 - accuracy: 0.5809 - val_loss: 1.8636 - val_accuracy: 0.5112\n",
            "Epoch 76/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.4460 - accuracy: 0.5838 - val_loss: 1.8737 - val_accuracy: 0.5111\n",
            "Epoch 77/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.4302 - accuracy: 0.5879 - val_loss: 1.8436 - val_accuracy: 0.5109\n",
            "Epoch 78/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.4176 - accuracy: 0.5917 - val_loss: 1.8724 - val_accuracy: 0.5089\n",
            "Epoch 79/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.4067 - accuracy: 0.5933 - val_loss: 1.8562 - val_accuracy: 0.5122\n",
            "Epoch 80/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.3945 - accuracy: 0.5955 - val_loss: 1.8334 - val_accuracy: 0.5141\n",
            "Epoch 81/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.3871 - accuracy: 0.5965 - val_loss: 1.8604 - val_accuracy: 0.5169\n",
            "Epoch 82/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.3703 - accuracy: 0.6016 - val_loss: 1.8650 - val_accuracy: 0.5210\n",
            "Epoch 83/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.3674 - accuracy: 0.6034 - val_loss: 1.8625 - val_accuracy: 0.5157\n",
            "Epoch 84/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.3559 - accuracy: 0.6045 - val_loss: 1.8833 - val_accuracy: 0.5140\n",
            "Epoch 85/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.3386 - accuracy: 0.6109 - val_loss: 1.8733 - val_accuracy: 0.5154\n",
            "Epoch 86/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.3327 - accuracy: 0.6099 - val_loss: 1.8784 - val_accuracy: 0.5157\n",
            "Epoch 87/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.3122 - accuracy: 0.6165 - val_loss: 1.9021 - val_accuracy: 0.5074\n",
            "Epoch 88/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.3108 - accuracy: 0.6172 - val_loss: 1.8569 - val_accuracy: 0.5177\n",
            "Epoch 89/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.2944 - accuracy: 0.6201 - val_loss: 1.8783 - val_accuracy: 0.5153\n",
            "Epoch 90/100\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.2843 - accuracy: 0.6235 - val_loss: 1.8663 - val_accuracy: 0.5180\n",
            "Epoch 91/100\n",
            "392/782 [==============>...............] - ETA: 6s - loss: 1.2657 - accuracy: 0.6248"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}