{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classwork Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNClnV8Vm3A2iLncODbm0Fh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikpy/DLSem3/blob/master/Classwork_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEogK-u8P2Tu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "118f1472-6486-45fb-aed6-07e607939a0e"
      },
      "source": [
        "# Sigmoid Function \n",
        "import numpy as np\n",
        "\n",
        "x = np.array([1, -1, 0.001])\n",
        "s = 1/(1 + np.exp(-x))\n",
        "s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.73105858, 0.26894142, 0.50025   ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRuLGdnzXnaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "df61d455-591d-444e-dc90-90e6bb529ce4"
      },
      "source": [
        "image = np.array([\n",
        "                  [\n",
        "                   [1,1,1],\n",
        "                   [1,1, 1],\n",
        "                   [1,1, 1]\n",
        "\n",
        "                  ],\n",
        "                  [\n",
        "                   [1,1, 1],\n",
        "                   [1,1, 1],\n",
        "                   [1,1, 1]\n",
        "\n",
        "                  ],\n",
        "                  [\n",
        "                   [1,1, 1],\n",
        "                   [1,1, 1],\n",
        "                   [1,1, 1]\n",
        "\n",
        "                  ],\n",
        "])\n",
        "image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 1, 1],\n",
              "        [1, 1, 1],\n",
              "        [1, 1, 1]],\n",
              "\n",
              "       [[1, 1, 1],\n",
              "        [1, 1, 1],\n",
              "        [1, 1, 1]],\n",
              "\n",
              "       [[1, 1, 1],\n",
              "        [1, 1, 1],\n",
              "        [1, 1, 1]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqpgRGUNYLXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v = image.reshape(image.shape[0]*image.shape[1]*image.shape[2], 1)\n",
        "v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G88yT7d1k_TY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.random.random((1000, 10))\n",
        "label = np.random.randint(2, size=(1000,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4waH2s9KlRsw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a056c7f8-ec37-465c-b716-e5a45a0ab8aa"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nda--ap8hRBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#First neural network building blocks\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "\n",
        "model = Sequential()\n",
        "#creation of first hidden layer with 10 nodes and sigmoid activation \n",
        "# Z[1] = W[1]X + b\n",
        "# A[1] = sigmoid(Z[1])\n",
        "model.add(Dense(units=10, activation='sigmoid', input_dim=10))\n",
        "#creation of hidden layer with 3 nodes and sigmoid activation\n",
        "#Z[2] = W[2]A[1] + b[2]\n",
        "#yhat = A[2] = sigmoid(Z[2])\n",
        "model.add(Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMFGXBU5kNI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLRJTNKJkV8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "8b1bff89-eda5-4653-d288-0c02ac014431"
      },
      "source": [
        "# X is data, y=label, epoch is iterations over the data \n",
        "model.fit(data, label, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 0s 323us/step - loss: 0.7185 - accuracy: 0.5070\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.7073 - accuracy: 0.5070\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.7011 - accuracy: 0.5080\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 42us/step - loss: 0.6979 - accuracy: 0.5110\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.6958 - accuracy: 0.5150\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.6948 - accuracy: 0.5140\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.6940 - accuracy: 0.5080\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 34us/step - loss: 0.6937 - accuracy: 0.5120\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.6936 - accuracy: 0.5150\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 33us/step - loss: 0.6935 - accuracy: 0.5140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f2cd1519da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg18WOZPmcRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "f2032ba6-3af2-43e8-80c2-e57264150ab3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVz4GAc3mf8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "4c18ac73-37c0-4556-d45c-27b42fef2c34"
      },
      "source": [
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG  \n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"255pt\" viewBox=\"0.00 0.00 181.00 191.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 187)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-187 177,-187 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139830467106464 -->\n<g class=\"node\" id=\"node1\">\n<title>139830467106464</title>\n<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 173,-182.5 173,-146.5 0,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_7_input: InputLayer</text>\n</g>\n<!-- 139830467106072 -->\n<g class=\"node\" id=\"node2\">\n<title>139830467106072</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_7: Dense</text>\n</g>\n<!-- 139830467106464&#45;&gt;139830467106072 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139830467106464-&gt;139830467106072</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 139830467106016 -->\n<g class=\"node\" id=\"node3\">\n<title>139830467106016</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_8: Dense</text>\n</g>\n<!-- 139830467106072&#45;&gt;139830467106016 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139830467106072-&gt;139830467106016</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN15uo3rqxmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models \n",
        "from keras.layers import Dense \n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA7AaeAjq8BY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cce8d631-b9a0-44a1-a747-09c5c73ed516"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ihZ0H7_rHIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d14ce47-f771-43c6-ab21-3b296aaed054"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfyVs8YqrJV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "636ec032-605a-4adc-cef4-15caea32d7f4"
      },
      "source": [
        "print(f\"X train shape {X_train.shape}\")\n",
        "print(f\"Y train shape { y_train.shape }\")\n",
        "print(f\"X test shape { X_test.shape}\")\n",
        "print(f\"Y test shape { y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape (60000, 28, 28)\n",
            "Y train shape (60000,)\n",
            "X test shape (10000, 28, 28)\n",
            "Y test shape (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPk3NhlQrnpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert from 2D - 28*28 to 784*1 \n",
        "X_train = X_train.reshape((X_train.shape[0], 28*28))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28*28))\n",
        "\n",
        "# Normalize \n",
        "X_train = X_train/255\n",
        "X_test = X_train/255\n",
        "\n",
        "# Cateogorical to one hot encoded \n",
        "\n",
        "y_test = to_categorical(y_test, 10)\n",
        "y_train = to_categorical(y_train, 10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn7wKHvptFQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66d3e14d-9874-42f9-89b6-9ebfbd776692"
      },
      "source": [
        "# A simple logistic regression\n",
        "model = Sequential()\n",
        "#creation of first hidden layer with 10 nodes and sigmoid activation \n",
        "# Z[1] = W[1]X + b\n",
        "# A[1] = sigmoid(Z[1])\n",
        "model.add(Dense(units=10, activation='sigmoid', input_dim=784))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,y_train, epochs=50, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/50\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 1.1963 - accuracy: 0.7317 - val_loss: 0.6370 - val_accuracy: 0.8648\n",
            "Epoch 2/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.5713 - accuracy: 0.8671 - val_loss: 0.4731 - val_accuracy: 0.8875\n",
            "Epoch 3/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.4723 - accuracy: 0.8812 - val_loss: 0.4167 - val_accuracy: 0.8951\n",
            "Epoch 4/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.4280 - accuracy: 0.8883 - val_loss: 0.3864 - val_accuracy: 0.9003\n",
            "Epoch 5/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.4017 - accuracy: 0.8937 - val_loss: 0.3678 - val_accuracy: 0.9043\n",
            "Epoch 6/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.3838 - accuracy: 0.8967 - val_loss: 0.3539 - val_accuracy: 0.9068\n",
            "Epoch 7/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.3705 - accuracy: 0.8997 - val_loss: 0.3442 - val_accuracy: 0.9087\n",
            "Epoch 8/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.3603 - accuracy: 0.9021 - val_loss: 0.3361 - val_accuracy: 0.9097\n",
            "Epoch 9/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.3519 - accuracy: 0.9037 - val_loss: 0.3299 - val_accuracy: 0.9105\n",
            "Epoch 10/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.3450 - accuracy: 0.9053 - val_loss: 0.3252 - val_accuracy: 0.9121\n",
            "Epoch 11/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.3394 - accuracy: 0.9063 - val_loss: 0.3198 - val_accuracy: 0.9123\n",
            "Epoch 12/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.3343 - accuracy: 0.9077 - val_loss: 0.3162 - val_accuracy: 0.9133\n",
            "Epoch 13/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.3299 - accuracy: 0.9090 - val_loss: 0.3126 - val_accuracy: 0.9154\n",
            "Epoch 14/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.3260 - accuracy: 0.9099 - val_loss: 0.3099 - val_accuracy: 0.9153\n",
            "Epoch 15/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.3226 - accuracy: 0.9108 - val_loss: 0.3068 - val_accuracy: 0.9163\n",
            "Epoch 16/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.3195 - accuracy: 0.9118 - val_loss: 0.3045 - val_accuracy: 0.9172\n",
            "Epoch 17/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.3167 - accuracy: 0.9127 - val_loss: 0.3027 - val_accuracy: 0.9172\n",
            "Epoch 18/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.3142 - accuracy: 0.9129 - val_loss: 0.3006 - val_accuracy: 0.9181\n",
            "Epoch 19/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.3118 - accuracy: 0.9139 - val_loss: 0.2991 - val_accuracy: 0.9177\n",
            "Epoch 20/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.3096 - accuracy: 0.9144 - val_loss: 0.2973 - val_accuracy: 0.9180\n",
            "Epoch 21/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.3076 - accuracy: 0.9154 - val_loss: 0.2958 - val_accuracy: 0.9181\n",
            "Epoch 22/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.3058 - accuracy: 0.9152 - val_loss: 0.2942 - val_accuracy: 0.9188\n",
            "Epoch 23/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.3040 - accuracy: 0.9155 - val_loss: 0.2934 - val_accuracy: 0.9189\n",
            "Epoch 24/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.3024 - accuracy: 0.9165 - val_loss: 0.2924 - val_accuracy: 0.9186\n",
            "Epoch 25/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.3009 - accuracy: 0.9166 - val_loss: 0.2910 - val_accuracy: 0.9194\n",
            "Epoch 26/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2994 - accuracy: 0.9173 - val_loss: 0.2899 - val_accuracy: 0.9194\n",
            "Epoch 27/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2980 - accuracy: 0.9173 - val_loss: 0.2896 - val_accuracy: 0.9195\n",
            "Epoch 28/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2969 - accuracy: 0.9178 - val_loss: 0.2882 - val_accuracy: 0.9201\n",
            "Epoch 29/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.2955 - accuracy: 0.9180 - val_loss: 0.2876 - val_accuracy: 0.9199\n",
            "Epoch 30/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2943 - accuracy: 0.9188 - val_loss: 0.2867 - val_accuracy: 0.9212\n",
            "Epoch 31/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2934 - accuracy: 0.9185 - val_loss: 0.2858 - val_accuracy: 0.9211\n",
            "Epoch 32/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2923 - accuracy: 0.9188 - val_loss: 0.2850 - val_accuracy: 0.9214\n",
            "Epoch 33/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.2912 - accuracy: 0.9192 - val_loss: 0.2844 - val_accuracy: 0.9207\n",
            "Epoch 34/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2903 - accuracy: 0.9200 - val_loss: 0.2835 - val_accuracy: 0.9210\n",
            "Epoch 35/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2894 - accuracy: 0.9196 - val_loss: 0.2830 - val_accuracy: 0.9215\n",
            "Epoch 36/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2886 - accuracy: 0.9196 - val_loss: 0.2827 - val_accuracy: 0.9216\n",
            "Epoch 37/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2878 - accuracy: 0.9202 - val_loss: 0.2820 - val_accuracy: 0.9213\n",
            "Epoch 38/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2868 - accuracy: 0.9202 - val_loss: 0.2819 - val_accuracy: 0.9218\n",
            "Epoch 39/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2861 - accuracy: 0.9202 - val_loss: 0.2810 - val_accuracy: 0.9222\n",
            "Epoch 40/50\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 0.2854 - accuracy: 0.9206 - val_loss: 0.2806 - val_accuracy: 0.9226\n",
            "Epoch 41/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2846 - accuracy: 0.9215 - val_loss: 0.2801 - val_accuracy: 0.9220\n",
            "Epoch 42/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.2841 - accuracy: 0.9206 - val_loss: 0.2794 - val_accuracy: 0.9225\n",
            "Epoch 43/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2833 - accuracy: 0.9215 - val_loss: 0.2796 - val_accuracy: 0.9225\n",
            "Epoch 44/50\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 0.2827 - accuracy: 0.9213 - val_loss: 0.2788 - val_accuracy: 0.9229\n",
            "Epoch 45/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.2820 - accuracy: 0.9212 - val_loss: 0.2784 - val_accuracy: 0.9229\n",
            "Epoch 46/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.2814 - accuracy: 0.9217 - val_loss: 0.2781 - val_accuracy: 0.9229\n",
            "Epoch 47/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.2808 - accuracy: 0.9216 - val_loss: 0.2775 - val_accuracy: 0.9227\n",
            "Epoch 48/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2802 - accuracy: 0.9223 - val_loss: 0.2770 - val_accuracy: 0.9233\n",
            "Epoch 49/50\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.2796 - accuracy: 0.9221 - val_loss: 0.2771 - val_accuracy: 0.9227\n",
            "Epoch 50/50\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.2791 - accuracy: 0.9226 - val_loss: 0.2769 - val_accuracy: 0.9233\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f2cd06a2e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qPU88Flt1bI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "329d9572-bd4b-46e3-cbc0-54d4a33e6398"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(model.history.history[\"accuracy\"])\n",
        "plt.plot(model.history.history[\"val_accuracy\"])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend([\"Train\", \"Validation\"], loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCIqj_uQ1AJe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a132c3dd-14bd-4740-94ee-bdec4110d870"
      },
      "source": [
        "from keras import models \n",
        "from keras.layers import Dense \n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "X_train = X_train.reshape((50000, 32*32*3))\n",
        "X_test = X_test.reshape((10000, 32*32*3))\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "# Normalize \n",
        "X_train = X_train.astype('float32')/255\n",
        "X_test =  X_test.astype('float32')/255\n",
        "\n",
        "# Cateogorical to one hot encoded \n",
        "\n",
        "y_test = to_categorical(y_test, 10)\n",
        "y_train = to_categorical(y_train, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 3072)\n",
            "(10000, 3072)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkEDvKPg2TML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59a1fb4c-90a5-412e-922c-b0ff19cbba6c"
      },
      "source": [
        "y_test.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psItzshI2Kzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A simple logistic regression\n",
        "model = Sequential()\n",
        "#creation of first hidden layer with 10 nodes and sigmoid activation \n",
        "# Z[1] = W[1]X + b\n",
        "# A[1] = sigmoid(Z[1])\n",
        "model.add(Dense(units=100, activation='sigmoid', input_dim=3072))\n",
        "model.add(Dense(units=10, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1Yk_ZM92tCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d1e4463-b56d-424c-dc24-7b53d9164b6f"
      },
      "source": [
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,y_train, epochs=50, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "40000/40000 [==============================] - 5s 125us/step - loss: 2.1886 - accuracy: 0.2281 - val_loss: 2.0676 - val_accuracy: 0.2890\n",
            "Epoch 2/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.9912 - accuracy: 0.3128 - val_loss: 1.9440 - val_accuracy: 0.3219\n",
            "Epoch 3/50\n",
            "40000/40000 [==============================] - 5s 125us/step - loss: 1.8991 - accuracy: 0.3418 - val_loss: 1.8800 - val_accuracy: 0.3419\n",
            "Epoch 4/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.8514 - accuracy: 0.3551 - val_loss: 1.8447 - val_accuracy: 0.3598\n",
            "Epoch 5/50\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.8188 - accuracy: 0.3679 - val_loss: 1.8202 - val_accuracy: 0.3690\n",
            "Epoch 6/50\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.7938 - accuracy: 0.3766 - val_loss: 1.7978 - val_accuracy: 0.3739\n",
            "Epoch 7/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.7730 - accuracy: 0.3826 - val_loss: 1.7806 - val_accuracy: 0.3816\n",
            "Epoch 8/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.7543 - accuracy: 0.3888 - val_loss: 1.7726 - val_accuracy: 0.3853\n",
            "Epoch 9/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.7378 - accuracy: 0.3955 - val_loss: 1.7603 - val_accuracy: 0.3844\n",
            "Epoch 10/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.7231 - accuracy: 0.4017 - val_loss: 1.7488 - val_accuracy: 0.3871\n",
            "Epoch 11/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.7088 - accuracy: 0.4047 - val_loss: 1.7368 - val_accuracy: 0.3926\n",
            "Epoch 12/50\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.6949 - accuracy: 0.4096 - val_loss: 1.7237 - val_accuracy: 0.4002\n",
            "Epoch 13/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.6810 - accuracy: 0.4141 - val_loss: 1.7058 - val_accuracy: 0.4078\n",
            "Epoch 14/50\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.6693 - accuracy: 0.4189 - val_loss: 1.6965 - val_accuracy: 0.4093\n",
            "Epoch 15/50\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.6571 - accuracy: 0.4231 - val_loss: 1.6888 - val_accuracy: 0.4102\n",
            "Epoch 16/50\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.6452 - accuracy: 0.4270 - val_loss: 1.6790 - val_accuracy: 0.4192\n",
            "Epoch 17/50\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.6340 - accuracy: 0.4304 - val_loss: 1.6739 - val_accuracy: 0.4180\n",
            "Epoch 18/50\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.6241 - accuracy: 0.4347 - val_loss: 1.6646 - val_accuracy: 0.4203\n",
            "Epoch 19/50\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.6144 - accuracy: 0.4365 - val_loss: 1.6565 - val_accuracy: 0.4193\n",
            "Epoch 20/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.6043 - accuracy: 0.4416 - val_loss: 1.6533 - val_accuracy: 0.4217\n",
            "Epoch 21/50\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.5953 - accuracy: 0.4452 - val_loss: 1.6480 - val_accuracy: 0.4214\n",
            "Epoch 22/50\n",
            "40000/40000 [==============================] - 5s 130us/step - loss: 1.5876 - accuracy: 0.4463 - val_loss: 1.6394 - val_accuracy: 0.4257\n",
            "Epoch 23/50\n",
            "40000/40000 [==============================] - 5s 130us/step - loss: 1.5786 - accuracy: 0.4504 - val_loss: 1.6240 - val_accuracy: 0.4345\n",
            "Epoch 24/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.5701 - accuracy: 0.4522 - val_loss: 1.6215 - val_accuracy: 0.4359\n",
            "Epoch 25/50\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.5624 - accuracy: 0.4545 - val_loss: 1.6237 - val_accuracy: 0.4311\n",
            "Epoch 26/50\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.5549 - accuracy: 0.4584 - val_loss: 1.6146 - val_accuracy: 0.4326\n",
            "Epoch 27/50\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.5475 - accuracy: 0.4582 - val_loss: 1.6204 - val_accuracy: 0.4337\n",
            "Epoch 28/50\n",
            "40000/40000 [==============================] - 5s 129us/step - loss: 1.5401 - accuracy: 0.4624 - val_loss: 1.6002 - val_accuracy: 0.4400\n",
            "Epoch 29/50\n",
            "40000/40000 [==============================] - 5s 132us/step - loss: 1.5335 - accuracy: 0.4658 - val_loss: 1.5907 - val_accuracy: 0.4449\n",
            "Epoch 30/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.5263 - accuracy: 0.4678 - val_loss: 1.6027 - val_accuracy: 0.4368\n",
            "Epoch 31/50\n",
            "40000/40000 [==============================] - 5s 129us/step - loss: 1.5204 - accuracy: 0.4694 - val_loss: 1.5903 - val_accuracy: 0.4454\n",
            "Epoch 32/50\n",
            "40000/40000 [==============================] - 5s 130us/step - loss: 1.5142 - accuracy: 0.4706 - val_loss: 1.5742 - val_accuracy: 0.4491\n",
            "Epoch 33/50\n",
            "40000/40000 [==============================] - 5s 129us/step - loss: 1.5075 - accuracy: 0.4745 - val_loss: 1.5755 - val_accuracy: 0.4470\n",
            "Epoch 34/50\n",
            "40000/40000 [==============================] - 5s 130us/step - loss: 1.5020 - accuracy: 0.4775 - val_loss: 1.5697 - val_accuracy: 0.4520\n",
            "Epoch 35/50\n",
            "40000/40000 [==============================] - 5s 134us/step - loss: 1.4954 - accuracy: 0.4785 - val_loss: 1.5680 - val_accuracy: 0.4519\n",
            "Epoch 36/50\n",
            "40000/40000 [==============================] - 5s 131us/step - loss: 1.4895 - accuracy: 0.4813 - val_loss: 1.5579 - val_accuracy: 0.4562\n",
            "Epoch 37/50\n",
            "40000/40000 [==============================] - 5s 132us/step - loss: 1.4843 - accuracy: 0.4822 - val_loss: 1.5601 - val_accuracy: 0.4511\n",
            "Epoch 38/50\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.4783 - accuracy: 0.4852 - val_loss: 1.5662 - val_accuracy: 0.4516\n",
            "Epoch 39/50\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.4734 - accuracy: 0.4853 - val_loss: 1.5484 - val_accuracy: 0.4581\n",
            "Epoch 40/50\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.4683 - accuracy: 0.4877 - val_loss: 1.5478 - val_accuracy: 0.4583\n",
            "Epoch 41/50\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.4616 - accuracy: 0.4893 - val_loss: 1.5535 - val_accuracy: 0.4540\n",
            "Epoch 42/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.4573 - accuracy: 0.4917 - val_loss: 1.5506 - val_accuracy: 0.4582\n",
            "Epoch 43/50\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.4518 - accuracy: 0.4926 - val_loss: 1.5390 - val_accuracy: 0.4629\n",
            "Epoch 44/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.4476 - accuracy: 0.4942 - val_loss: 1.5336 - val_accuracy: 0.4619\n",
            "Epoch 45/50\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.4415 - accuracy: 0.4974 - val_loss: 1.5288 - val_accuracy: 0.4654\n",
            "Epoch 46/50\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.4367 - accuracy: 0.4990 - val_loss: 1.5274 - val_accuracy: 0.4628\n",
            "Epoch 47/50\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.4324 - accuracy: 0.5003 - val_loss: 1.5247 - val_accuracy: 0.4632\n",
            "Epoch 48/50\n",
            "40000/40000 [==============================] - 5s 126us/step - loss: 1.4269 - accuracy: 0.5042 - val_loss: 1.5224 - val_accuracy: 0.4641\n",
            "Epoch 49/50\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.4226 - accuracy: 0.5033 - val_loss: 1.5239 - val_accuracy: 0.4670\n",
            "Epoch 50/50\n",
            "40000/40000 [==============================] - 6s 144us/step - loss: 1.4173 - accuracy: 0.5046 - val_loss: 1.5179 - val_accuracy: 0.4637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f2cd06ddf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2GlI9nS2gya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a35e24f8-0c4b-461f-84d0-0b2923794b77"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(model.history.history[\"accuracy\"])\n",
        "plt.plot(model.history.history[\"val_accuracy\"])\n",
        "plt.title(\"Model Accuracy Cifar 10\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend([\"Train\", \"Validation\"], loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3zU9f3A8dc7IQMyGEmAQBL2VkGIoKIITlQEt2BV0NZVbbXWttbS1vmrbdVaR21xb1wVwVEHguBACILIFAgjgZAJWWRd7v374/sNHuECAXI5kns/H4975L7r7v0N4d732aKqGGOMMfWFBTsAY4wxRyZLEMYYY/yyBGGMMcYvSxDGGGP8sgRhjDHGL0sQxhhj/LIEYY5YItJTRFRE2jTi3Gki8kVzxNWSiUiaiJSJSLi73UVEFohIqYg8FOz4zJHFEoRpEiKyWUSqRSSx3v5l7od8z+BEtlcsse6H44fBjiWQRKS/iLwpIgUiUiwiK0TkNhEJV9WtqhqrqrXu6dcBBUC8qv66id5/hoisExGviEzzc/xXIrJDREpE5FkRiWqK9zVNzxKEaUqbgCl1GyJyNNAueOHs4yKgCjhDRLo25xs3phTURO/TB/gGyAKOVtX2wCVAOhDn55IewGo9hBGz+7mn74CfA9/6ueYs4A7gNPe9ewN3H+x7m+ZhCcI0pZeAq3y2pwIv+p4gIu1F5EURyReRLSIyXUTC3GPhIvKg+803EzjXz7XPiEiOiGwTkfvqqkoaaSrwb2AFcEW91z5JRL4SkV0iklX3zVdE2orIQ26sxSLyhbtvrIhk13uNzSJyuvv8LhF5S0ReFpESYJqIjBSRr933yBGRx0Uk0uf6ISLyiYgUiUiuiNwpIl1FZLeIJPicN9z9/UX4uce7ga9U9TZVzQFQ1XWqermq7vKtthOR593fyW/dktXpjYhRReQmEVkPrPf3S1bVJ1R1LlDZwL/BM6q6SlV3AvcC0/y9jgk+SxCmKS0C4kVkkPvBPRl4ud45jwHtcb45noKTUK52j10LTACOxfnGe3G9a58HPEBf95wzgZ81JjAR6QGMBV5xH1fVO/ahG1sSMAxY7h5+EBgBnAh0An4LeBvznsAk4C2gg/uetcCvgETgBJxv0T93Y4gDPgX+B3Rz73Guqu4A5gOX+rzulcBMVa3x856nu+95QKo6zY3rb26106f7i9HH+cAoYHBj3qeeITgljDrfAV18E6A5cliCME2trhRxBrAG2FZ3wCdp/F5VS1V1M/AQzgceOB+Cj6hqlqoWAX/xubYLcA5wq6qWq2oe8A/39RrjSmCFqq4GZgJDRORY99jlwKeq+pqq1qhqoaoud0s21wC3qOo2Va1V1a9UtaqR7/m1qs5SVa+qVqjqUlVdpKoe997/g5MkwUmMO1T1IVWtdH8/37jHXsAt8bi/wyk4v2d/EoCcRsa3jwPEWOcvqlqkqhWH8BaxQLHPdt1zf9VfJsiapV7UhJSXgAVAL+pVL+F8K40Atvjs2wJ0d593w6k79z1Wp4d7bY6I1O0Lq3f+/lwFPAWgqttE5HOc6o5lQCqw0c81iUB0A8caY6/YRKQ/8DBO6agdzv+/pe7hhmIAeBf4t4j0AgYAxaq6uIFzC4HkQ4z3QDHWaezv3J8yIN5nu+556WG8pgkQK0GYJqWqW3Aaq88B/lvvcAFQg/NhXyeNH0sZOTgflL7H6mThNDAnqmoH9xGvqkMOFJOInAj0A37v9p7ZgVNFcrnb0JoF9PFzaQFOPbq/Y+X4NMC73+yT6p1Tv+H3SWAt0E9V44E7gbpsl4VT7bYPVa0E3sApRVxJw6UHcKqpLtrP8QPZX4x7QjqM118FDPXZHgrkqmrhYbymCRBLECYQfgqcqqrlvjvdrpVvAPeLSJxb938bP7ZTvAH8UkRSRKQjTm+XumtzgI+Bh0QkXkTCRKSPiNSv/vBnKvAJTp35MPdxFNAWOBunHv50EbnUbbxNEJFhquoFngUeFpFubiP6CW63zB+AaBE5120sng4cqLtmHFAClInIQOBGn2PvAckicquIRLm/n1E+x1/EacydyP4TxJ+BE0Xk73U9tUSkr9tY3uFAv6gDxNgoIhIpItE4iSVCRKLrOiK49/FTERnsxjMdp23JHIEsQZgmp6obVTWjgcO/wPn2nQl8AbyK8yEMThXQRzgNl9+ybwnkKiASWA3sxGmM3W91ivtBdSnwmKru8HlswvmgnaqqW3FKPL8GinAaqOu+5d4OfA8scY/9FQhT1WKcxtuncUpA5cBevZr8uB2nvaPUvdfX6w6oailOu815wA6cHkLjfI5/idM4/q1bSvNLVTfiNC73BFaJSDHwNpBB46pxGozxIHwMVOA07M9wn49x4/sf8DdgHrAVpxrxz4fwHqYZiC0YZEzLICKfAa+q6tPBjsWEBksQxrQAInIcTjVZqlvaMCbgrIrJmCOciLyA0/h8qyUH05ysBGGMMcYvK0EYY4zxq9UMlEtMTNSePXsGOwxjjGlRli5dWqCq9cfwAK0oQfTs2ZOMjIZ6VhpjjPFHRBrsNm1VTMYYY/yyBGGMMcYvSxDGGGP8ajVtEP7U1NSQnZ1NZaW/dUvMoYiOjiYlJYWICH9r1RhjWpNWnSCys7OJi4ujZ8+e+EwRbQ6RqlJYWEh2dja9evUKdjjGmABr1VVMlZWVJCQkWHJoIiJCQkKClciMCRGtOkEAlhyamP0+jQkdrbqKyRhjWhJVZe2OUqIjwkluH010RLjf87xeJaekkg15ZWzMKyM6IpzLR6X5PfdwBDRBiMh44J9AOPC0qj5Q7/g04O/8uKLY43VTGYvIVJzFRADuU9UXAhlrIBQWFnLaaacBsGPHDsLDw0lKcgYsLl68mMjIyAavzcjI4MUXX+TRRx9tlliNMcFTU+vlvRXbmbFgE2tySvbsT4iJJLlDNN3atyW5fTS7KmrYmF/GxrxyKmpq95x3bFqHlpUg3CUYn8BZBCUbWCIis91F4329rqo317u2E84iIuk4yxsuda/dGah4AyEhIYHly5cDcNdddxEbG8vtt9++57jH46FNG///BOnp6aSnpzdLnMaY4CitrGHm4iye/XITOcWV9O0cy33nH0XbiHC276pge3El23dVsLmwnK83FhLfNoI+nWM5bmQn+naOpU9SLH07x5IQ0/CXzcMRyBLESGCDqmYCiMhMYBLOamAHchbwiaoWudd+AowHXgtQrM1m2rRpREdHs2zZMkaPHs3kyZO55ZZbqKyspG3btjz33HMMGDCA+fPn8+CDD/Lee+9x1113sXXrVjIzM9m6dSu33norv/zlL4N9K8aYg1Tt8ZK1czebC8r5ZlMRr32zldIqD6N6deL+C45ibP/OhIUdOe18gUwQ3XEWYq+TjbNQfH0XicgYnDV+f6WqWQ1c2/1wgrl7zipWby858IkHYXC3eP583pCDvi47O5uvvvqK8PBwSkpKWLhwIW3atOHTTz/lzjvv5O23397nmrVr1zJv3jxKS0sZMGAAN954o41FMOYIVVFdy5odJazeXsIPuaVsKihnc2E523ZW4HVXWAgTOOfoZK49uTdDUxuzXHjzC3Yj9RzgNVWtEpHrgReAUxt7sYhcB1wHkJbW9PVvgXLJJZcQHu40PhUXFzN16lTWr1+PiFBTU+P3mnPPPZeoqCiioqLo3Lkzubm5pKSkNGfYxhg/VJXlWbtYvKmIVdtLWLW9mE0F5XsSQVxUG3omxjAstSMXDOtOj4QYeibG0Ccphg7tAlM11FQCmSC2Aak+2yn82BgNgKoW+mw+jbOYed21Y+tdO7/+G6jqDJxF0UlPT9/vykeH8k0/UGJiYvY8/+Mf/8i4ceN455132Lx5M2PHjvV7TVRU1J7n4eHheDyeQIdpjNmPLYXlvLNsG7OWbWNz4W4Aundoy6DkeCYc040h3eIZ3C2e7h3attju4YFMEEuAfiLSC+cDfzJwue8JIpKsqjnu5kRgjfv8I+D/RKSju30m8PsAxho0xcXFdO/u1J49//zzwQ3GGLNfReXVvP99Du98m823W3chAif0TuCmcX05bVAXOgWosThYApYgVNUjIjfjfNiHA8+q6ioRuQfIUNXZwC9FZCLgAYqAae61RSJyL06SAbinrsG6tfntb3/L1KlTue+++zj33HODHY4xBqfaKLekilXbi1m13WlLWJVTTFZRBQD9u8Tyu/EDmTSsG906tA1ytIHTatakTk9P1/oLBq1Zs4ZBgwYFKaLWy36vpjXIL61iedYucksqySupJLekitzSSvJKqtheXMGu3T+2B/ZKjGFwslNldEr/JIZ0i2+x1Ub1ichSVfXbpz7YjdTGGNMsqjy1LN2ykwU/FLDgh3xW+wxICxNIjI2iS3w03TpEMyytAwO6xDGkWzwDk+OJjQrNj8rQvGtjTKuXV1rJ6u0lrM4pIWPzThZlFrK7upY2YcKIHh35zVkDOL53Aqkd25IQG0X4ETT+4EhhCcIY0+IVV9Tw9cYClmXtYk1OKau3l1BQVrXneM+Edlw0PIUx/ZM4oU9CyJYIDpb9lowxLY7Xq3y/rZjPf8hnwQ/5LMvaRa1XiQgX+nWOY+yApD1tBoO6xtO+nQ0qPRSWIIwxR5Rqj5cvNxSwYH0+lTW1eGqVWq9Sq4rHq1TV1PLt1l0UlVcjAkd3b8+Np/RhTP8khqV2ILJNq1/FoNlYgjDGBJ2n1ss3m4qY8912Ply5g+KKGtpGhBMX3YbwMCE8TGiz52cYYwckcUr/JE7qm0hCbNSB38AcEksQATZu3DjuuOMOzjrrrD37HnnkEdatW8eTTz65z/ljx47lwQcfJD09nXPOOYdXX32VDh32nqfF38yw9c2aNYv+/fszePBgAP70pz8xZswYTj/99Ca6M2MOnter7Nxd7dOltJKV20r4cGUOBWXVxESGc+aQrkw4JpmT+yVZaSDILEEE2JQpU5g5c+ZeCWLmzJn87W9/289Vjg8++OCQ33fWrFlMmDBhT4K45557Dvm1jDlUxRU1zF2Ty4crd7BqWzH5ZVXU1O499io6IozTBnZhwjHJjBvYucFFckzzswQRYBdffDHTp0+nurqayMhINm/ezPbt23nttde47bbbqKio4OKLL+buu+/e59qePXuSkZFBYmIi999/Py+88AKdO3cmNTWVESNGAPDUU08xY8YMqqur6du3Ly+99BLLly9n9uzZfP7559x33328/fbb3HvvvUyYMIGLL76YuXPncvvtt+PxeDjuuON48skniYqKomfPnkydOpU5c+ZQU1PDm2++ycCBA5v7V2ZauMKyKj5Z7SSFrzYWUFOrJLeP5vjeCXRtH02XOGe8Qef4KDrHOT+j2lhSOBKFToL48A7Y8X3TvmbXo+HsB/Z7SqdOnRg5ciQffvghkyZNYubMmVx66aXceeeddOrUidraWk477TRWrFjBMccc4/c1li5dysyZM1m+fDkej4fhw4fvSRAXXngh1157LQDTp0/nmWee4Re/+AUTJ07ckxB8VVZWMm3aNObOnUv//v256qqrePLJJ7n11lsBSExM5Ntvv+Vf//oXDz74IE8//fTh/pZMK1RSWUNW0W6276pk287dbC+uZNuuCrKLdvP9tmK8Cmmd2nHN6F6MP6orQ1M6HFHrHJjGCZ0EEUR11Ux1CeKZZ57hjTfeYMaMGXg8HnJycli9enWDCWLhwoVccMEFtGvXDoCJEyfuObZy5UqmT5/Orl27KCsr26sqy59169bRq1cv+vfvD8DUqVN54okn9iSICy+8EIARI0bw3//+97Dv3bQehWVV/G/VDt5fkcOizMI901kDRLYJo3sHZ1nMn4/ty/ijuraq6ShCVegkiAN80w+kSZMm8atf/Ypvv/2W3bt306lTJx588EGWLFlCx44dmTZtGpWVlYf02tOmTWPWrFkMHTqU559/nvnz5x9WrHXTituU4gZgZ3k1H63awXsrcvg6s5Bar9I7MYafj+3LkG7xdOvQlu4d25IQE2nJoBUKnQQRRLGxsYwbN45rrrmGKVOmUFJSQkxMDO3btyc3N5cPP/ywwXUgAMaMGcO0adP4/e9/j8fjYc6cOVx//fUAlJaWkpycTE1NDa+88sqeqcPj4uIoLS3d57UGDBjA5s2b2bBhw542i1NOOSUg921arpXbinlqYSbvr8jB41V6JLTjhlN6c+7R3RiUHGfJIERYgmgmU6ZM4YILLmDmzJkMHDiQY489loEDB5Kamsro0aP3e+3w4cO57LLLGDp0KJ07d+a4447bc+zee+9l1KhRJCUlMWrUqD1JYfLkyVx77bU8+uijvPXWW3vOj46O5rnnnuOSSy7Z00h9ww03BOamTYvi9Srz1uXx1MJMFmUWERvVhitP6MFFw1OsuihE2XTf5qDZ77X18HqVHSWVzFuXxzNfbCIzv5zk9tFcPbonk0emER9tU1S0djbdtzEhrqi8mtXbS9iYX8bmwnK2Fu5mS9FuthbtptrjBeCo7vH8c/Iwzjk6mYhwG6BmLEEY06qoKllFFazcXrxnquvV20vYUfJjJ4i2EeH0SGhH78QYTh3YmbRO7RjcLZ5jUztYNZLZS6tPEKpqf/RNqLVUSbYW1R4vK7cX8+2WnWRs3knGlp17prkODxP6JsVyQp8EBiXHMTi5Pf27xJIUF2X/J1oSVdj2Laz7AOK7wVEXQdsOB76uCbTqBBEdHU1hYSEJCQn2H6IJqCqFhYVER0cHO5SQVlbl4f0V23ln2TaWbd1FlVtFlNapHSf3S2REj44MS+1A386xNm1Fc/BUww//A68H+pzaNB/edUlh1X9h9Wwo3goIoPDRnTBwAhz7E+g1FsICVx3YqhNESkoK2dnZ5OfnBzuUViM6OpqUlJRghxFyVJVvt+7ijSVZzFmxnd3VtfRJiuGK43uQ3qMjI3p0pHO8Je5mVZQJS1+AZS/D7gJnn4RDjxOh/3jnkdh3/6/hqYayXCjNcR4lObBzE6z9wEkKYRHQZxyM+z0MOBuKNsHyV+D7N2HlWxCfAsMudx6dejX5LbbqXkzGtHTFFTW8mZHF60uyWJ9XRrvIcCYck8xlx6UxPM3aDAIiazFkPAeRMdC+O7RPhfju0D4FYhJh/cfO8cx5TkLoPx7Sr4aoeKck8cNHkLfKea2EvtBtOHgqobocanZDdZnzvLLkx8TiKzwKep8Cg8+HgedA2477nlNTCeveh2WvwMbPIGkg3LTokG53f72YLEEYcwTaWV7Ns19u4vkvN1Na5eHYtA5clp7KhKHdbLnMQClYD3PvhjVzIKq9U6NTWez/3PgUGH4VDL/SaReob+cWJ5Gs+9B53ch2TsKJjIEI92dULMQl//iIT4a4btCuExxM4i/eBiXbIfW4A5/rhyUIY1qIgrIqnl64iZe+3kx5dS1nH9WVm8b15aju7YMdWutVugPmPwDfvggRbWH0LXD8z50P8KpS5wO4OBtKsp0qoG7HQr8zIKx1tO/YOAhjjgC1XmXe2jy2Fu0mok0YkeFCRHjYnkfG5iJe/mYLVR4vE47pxs3j+jKga1ywwz7y5K9zvjHX1kBttftwnycPhWT/k17uo2IXfPUYLPqXc/1xP4Mxv4HYpB/PiYqDzgOdRwiyBGFMgJVXeXgzI4tnv9zM1qLdDZ4XHiZMGtaNm8b1pU9SbDNG2ELU1sBn98KX/9z/ef3PhlN+C92H+z9eXuAkhcVPQVWJ02301OnQqXfTx9zCWYIwJkByiit44astvPrNFkoqPQxP68AdZw/kxD4J1NQqNbXePY9qj5IQG0mX1tgTadtSWPiw8wF/2h+ddVQOVnE2vHUNZH0DI66GoZOdHj7hERAe6fwUge/fhq8fh6fGQb8z4ZQ7IMVZO4XSHU6JIeNZqKmAwRPh5NsbX+IIQdYGYUwTyimu4Iv1Bcz/IZ+PVu7Aq8rZRyVzzUm9GNHDT2+U1iw7w6nb3/CJ0xNHwqBiJ6RfA+P+4DTGNsa6/8GsG6DWAxP/6Xzj35/KEljyFHz1OFQUQZ/ToGMPp8eP1wNHXwIn3wZJAw7/HluBoDVSi8h44J9AOPC0qvpdlEFELgLeAo5T1QwR6QmsAda5pyxS1f1OOWoJwgRD8e4avs4s5MsNBXy5sYDM/HIAEmIimTisG9eM7kVqp3ZBjrKZZS12EsPGudC2E5x4M4y8zvlwnv+AU7UTHe9U64y4uuHG3toap1fRV49B12PgkuchoU/j46gqhSVPO9dXljhjBU661aqS6glKghCRcOAH4AwgG1gCTFHV1fXOiwPeByKBm30SxHuqelRj388ShAm0yppa1uSUsCK7mO+yd7Eiu5iN+WWoQrvIcEb16sTovomM7pvIgC5xrXOJTVVY+bZTZVRV4pQKJMz5kJdw0Foo3ADtEuDEXzoNv1H12lNyV8GHv4PNC6HL0TDm1861VaXOa1aWOD+3fAnblzmvceb9EHGI1W81FeCparbpKVqaYPViGglsUNVMN4iZwCRgdb3z7gX+CvwmgLEYc0jKqzzMXJLFrGXbWLujhJpa5wtVYmwUQ1PaM3FoN47vncCw1A5EtmnlM6Bu+xb+d4fTDtDlaOg1Bry1TlLw/TlimlONFBnj/3W6DIGpc2D1u/DxdHhz2r7nRLSDmCSn1DDkgsOLO6Kt8zAHLZAJojuQ5bOdDYzyPUFEhgOpqvq+iNRPEL1EZBlQAkxX1YX130BErgOuA0hLS2vK2E2IKyqv5oWvNvPC15vZtbuGY9M68LOTezM0pT3HpHQguX106xjFXLAeFs+AvDXQfQT0GA1poyDaZ9xF6Q6Ye48zxUNMEkx83KmuOZxxACIw5HynIXnHCichRMc7o5Gj4pxGZxN0QevFJCJhwMPAND+Hc4A0VS0UkRHALBEZoqolviep6gxgBjhVTAEO2YSAbbsqeHphJjMXZ1FRU8uZg7tww9g+DE9rRQ3M3lpY/wks/o8zTUN4JHQeBF8/AV8+4lQZdTnKSRZRsbDoSaeKZvQtTq+f6PimiyWyHaQd33SvZ5pUIBPENiDVZzvF3VcnDjgKmO9+E+sKzBaRiaqaAVQBqOpSEdkI9AeskcEctrpV1LKKdpO1s8L5WbSbrJ27WbZ1FwCThnXnhlN6069LKxqoVlkM377k9PDZudmZ3mHcdKdKKDYJqnfDtgzY8pVT/7/0efBUwIBz4cx7D66B2LQKgUwQS4B+ItILJzFMBi6vO6iqxUBi3baIzAdudxupk4AiVa0Vkd5APyAzgLGaELBtVwWvfbOVmUuy9qyZAE5tR3J8NCmd2nH16J5MG92L7h2O4DprVWdtgMUzYPStzmyfB7IrC16Y4CSGtBPgtD/DoPP2rsqJbOe0K/Qa42x7qqE835mwzoSkgCUIVfWIyM3ARzjdXJ9V1VUicg+Qoaqz93P5GOAeEakBvMANqloUqFhN6+X1KgvW5/Pyoq18tjYXBU4b2Jlx7kpqqR3b0a1D25bTwJzzHXz0B6cHUHik823/omecQV8N2bUVnp/gTC0x7QPoObpx79Um0pJDiLOBcqZVqqyp5aWvt/DSoi1sLdpNYmwklx2XypSRaaR0bIHjEkpynGkmlr/qDDAbd6czHfTMyyF7CUx8DI69Yt/rdm5xkkNVMVw5q+HpJ0zIssn6TMhQVT5dk8c9760iq6iCkT07cftZAxg/pGvLKSX4qqlwBnp98Qh4a+DEX8DJv/6xT/+V78DrV8C7NzltDCfc9OO1RZvghfOc8QVXvevMQmrMQbAEYVqNzPwy7p6zms9/yKdv51he+dkoRvdNPPCFR6q8Nc78Q3mrYfAkOP2ufUcBR8bAlJnw32udpSgrdjrTWOzcBM+fBzXlMHW2M8upMQfJEoRp8cqqPDz22Xqe/WIT0W3CmX7uIKae2JOI8BZYYgCnETrjWecDPzIWLn8T+p/Z8PltouDi52DOLbDg7876BZnznVXMps45tMnxjMEShGmBqjy1rMkpZUX2Lr7LKmbB+nzyS6u4eEQKvxs/kKS4qMAHUbELCn5w1hHuc6ozuKsp7C6C2b+Ate9B73FwwX8grsuBrwsLd9oh2nZwqqTaJbjJodGz1RizD0sQpkXI2FzErOXb+C6ruN6UF5EMS+3Iz8cFcDBbZbGzSHzeWshf6ySGstwfj8d0dhqNj70Swg/jv9TmL52qorI8OONeOOFmCDuIUpCIc13Kcc5ANxu3YA6T9WIyR7SMzUX8c+56Fq4vICYynKGpHTgmpYMz5UVqB7oFesqLip3w4iSne2lUPCT2dxaIT+oPiQOc6p3P/wpbv3a2z7zXmT6ioZi8XijPc7qe7twCu9zHzi1O19WOPZ1uq9bbyDQT68VkWpylW4p45FMnMSTGRvKHcwbxk+PTaBfZjH+yFbvgpQsgdzVMfg0GnO3/g7/3WFj7PnzyJ3j1Uuh5Mpx5n7OYfe4qp7E5b7XzM38tVJftfX1MEnToASOvh1P/0HTVVcYcJitBmCOG16ssyizkyc837kkM14/p0/yJAZxqpZcugJwVcNlLTnI4kNoayHgOPn8AdhfufaxdAnQe7DwS+zkJoUOa84hsgeMyTKthJQhzRMspruCtjGzeXJq9Z1BbUEoMdapK4eWLnWqlS19sXHIAZ9qKUdfB0Mvg2xchrI0zCV7nIc5cR8a0MJYgTFBUe7x8uiaXNzKyWPBDPl6FE/skcNsZ/Rl/VFeiIw5jKunDUZccti111iIYeO7Bv0Z0e2dAmzEtnCUI06x2llfz8qItvPD1FgrKqkhuH81N4/pyyYhU0hKCXNVSVQavXOpMXXHxAeY3MiYEWIIwzWJzQTnPfLGJN5dmUVnjZdyAJK46sSdj+iURHuylOWtr4LuZsPBBp3fRRU8f/ipmxrQCliBMQC3dUsSMBZl8vDqXiLAwLji2Oz87udeRsc6Cpxq+ew0WPuR0NU0eCle87Qx8M8ZYgjBNT1VZuL6Ax+dtYPGmIjq0i+CmsX256sQedI47xIXnD5bX63Qtra121iNuE+08IqKdxuPv34SF/4Dirc4kdmf/Dfqf1fD4BWNCkCUI02S8XuWTNbk8MW8DK7KL6RofzZ8mDGbyyNTD741UsdMZTBaX7Iwb8DfCuGS7s4TmxqqYUqEAABxMSURBVM9g4zyoOMASIt3TYcLD0Pd0SwzG+GEJwhy2Wq/y3ortPDFvAz/klpHWqR0PXHg0FwzvTlSbBnojbVrgrHHQqRd07AUxiXt/SNdUQtYiZ9K5zM8hZzmo1zkWHukMQmufCvHdnXWTN38J+Wuc47FdnNJA77FOj6KaCmfiOk+l87qeCqfU0HucJQZj9sMShDlkqsr8H/J54IO1rMstpV/nWB65bBgTjkmmzf5mUs14Dt67de99kXHQqaeTLKpKYOsi5wM9rI3zTX/Mb50xBWV5UJINxdnOrKVbvnQmuEtJh2FToM9p0GWIffAb0wQsQZhD8n12MX/5cA1fbSykR0I7Hr/8WM45KpmwA/VI+m4mvPcr6HuGM2/Rzi3O2gVFm6Ao02k3aBMN6dc4JYAeJ9rUE8YEiSUIc1Cyinbz94/WMfu77XSKieSu8wZz+agejVutbeV/YdaN0OtkZ/qKiLZOqcAYc0SyBGEaJb+0in/N38Ari7YSFgY3j+vL9af0Ji46onEvsPZ9Zyrr1FHOCmgRbQMbsDHmsFmCMPtVvLuGGQs38uwXm6mu9XLx8BRuPaMfye0P4gN+/afw5jRnnMHlbzjLZBpjjniWIIxf5VUenvtyEzMWZFJS6eG8od341en96J0Ue3AvlPk5vP4TSBrgDEKLjg9MwMaYJmcJwuylptbLK4u28NhnGygsr+b0QV349Zn9GZTcwAd7Vamz0lrBD1C63em6Wuo+SnKcldeSBsKV70LbAK34ZowJCEsQBnC6rH62No/7P1hDZn45J/ZJ4PazBuy9jGdlMfzw0Y+L3+StduYu8tW2kzOYLT7Z6W7aPs3pkRST0Lw3ZIw5bJYgDGt3lHDfe2v4YkMBvZNieHZaOuMGdN57Kc+iTGca7KKNEBbhLL2ZMhKGT3UWwUka4Axai2imqTSMMQFnCSKEFZRV8dDHP/D6kq3ERUdw13mD+cnxPYioP8gtOwNevQy0Fq74L/Qa4yyOY4xp1SxBhJjKmlo+W5vH7OXb+WxdHl6vMvXEntxyWj86tIvc94I178HbP4O4LvCTtyGxb/MHbYwJioAmCBEZD/wTCAeeVtUHGjjvIuAt4DhVzXD3/R74KVAL/FJVPwpkrK1ZTa2XLzYUMGf5dj5enUtZlYfE2CguH5nGlSf0oE9DPZO++Q98+DvoPsIZu2DLZhoTUgKWIEQkHHgCOAPIBpaIyGxVXV3vvDjgFuAbn32DgcnAEKAb8KmI9FfV2kDF21p9+H0Of3x3FQVlVcRFt+Gco7syaVh3ju+d0PBCPV4vfPJH+PpxGHCus4BOZJBXezPGNLtAliBGAhtUNRNARGYCk4DV9c67F/gr8BuffZOAmapaBWwSkQ3u630dwHhblfIqD/fMWc3rGVkck9Ke/7vgKE4ZkNTw7Kp1airgneth9bsw8noY/xcIC9L60MaYoApkgugOZPlsZwOjfE8QkeFAqqq+LyK/qXftonrXdq//BiJyHXAdQFpaWhOF3fKtyN7FLTOXs7mwnJ+P7cOvzui/b8OzP+WFMHMKZH0DZ94PJ9xks6IaE8KC1kgtImHAw8C0Q30NVZ0BzABIT0/Xpoms5ar1Kv9ZsJGHP/6BpLgoXrv2eI7v3cjxB3XdWIuz4ZIXYMj5gQ3WGHPEC2SC2Aak+mynuPvqxAFHAfPd/vZdgdkiMrER15p6dhRXcuvry1iUWcS5RyfzfxccTft2jeyKmp0Br14KqjB1NqQdH9hgjTEtQiATxBKgn4j0wvlwnwxcXndQVYuBxLptEZkP3K6qGSJSAbwqIg/jNFL3AxYHMNYW7csNBfzytWVU1NTy94uP4eIRKXsPctsf68ZqjGnAAROEiJwHvK9at95j46iqR0RuBj7C6eb6rKquEpF7gAxVnb2fa1eJyBs4Ddoe4CbrwbQvr1d58vONPPTxOnonxfL6FcPp27mRi+uowqJ/wUd/sG6sxhi/RHX/Vfci8jJwAvA2zof82uYI7GClp6drRkZGsMNoNsW7a7jtjeXMXZvHxKHd+MuFRxMT1cgCYcF6mHMrbPkCBk6AC5+ybqzGhCgRWaqq6f6OHfATRVWvEJF4YArwvIgo8BzwmqqWNm2opjFWbivmxleWsqO4krsnDuGqE3o0rkrJUw1fPgIL/u4s2DPxMRh2BYQ1ooeTMSbkNOorp6qWiMhbQFvgVuAC4Dci8qiqPhbIAM2PVJVXF2/l7jmrSYiJ5PXrT9h7ttX92boI5twC+WthyIUw/gGn3cEYYxrQmDaIicDVQF/gRWCkquaJSDucNgJLEM2gqLya3729gk9W53Jyv0QeuWwYCbFR+79IFXKWw9LnnUf7VGdFt/5nNUfIxpgWrjEliIuAf6jqAt+dqrpbRH4amLCMry83FHDbG8vZWV7D3WelceWgMMLCykEj9x3IVlsDm79w1oBe9yGUZIOEw/E3wbg7IeogV4QzxoSsxiSIu4Ccug0RaQt0UdXNqjo3UIEZqPZ4eejjdcxYmMkpHXfy0NDFJHz9Nnxe5pwQHgVxXSG+m/MTYMNnUFUMbdpC39Pg1D9Av7NswR5jzEFrTIJ4EzjRZ7vW3XdcQCIyAGTml/Gr15aSsGMBHyUsoH/ZYlgX6bQf9D0dyvN/XNqzdAfkrABPJQw6DwaeC73HWs8kY8xhaUyCaKOq1XUbqlotIn4WDjBNQVV5adEW1n74JI+HvUNqZC5IMoybDiOm2VgFY0yzaUyCyBeRiXUD20RkElAQ2LBCU05xBb97czknbX6M/2vzPtVdh8NJDzilAlvBzRjTzBqTIG4AXhGRxwHBmaH1qoBGFWJUlXeXb+eed5dxr/cJzm3zFXrctUSe/VebatsYEzSNGSi3ETheRGLd7bKARxVCisqrmT7re774fiOvxj3GUTUr4PS7kdG32FTbxpigatRAORE5F2d1t+i6Ebuqek8A4woJG/LK+MnTi4gsz2FewiN0qtgCFz4Nx1wS7NCMMaZRA+X+DbQDxgFPAxdjM6setg15ZUx5ahG9vVt4ucPfiPDshiveht6nBDs0Y4wBoDGT8JyoqlcBO1X1bpyJ+/oHNqzWbWN+GdNmfM7VtW/xmkwnIkzg6g8tORhjjiiNqWKqdH/uFpFuQCGQHLiQWrfMvBKe/89DvFX7Ml0pgAHnwfi/Qvt9VlQ1xpigakyCmCMiHYC/A98CCjwV0Khaqe3fz2P3f3/DvbqeysSjYcIL0POkYIdljDF+7TdBuOtGz1XVXcDbIvIeEO2uBmcaq2IXZW/fTLcNc2hDJ3JOfYTkk6baNNvGmCPafj+h3FXknvDZrrLkcJCqy6l+8WKiNnzIf+QSdv10EcljrrbkYIw54jXmU2quiFwkjV7k2OzhqUJn/oQ2OUu53ftLTrn+Yfqn2hoMxpiWoTEJ4nqcyfmqRKREREpFpCTAcbV8tR546xokcx6/rbmW486ZxsCu8cGOyhhjGq0xI6njmiOQVsXrhXd/Dmvf4z7vNHJ7X8RPRqUFOypjjDkojRkoN8bf/voLCBmXKnxwO6x4nVdjp/J62Tl8fPExjVsz2hhjjiCN6eb6G5/n0cBIYClwakAiaunm3g0Zz7AsbRp3/nAG/7hsCMnt2wY7KmOMOWiNqWI6z3dbRFKBRwIWUUu2/FX44h/sHHwVl313FuOHdOH8YTYAzhjTMh1KX8tsYFBTB9Li1dbA/L/g7TaCK3MuJi46gvsvOMqqlowxLVZj2iAewxk9DU5CGYYzotr4+v5N2LWVd7veysrMMv5z5QgSYqOCHZUxxhyyxrRBZPg89wCvqeqXAYqnZfLWwsKHqOg0mNtXdOXC4d05a0jXYEdljDGHpTEJ4i2gUlVrAUQkXETaqeruwIbWgqx6Bwo38GC7O0iKjebP5w0JdkTGGHPYGjWSGvDthtMW+LQxLy4i40VknYhsEJE7/By/QUS+F5HlIvKFiAx29/cUkQp3/3J3TYojk9cLCx+isG0vni06iv+78Cjat7X1o40xLV9jShDRvsuMqmqZiLQ70EUiEo4zj9MZOA3bS0Rktqqu9jntVVX9t3v+ROBhYLx7bKOqDmvkfQTPug8gbzX3eW5m0rAUTh1oU2kYY1qHxpQgykVkeN2GiIwAKhpx3Uhgg6pmqmo1MBOY5HuCqvpO2RHDj43hLYMquuDvbA/rxpeRJ/Mnq1oyxrQijSlB3Aq8KSLbAQG6Apc14rruQJbPdjYwqv5JInITcBsQyd6D73qJyDKgBJiuqgv9XHsdcB1AWloQprLY8CmSs5x/1FzHny47hk4xkc0fgzHGBEhjBsotEZGBwAB31zpVrWmqAFT1CeAJEbkcmA5MBXKANFUtdEsss0RkSL0SB6o6A5gBkJ6e3rylD1Uq5/6FQk2krP+FnHu0LbJnjGldDljF5H7Dj1HVlaq6EogVkZ834rW3Aak+2ynuvobMBM6HPetOFLrPlwIbOcLWwfZmLiB6x1Kek/O5+4JjbUCcMabVaUwbxLXuinIAqOpO4NpGXLcE6CcivUQkEpgMzPY9QUT6+WyeC6x39ye5jdyISG+gH5DZiPdsNnnv30uudmDg2TfSOT462OEYY0yTa0wbRLiIiKoq7OmddMDKdlX1iMjNwEdAOPCsqq4SkXuADFWdDdwsIqcDNcBOnOolgDHAPSJSA3iBG1S16GBvLlDyV39O16IlvNLxei4f2SfY4RhjTECI+7nf8Akifwd6AP9xd10PbFXV2wMc20FJT0/XjIyMA5/YBFY9OJ7k0pXs/vlyUrokNst7GmNMIIjIUlVN93esMVVMvwM+A25wH9+z98C5kFKTt55BZYtY2vkiSw7GmFbtgAlCVb3AN8BmnLENpwJrAhvWkatg7qN4NIzwUT8LdijGGBNQDbZBiEh/YIr7KABeB1DVcc0T2hGosphO69/iAz2RM462Gc+NMa3b/koQa3FKCxNU9SRVfQyobZ6wjlDLXiHKu5tl3SYTE9WY9n1jjGm59pcgLsQZsDZPRJ4SkdNwRlKHJm8tNV//myXe/vQZelKwozHGmIBrMEGo6ixVnQwMBObhTLnRWUSeFJEzmyvAI8YP/yOiZAvPecZz6sDOwY7GGGMCrjGN1OWq+qq7NnUKsAynZ1NoWfQkBWFJbE46lZSOB5zM1hhjWryDWpNaVXeq6gxVPS1QAR2RdqyEzQt5pvp0xg22OZeMMaHhoBJEyPrm33jCo3nVM47TBtl6D8aY0GBdcQ6kvABWvMGi2DNpQyeGpXQIdkTGGNMsrARxIEufg9oqHiwex7iBnQkLC92OXMaY0GIJYn9qa2DJM+xKPpnllV05fZD1XjLGhA5LEPuz+l0ozeF/secTGR7GSf2Sgh2RMcY0G2uD2J/FMyChL09t782o3jHE2uhpY0wIsRJEQ3YXQdZiivqcz8bCCk633kvGmBBjCaIhmxYAyhfeowBs9LQxJuRYnUlDMudDZByvb+vMgC61pHay0dPGmNBiJYiGZM6nJu1EvtlSzGnWe8kYE4IsQfizcwvs3MTadiPweNUShDEmJFmC8GfT5wC8V9qfTjGRDEvtGOSAjDGm+VkbhD+Z8yG2K3O2xXFS3wTCbfS0MSYEWQmiPq8XMj/H22sMuWXVpFnjtDEmRFmCqC9vNewuoKzbaGq9Spf4qGBHZIwxQWEJor7M+QDkdBoFQOf46CAGY4wxwWMJor5Nn0NCP7JqOwHQ1RKEMSZEWYLw5amGzV9C71PILa0EoIslCGNMiApoghCR8SKyTkQ2iMgdfo7fICLfi8hyEflCRAb7HPu9e906ETkrkHHusS0Dasqh91hyS6oQgcTYyGZ5a2OMOdIELEGISDjwBHA2MBiY4psAXK+q6tGqOgz4G/Cwe+1gYDIwBBgP/Mt9vcDK/BwkDHqeRG5xJYmxUbQJt0KWMSY0BfLTbySwQVUzVbUamAlM8j1BVUt8NmMAdZ9PAmaqapWqbgI2uK8XWJnzIXkYtO1IbmmltT8YY0JaIBNEdyDLZzvb3bcXEblJRDbilCB+eTDXNqmqUqeKqfcpAOSWVFkXV2NMSAt6/YmqPqGqfYDfAdMP5loRuU5EMkQkIz8///AC2fIVeD3QeywAeSWV1sXVGBPSApkgtgGpPtsp7r6GzATOP5hrVXWGqqaranpS0mEuB5o5H9pEQ+rxVHlqKSyvpkucJQhjTOgKZIJYAvQTkV4iEonT6Dzb9wQR6eezeS6w3n0+G5gsIlEi0gvoBywOYKxOA3XqKIiIJr+0CoCu7a2KyRgTugI2WZ+qekTkZuAjIBx4VlVXicg9QIaqzgZuFpHTgRpgJzDVvXaViLwBrAY8wE2qWhuoWCnNhbxVcNqfAaf9AWwUtTEmtAV0NldV/QD4oN6+P/k8v2U/194P3B+46HxsWuD83NNA7Q6SsyomY0wIC3oj9RFh03yIbu90ceXHBNG1vSUIY0zosgShChvnQ68xEOaMxcstqSIiXOjYLiK4sRljTBBZgti1BUqyodcpe3bllVTSOS4aEVsoyBgTumxFuY494daVEBmzZ9eOkkobJGeMCXlWggDokArtOu3ZzC2ptPYHY0zIswThR15JFZ2tB5MxJsRZgqinvMpDaZXH1oEwxoQ8SxD17BkDYW0QxpgQZwminrpR1DbVtzEm1FmCqCfPXWrUptkwxoQ6SxD17Ci2KiZjjAFLEPvILakiJjKcuGgbRW2MCW2WIOrJLa20HkzGGIMliH04K8lZ9ZIxxliCqMeZZsNKEMYYYwnCh6qSW1JlXVyNMQZLEHsprqih2uO1Lq7GGIMliL3UDZKzLq7GGGMJYi879kyzYSUIY4yxBOFjz1KjliCMMcYShK88N0EkxVkVkzHGWILwsaOkkg7tIoiOCA92KMYYE3SWIHxYF1djjPmRJQgfzihqSxDGGAOWIPaSW1JFF2t/MMYYwBLEHrVeJb+syrq4GmOMyxKEq7Csilqv0qW9JQhjjIEAJwgRGS8i60Rkg4jc4ef4bSKyWkRWiMhcEenhc6xWRJa7j9mBjBN8RlFbFZMxxgDQJlAvLCLhwBPAGUA2sEREZqvqap/TlgHpqrpbRG4E/gZc5h6rUNVhgYqvvlwbRW2MMXsJZAliJLBBVTNVtRqYCUzyPUFV56nqbndzEZASwHj2y6bZMMaYvQUyQXQHsny2s919Dfkp8KHPdrSIZIjIIhE5398FInKde05Gfn7+YQWbV1JJmEBibORhvY4xxrQWAatiOhgicgWQDpzis7uHqm4Tkd7AZyLyvapu9L1OVWcAMwDS09P1cGLILakiMTaKNuHWbm+MMRDYEsQ2INVnO8XdtxcROR34AzBRVavq9qvqNvdnJjAfODaAsdpKcsYYU08gE8QSoJ+I9BKRSGAysFdvJBE5FvgPTnLI89nfUUSi3OeJwGjAt3G7yeVagjDGmL0ELEGoqge4GfgIWAO8oaqrROQeEZnonvZ3IBZ4s1531kFAhoh8B8wDHqjX+6nJ5ZVW2UJBxhjjI6BtEKr6AfBBvX1/8nl+egPXfQUcHcjYfFV5aikqr7YShDHG+LAWWSDPlho1xph9WIIA8kptDIQxxtRnCQKfaTYsQRhjzB6WILBpNowxxh9LEDhjICLDw+jYLiLYoRhjzBHDEgROI3Xn+ChEJNihGGPMEcMSBDZIzhhj/LEEQd00G9bF1RhjfFmCwKlishKEMcbsLeQTRFmVh7IqjyUIY4ypJ+QTRLXHy3lDuzGkW3ywQzHGmCPKEbEeRDB1ionksSkBnUncGGNapJAvQRhjjPHPEoQxxhi/LEEYY4zxyxKEMcYYvyxBGGOM8csShDHGGL8sQRhjjPHLEoQxxhi/RFWDHUOTEJF8YMthvEQiUNBE4bQkdt+hxe47tDTmvnuoapK/A60mQRwuEclQ1fRgx9Hc7L5Di913aDnc+7YqJmOMMX5ZgjDGGOOXJYgfzQh2AEFi9x1a7L5Dy2Hdt7VBGGOM8ctKEMYYY/yyBGGMMcavkE8QIjJeRNaJyAYRuSPY8QSSiDwrInkistJnXycR+URE1rs/OwYzxqYmIqkiMk9EVovIKhG5xd3f2u87WkQWi8h37n3f7e7vJSLfuH/vr4tIZLBjDQQRCReRZSLynrsdKve9WUS+F5HlIpLh7jvkv/WQThAiEg48AZwNDAamiMjg4EYVUM8D4+vtuwOYq6r9gLnudmviAX6tqoOB44Gb3H/j1n7fVcCpqjoUGAaMF5Hjgb8C/1DVvsBO4KdBjDGQbgHW+GyHyn0DjFPVYT7jHw75bz2kEwQwEtigqpmqWg3MBCYFOaaAUdUFQFG93ZOAF9znLwDnN2tQAaaqOar6rfu8FOdDozut/75VVcvczQj3ocCpwFvu/lZ33wAikgKcCzztbgshcN/7cch/66GeILoDWT7b2e6+UNJFVXPc5zuALsEMJpBEpCdwLPANIXDfbjXLciAP+ATYCOxSVY97Smv9e38E+C3gdbcTCI37BudLwMcislRErnP3HfLfepumjs60XKqqItIq+z2LSCzwNnCrqpY4XyodrfW+VbUWGCYiHYB3gIFBDingRGQCkKeqS0VkbLDjCYKTVHWbiHQGPhGRtb4HD/ZvPdRLENuAVJ/tFHdfKMkVkWQA92dekONpciISgZMcXlHV/7q7W/1911HVXcA84ASgg4jUfTFsjX/vo4GJIrIZp8r4VOCftP77BkBVt7k/83C+FIzkMP7WQz1BLAH6uT0cIoHJwOwgx9TcZgNT3edTgXeDGEuTc+ufnwHWqOrDPoda+30nuSUHRKQtcAZO+8s84GL3tFZ336r6e1VNUdWeOP+fP1PVn9DK7xtARGJEJK7uOXAmsJLD+FsP+ZHUInIOTp1lOPCsqt4f5JACRkReA8biTAGcC/wZmAW8AaThTJd+qarWb8husUTkJGAh8D0/1knfidMO0Zrv+xicBslwnC+Cb6jqPSLSG+ebdSdgGXCFqlYFL9LAcauYblfVCaFw3+49vuNutgFeVdX7RSSBQ/xbD/kEYYwxxr9Qr2IyxhjTAEsQxhhj/LIEYYwxxi9LEMYYY/yyBGGMMcYvSxDGHICI1LqzY9Y9mmxiPxHp6Tu7rjFHEptqw5gDq1DVYcEOwpjmZiUIYw6RO/f+39z59xeLSF93f08R+UxEVojIXBFJc/d3EZF33DUavhORE92XCheRp9x1Gz52Rz4jIr9017FYISIzg3SbJoRZgjDmwNrWq2K6zOdYsaoeDTyOMyIf4DHgBVU9BngFeNTd/yjwubtGw3Bglbu/H/CEqg4BdgEXufvvAI51X+eGQN2cMQ2xkdTGHICIlKlqrJ/9m3EW5cl0JwTcoaoJIlIAJKtqjbs/R1UTRSQfSPGd4sGdgvwTdzEXROR3QISq3ici/wPKcKZDmeWzvoMxzcJKEMYcHm3g+cHwnROolh/bBs/FWfFwOLDEZzZSY5qFJQhjDs9lPj+/dp9/hTOTKMBPcCYLBGe5xxthz2I+7Rt6UREJA1JVdR7wO6A9sE8pxphAsm8kxhxYW3dltjr/U9W6rq4dRWQFTilgirvvF8BzIvIbIB+42t1/CzBDRH6KU1K4EcjBv3DgZTeJCPCou66DMc3G2iCMOURuG0S6qhYEOxZjAsGqmIwxxvhlJQhjjDF+WQnCGGOMX5YgjDHG+GUJwhhjjF+WIIwxxvhlCcIYY4xf/w8CU3s4dzuMewAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCCs-rNA3FJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bb7f5fdf-4151-4f24-8fb6-f21e679a03b6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(model.history.history[\"loss\"])\n",
        "plt.plot(model.history.history[\"val_loss\"])\n",
        "plt.title(\"Model Loss Cifar 10\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend([\"Train\", \"Validation\"], loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ia7UaAo3hL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "\n",
        "iris_data.data.shape\n",
        "iris_data.target.shape\n",
        "\n",
        "x = iris_data.data\n",
        "y1 = iris_data.target.reshape(-1, 1)\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y  = encoder.fit_transform(y1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsH2nbnw5aL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8c44741-a787-419d-dd60-2d9ea02ef69b"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7OowZq65PsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A simple logistic regression\n",
        "model = Sequential()\n",
        "#creation of first hidden layer with 10 nodes and sigmoid activation \n",
        "# Z[1] = W[1]X + b\n",
        "# A[1] = sigmoid(Z[1])\n",
        "model.add(Dense(units=200, activation='sigmoid', input_dim=4))\n",
        "model.add(Dense(units=3, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn67QA8N5wQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86634bce-f1d2-4470-cb0c-b20266652268"
      },
      "source": [
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(X_train,y_train, epochs=1000, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 96 samples, validate on 24 samples\n",
            "Epoch 1/1000\n",
            "96/96 [==============================] - 0s 679us/step - loss: 0.9870 - accuracy: 0.5417 - val_loss: 0.9963 - val_accuracy: 0.4583\n",
            "Epoch 2/1000\n",
            "96/96 [==============================] - 0s 77us/step - loss: 0.9835 - accuracy: 0.6875 - val_loss: 0.9929 - val_accuracy: 0.5000\n",
            "Epoch 3/1000\n",
            "96/96 [==============================] - 0s 76us/step - loss: 0.9838 - accuracy: 0.4375 - val_loss: 0.9900 - val_accuracy: 0.5000\n",
            "Epoch 4/1000\n",
            "96/96 [==============================] - 0s 73us/step - loss: 0.9813 - accuracy: 0.6875 - val_loss: 0.9863 - val_accuracy: 0.5000\n",
            "Epoch 5/1000\n",
            "96/96 [==============================] - 0s 73us/step - loss: 0.9753 - accuracy: 0.5938 - val_loss: 0.9831 - val_accuracy: 0.5000\n",
            "Epoch 6/1000\n",
            "96/96 [==============================] - 0s 73us/step - loss: 0.9736 - accuracy: 0.6875 - val_loss: 0.9799 - val_accuracy: 0.5000\n",
            "Epoch 7/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.9721 - accuracy: 0.6667 - val_loss: 0.9777 - val_accuracy: 0.5000\n",
            "Epoch 8/1000\n",
            "96/96 [==============================] - 0s 77us/step - loss: 0.9686 - accuracy: 0.6667 - val_loss: 0.9726 - val_accuracy: 0.5000\n",
            "Epoch 9/1000\n",
            "96/96 [==============================] - 0s 80us/step - loss: 0.9629 - accuracy: 0.6875 - val_loss: 0.9700 - val_accuracy: 0.5000\n",
            "Epoch 10/1000\n",
            "96/96 [==============================] - 0s 80us/step - loss: 0.9597 - accuracy: 0.6875 - val_loss: 0.9669 - val_accuracy: 0.5000\n",
            "Epoch 11/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.9584 - accuracy: 0.6771 - val_loss: 0.9639 - val_accuracy: 0.5000\n",
            "Epoch 12/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.9580 - accuracy: 0.6979 - val_loss: 0.9605 - val_accuracy: 0.5000\n",
            "Epoch 13/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.9501 - accuracy: 0.6875 - val_loss: 0.9564 - val_accuracy: 0.5000\n",
            "Epoch 14/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.9483 - accuracy: 0.6875 - val_loss: 0.9538 - val_accuracy: 0.5000\n",
            "Epoch 15/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.9439 - accuracy: 0.6875 - val_loss: 0.9509 - val_accuracy: 0.5000\n",
            "Epoch 16/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.9425 - accuracy: 0.6875 - val_loss: 0.9477 - val_accuracy: 0.5000\n",
            "Epoch 17/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.9379 - accuracy: 0.6875 - val_loss: 0.9437 - val_accuracy: 0.5000\n",
            "Epoch 18/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.9347 - accuracy: 0.6875 - val_loss: 0.9408 - val_accuracy: 0.5000\n",
            "Epoch 19/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.9317 - accuracy: 0.6979 - val_loss: 0.9379 - val_accuracy: 0.5000\n",
            "Epoch 20/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.9276 - accuracy: 0.6875 - val_loss: 0.9338 - val_accuracy: 0.5000\n",
            "Epoch 21/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.9260 - accuracy: 0.7292 - val_loss: 0.9304 - val_accuracy: 0.5000\n",
            "Epoch 22/1000\n",
            "96/96 [==============================] - 0s 121us/step - loss: 0.9238 - accuracy: 0.7083 - val_loss: 0.9265 - val_accuracy: 0.5000\n",
            "Epoch 23/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.9177 - accuracy: 0.7292 - val_loss: 0.9235 - val_accuracy: 0.5000\n",
            "Epoch 24/1000\n",
            "96/96 [==============================] - 0s 121us/step - loss: 0.9153 - accuracy: 0.7396 - val_loss: 0.9208 - val_accuracy: 0.5000\n",
            "Epoch 25/1000\n",
            "96/96 [==============================] - 0s 120us/step - loss: 0.9120 - accuracy: 0.7292 - val_loss: 0.9172 - val_accuracy: 0.5000\n",
            "Epoch 26/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.9090 - accuracy: 0.7188 - val_loss: 0.9139 - val_accuracy: 0.5000\n",
            "Epoch 27/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.9052 - accuracy: 0.7188 - val_loss: 0.9107 - val_accuracy: 0.5000\n",
            "Epoch 28/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.9041 - accuracy: 0.6979 - val_loss: 0.9047 - val_accuracy: 0.5000\n",
            "Epoch 29/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.8976 - accuracy: 0.7500 - val_loss: 0.9018 - val_accuracy: 0.5000\n",
            "Epoch 30/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.8957 - accuracy: 0.7188 - val_loss: 0.8976 - val_accuracy: 0.5417\n",
            "Epoch 31/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.8916 - accuracy: 0.7917 - val_loss: 0.8957 - val_accuracy: 0.5000\n",
            "Epoch 32/1000\n",
            "96/96 [==============================] - 0s 119us/step - loss: 0.8879 - accuracy: 0.7396 - val_loss: 0.8918 - val_accuracy: 0.5417\n",
            "Epoch 33/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.8842 - accuracy: 0.7188 - val_loss: 0.8867 - val_accuracy: 0.6250\n",
            "Epoch 34/1000\n",
            "96/96 [==============================] - 0s 130us/step - loss: 0.8815 - accuracy: 0.7396 - val_loss: 0.8830 - val_accuracy: 0.7083\n",
            "Epoch 35/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.8771 - accuracy: 0.7500 - val_loss: 0.8790 - val_accuracy: 0.7083\n",
            "Epoch 36/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.8742 - accuracy: 0.8125 - val_loss: 0.8770 - val_accuracy: 0.7083\n",
            "Epoch 37/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.8746 - accuracy: 0.8021 - val_loss: 0.8750 - val_accuracy: 0.5833\n",
            "Epoch 38/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.8687 - accuracy: 0.8021 - val_loss: 0.8728 - val_accuracy: 0.5417\n",
            "Epoch 39/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.8644 - accuracy: 0.7396 - val_loss: 0.8679 - val_accuracy: 0.7083\n",
            "Epoch 40/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.8625 - accuracy: 0.7292 - val_loss: 0.8621 - val_accuracy: 0.7083\n",
            "Epoch 41/1000\n",
            "96/96 [==============================] - 0s 122us/step - loss: 0.8574 - accuracy: 0.7812 - val_loss: 0.8587 - val_accuracy: 0.7083\n",
            "Epoch 42/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.8547 - accuracy: 0.8542 - val_loss: 0.8570 - val_accuracy: 0.7083\n",
            "Epoch 43/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.8526 - accuracy: 0.8125 - val_loss: 0.8539 - val_accuracy: 0.7083\n",
            "Epoch 44/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.8479 - accuracy: 0.7917 - val_loss: 0.8501 - val_accuracy: 0.7083\n",
            "Epoch 45/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.8452 - accuracy: 0.8438 - val_loss: 0.8477 - val_accuracy: 0.7083\n",
            "Epoch 46/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.8443 - accuracy: 0.7812 - val_loss: 0.8444 - val_accuracy: 0.7083\n",
            "Epoch 47/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.8386 - accuracy: 0.8333 - val_loss: 0.8422 - val_accuracy: 0.7083\n",
            "Epoch 48/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.8355 - accuracy: 0.7708 - val_loss: 0.8374 - val_accuracy: 0.7500\n",
            "Epoch 49/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.8354 - accuracy: 0.8438 - val_loss: 0.8359 - val_accuracy: 0.7083\n",
            "Epoch 50/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.8304 - accuracy: 0.7812 - val_loss: 0.8309 - val_accuracy: 0.7917\n",
            "Epoch 51/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.8255 - accuracy: 0.7917 - val_loss: 0.8272 - val_accuracy: 0.8333\n",
            "Epoch 52/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.8242 - accuracy: 0.8438 - val_loss: 0.8266 - val_accuracy: 0.7083\n",
            "Epoch 53/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.8233 - accuracy: 0.7604 - val_loss: 0.8193 - val_accuracy: 0.8750\n",
            "Epoch 54/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.8161 - accuracy: 0.8438 - val_loss: 0.8161 - val_accuracy: 0.8750\n",
            "Epoch 55/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.8138 - accuracy: 0.8021 - val_loss: 0.8122 - val_accuracy: 0.8750\n",
            "Epoch 56/1000\n",
            "96/96 [==============================] - 0s 80us/step - loss: 0.8134 - accuracy: 0.8229 - val_loss: 0.8078 - val_accuracy: 0.8750\n",
            "Epoch 57/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.8158 - accuracy: 0.7708 - val_loss: 0.8030 - val_accuracy: 0.9167\n",
            "Epoch 58/1000\n",
            "96/96 [==============================] - 0s 84us/step - loss: 0.8078 - accuracy: 0.8021 - val_loss: 0.7980 - val_accuracy: 0.9167\n",
            "Epoch 59/1000\n",
            "96/96 [==============================] - 0s 77us/step - loss: 0.8026 - accuracy: 0.9479 - val_loss: 0.7992 - val_accuracy: 0.8750\n",
            "Epoch 60/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.8024 - accuracy: 0.7604 - val_loss: 0.7937 - val_accuracy: 0.9167\n",
            "Epoch 61/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.7954 - accuracy: 0.9062 - val_loss: 0.7913 - val_accuracy: 0.9167\n",
            "Epoch 62/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.7950 - accuracy: 0.8750 - val_loss: 0.7919 - val_accuracy: 0.8750\n",
            "Epoch 63/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.7888 - accuracy: 0.8958 - val_loss: 0.7893 - val_accuracy: 0.8750\n",
            "Epoch 64/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.7871 - accuracy: 0.9271 - val_loss: 0.7879 - val_accuracy: 0.8750\n",
            "Epoch 65/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.7840 - accuracy: 0.8438 - val_loss: 0.7836 - val_accuracy: 0.8750\n",
            "Epoch 66/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.7832 - accuracy: 0.8438 - val_loss: 0.7793 - val_accuracy: 0.9167\n",
            "Epoch 67/1000\n",
            "96/96 [==============================] - 0s 115us/step - loss: 0.7805 - accuracy: 0.8854 - val_loss: 0.7761 - val_accuracy: 0.9583\n",
            "Epoch 68/1000\n",
            "96/96 [==============================] - 0s 115us/step - loss: 0.7750 - accuracy: 0.9167 - val_loss: 0.7739 - val_accuracy: 0.9583\n",
            "Epoch 69/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.7726 - accuracy: 0.8854 - val_loss: 0.7709 - val_accuracy: 0.9583\n",
            "Epoch 70/1000\n",
            "96/96 [==============================] - 0s 144us/step - loss: 0.7694 - accuracy: 0.9583 - val_loss: 0.7701 - val_accuracy: 0.8750\n",
            "Epoch 71/1000\n",
            "96/96 [==============================] - 0s 145us/step - loss: 0.7736 - accuracy: 0.8958 - val_loss: 0.7709 - val_accuracy: 0.8750\n",
            "Epoch 72/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.7712 - accuracy: 0.7604 - val_loss: 0.7628 - val_accuracy: 0.9583\n",
            "Epoch 73/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.7635 - accuracy: 0.9062 - val_loss: 0.7621 - val_accuracy: 0.8750\n",
            "Epoch 74/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.7612 - accuracy: 0.9375 - val_loss: 0.7617 - val_accuracy: 0.8750\n",
            "Epoch 75/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.7574 - accuracy: 0.8646 - val_loss: 0.7569 - val_accuracy: 0.8750\n",
            "Epoch 76/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.7537 - accuracy: 0.9271 - val_loss: 0.7554 - val_accuracy: 0.8750\n",
            "Epoch 77/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.7537 - accuracy: 0.9062 - val_loss: 0.7552 - val_accuracy: 0.8750\n",
            "Epoch 78/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.7494 - accuracy: 0.8958 - val_loss: 0.7513 - val_accuracy: 0.8750\n",
            "Epoch 79/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.7456 - accuracy: 0.8646 - val_loss: 0.7474 - val_accuracy: 0.8750\n",
            "Epoch 80/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.7446 - accuracy: 0.8542 - val_loss: 0.7421 - val_accuracy: 0.9583\n",
            "Epoch 81/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.7405 - accuracy: 0.9271 - val_loss: 0.7402 - val_accuracy: 0.9583\n",
            "Epoch 82/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.7387 - accuracy: 0.9375 - val_loss: 0.7397 - val_accuracy: 0.9167\n",
            "Epoch 83/1000\n",
            "96/96 [==============================] - 0s 136us/step - loss: 0.7354 - accuracy: 0.9583 - val_loss: 0.7385 - val_accuracy: 0.8750\n",
            "Epoch 84/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.7347 - accuracy: 0.8750 - val_loss: 0.7341 - val_accuracy: 0.9583\n",
            "Epoch 85/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.7328 - accuracy: 0.9375 - val_loss: 0.7350 - val_accuracy: 0.8750\n",
            "Epoch 86/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.7307 - accuracy: 0.8958 - val_loss: 0.7329 - val_accuracy: 0.8750\n",
            "Epoch 87/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.7312 - accuracy: 0.9062 - val_loss: 0.7334 - val_accuracy: 0.8750\n",
            "Epoch 88/1000\n",
            "96/96 [==============================] - 0s 80us/step - loss: 0.7264 - accuracy: 0.8542 - val_loss: 0.7277 - val_accuracy: 0.8750\n",
            "Epoch 89/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.7214 - accuracy: 0.9167 - val_loss: 0.7258 - val_accuracy: 0.8750\n",
            "Epoch 90/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.7201 - accuracy: 0.9583 - val_loss: 0.7252 - val_accuracy: 0.8750\n",
            "Epoch 91/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.7168 - accuracy: 0.8958 - val_loss: 0.7200 - val_accuracy: 0.8750\n",
            "Epoch 92/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.7148 - accuracy: 0.8646 - val_loss: 0.7154 - val_accuracy: 0.9583\n",
            "Epoch 93/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.7168 - accuracy: 0.8021 - val_loss: 0.7078 - val_accuracy: 0.9583\n",
            "Epoch 94/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.7139 - accuracy: 0.9062 - val_loss: 0.7120 - val_accuracy: 0.9583\n",
            "Epoch 95/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.7078 - accuracy: 0.9167 - val_loss: 0.7089 - val_accuracy: 0.9583\n",
            "Epoch 96/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.7044 - accuracy: 0.9479 - val_loss: 0.7073 - val_accuracy: 0.9583\n",
            "Epoch 97/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.7050 - accuracy: 0.9583 - val_loss: 0.7079 - val_accuracy: 0.8750\n",
            "Epoch 98/1000\n",
            "96/96 [==============================] - 0s 115us/step - loss: 0.7032 - accuracy: 0.8021 - val_loss: 0.7000 - val_accuracy: 0.9167\n",
            "Epoch 99/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.6989 - accuracy: 0.9583 - val_loss: 0.7014 - val_accuracy: 0.9583\n",
            "Epoch 100/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.6965 - accuracy: 0.9479 - val_loss: 0.7009 - val_accuracy: 0.9167\n",
            "Epoch 101/1000\n",
            "96/96 [==============================] - 0s 76us/step - loss: 0.6962 - accuracy: 0.9583 - val_loss: 0.7003 - val_accuracy: 0.8750\n",
            "Epoch 102/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.6949 - accuracy: 0.8646 - val_loss: 0.6954 - val_accuracy: 0.9583\n",
            "Epoch 103/1000\n",
            "96/96 [==============================] - 0s 148us/step - loss: 0.6926 - accuracy: 0.8438 - val_loss: 0.6888 - val_accuracy: 0.9167\n",
            "Epoch 104/1000\n",
            "96/96 [==============================] - 0s 119us/step - loss: 0.6884 - accuracy: 0.9479 - val_loss: 0.6894 - val_accuracy: 0.9167\n",
            "Epoch 105/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.6864 - accuracy: 0.9688 - val_loss: 0.6888 - val_accuracy: 0.9583\n",
            "Epoch 106/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.6848 - accuracy: 0.9375 - val_loss: 0.6857 - val_accuracy: 0.9167\n",
            "Epoch 107/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.6818 - accuracy: 0.9375 - val_loss: 0.6830 - val_accuracy: 0.9167\n",
            "Epoch 108/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.6864 - accuracy: 0.8854 - val_loss: 0.6815 - val_accuracy: 0.9167\n",
            "Epoch 109/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.6781 - accuracy: 0.9271 - val_loss: 0.6801 - val_accuracy: 0.9167\n",
            "Epoch 110/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.6806 - accuracy: 0.8958 - val_loss: 0.6803 - val_accuracy: 0.9583\n",
            "Epoch 111/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.6759 - accuracy: 0.9271 - val_loss: 0.6804 - val_accuracy: 0.8750\n",
            "Epoch 112/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.6714 - accuracy: 0.9062 - val_loss: 0.6763 - val_accuracy: 0.9583\n",
            "Epoch 113/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.6710 - accuracy: 0.9271 - val_loss: 0.6738 - val_accuracy: 0.9583\n",
            "Epoch 114/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.6672 - accuracy: 0.9271 - val_loss: 0.6707 - val_accuracy: 0.9167\n",
            "Epoch 115/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.6673 - accuracy: 0.9375 - val_loss: 0.6674 - val_accuracy: 0.9167\n",
            "Epoch 116/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.6664 - accuracy: 0.9479 - val_loss: 0.6703 - val_accuracy: 0.9583\n",
            "Epoch 117/1000\n",
            "96/96 [==============================] - 0s 75us/step - loss: 0.6624 - accuracy: 0.8854 - val_loss: 0.6647 - val_accuracy: 0.9167\n",
            "Epoch 118/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.6597 - accuracy: 0.9583 - val_loss: 0.6626 - val_accuracy: 0.9167\n",
            "Epoch 119/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.6587 - accuracy: 0.9375 - val_loss: 0.6594 - val_accuracy: 0.9167\n",
            "Epoch 120/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.6584 - accuracy: 0.9375 - val_loss: 0.6573 - val_accuracy: 0.9167\n",
            "Epoch 121/1000\n",
            "96/96 [==============================] - 0s 81us/step - loss: 0.6552 - accuracy: 0.9583 - val_loss: 0.6548 - val_accuracy: 0.9583\n",
            "Epoch 122/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.6565 - accuracy: 0.9375 - val_loss: 0.6519 - val_accuracy: 0.9583\n",
            "Epoch 123/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.6507 - accuracy: 0.9792 - val_loss: 0.6516 - val_accuracy: 0.9583\n",
            "Epoch 124/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.6500 - accuracy: 0.9583 - val_loss: 0.6515 - val_accuracy: 0.9167\n",
            "Epoch 125/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.6471 - accuracy: 0.9375 - val_loss: 0.6492 - val_accuracy: 0.9167\n",
            "Epoch 126/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.6456 - accuracy: 0.9479 - val_loss: 0.6492 - val_accuracy: 0.9167\n",
            "Epoch 127/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.6441 - accuracy: 0.9375 - val_loss: 0.6460 - val_accuracy: 0.9167\n",
            "Epoch 128/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.6426 - accuracy: 0.9375 - val_loss: 0.6456 - val_accuracy: 0.9167\n",
            "Epoch 129/1000\n",
            "96/96 [==============================] - 0s 81us/step - loss: 0.6408 - accuracy: 0.9583 - val_loss: 0.6454 - val_accuracy: 0.9167\n",
            "Epoch 130/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.6387 - accuracy: 0.9167 - val_loss: 0.6426 - val_accuracy: 0.9167\n",
            "Epoch 131/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.6366 - accuracy: 0.9583 - val_loss: 0.6409 - val_accuracy: 0.9167\n",
            "Epoch 132/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.6370 - accuracy: 0.9583 - val_loss: 0.6427 - val_accuracy: 0.9583\n",
            "Epoch 133/1000\n",
            "96/96 [==============================] - 0s 77us/step - loss: 0.6348 - accuracy: 0.8958 - val_loss: 0.6370 - val_accuracy: 0.9167\n",
            "Epoch 134/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.6323 - accuracy: 0.9688 - val_loss: 0.6379 - val_accuracy: 0.9583\n",
            "Epoch 135/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.6309 - accuracy: 0.9271 - val_loss: 0.6352 - val_accuracy: 0.9167\n",
            "Epoch 136/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.6290 - accuracy: 0.9375 - val_loss: 0.6344 - val_accuracy: 0.9167\n",
            "Epoch 137/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.6280 - accuracy: 0.9062 - val_loss: 0.6297 - val_accuracy: 0.9583\n",
            "Epoch 138/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.6265 - accuracy: 0.9375 - val_loss: 0.6282 - val_accuracy: 0.9583\n",
            "Epoch 139/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.6242 - accuracy: 0.9583 - val_loss: 0.6275 - val_accuracy: 0.9167\n",
            "Epoch 140/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.6253 - accuracy: 0.9271 - val_loss: 0.6311 - val_accuracy: 0.9583\n",
            "Epoch 141/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.6207 - accuracy: 0.9271 - val_loss: 0.6276 - val_accuracy: 0.9583\n",
            "Epoch 142/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.6194 - accuracy: 0.9583 - val_loss: 0.6268 - val_accuracy: 0.9583\n",
            "Epoch 143/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.6176 - accuracy: 0.9479 - val_loss: 0.6253 - val_accuracy: 0.9583\n",
            "Epoch 144/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.6181 - accuracy: 0.9271 - val_loss: 0.6249 - val_accuracy: 0.9583\n",
            "Epoch 145/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.6166 - accuracy: 0.9167 - val_loss: 0.6217 - val_accuracy: 0.9167\n",
            "Epoch 146/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.6162 - accuracy: 0.9375 - val_loss: 0.6242 - val_accuracy: 0.9583\n",
            "Epoch 147/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.6128 - accuracy: 0.9375 - val_loss: 0.6205 - val_accuracy: 0.9583\n",
            "Epoch 148/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.6121 - accuracy: 0.8958 - val_loss: 0.6138 - val_accuracy: 0.9583\n",
            "Epoch 149/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.6100 - accuracy: 0.9583 - val_loss: 0.6143 - val_accuracy: 0.9167\n",
            "Epoch 150/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.6095 - accuracy: 0.8958 - val_loss: 0.6096 - val_accuracy: 0.9583\n",
            "Epoch 151/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.6074 - accuracy: 0.9375 - val_loss: 0.6069 - val_accuracy: 0.9583\n",
            "Epoch 152/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.6046 - accuracy: 0.9688 - val_loss: 0.6086 - val_accuracy: 0.9583\n",
            "Epoch 153/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.6066 - accuracy: 0.8854 - val_loss: 0.6038 - val_accuracy: 0.9583\n",
            "Epoch 154/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.6019 - accuracy: 0.9792 - val_loss: 0.6050 - val_accuracy: 0.9583\n",
            "Epoch 155/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.6030 - accuracy: 0.9479 - val_loss: 0.6072 - val_accuracy: 0.9167\n",
            "Epoch 156/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.5985 - accuracy: 0.9688 - val_loss: 0.6060 - val_accuracy: 0.9167\n",
            "Epoch 157/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.5990 - accuracy: 0.9479 - val_loss: 0.6053 - val_accuracy: 0.9167\n",
            "Epoch 158/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.5958 - accuracy: 0.9583 - val_loss: 0.6026 - val_accuracy: 0.9167\n",
            "Epoch 159/1000\n",
            "96/96 [==============================] - 0s 170us/step - loss: 0.5955 - accuracy: 0.8958 - val_loss: 0.5991 - val_accuracy: 0.9583\n",
            "Epoch 160/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.5956 - accuracy: 0.9375 - val_loss: 0.6032 - val_accuracy: 0.9583\n",
            "Epoch 161/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.5930 - accuracy: 0.9375 - val_loss: 0.5981 - val_accuracy: 0.9167\n",
            "Epoch 162/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.5905 - accuracy: 0.9792 - val_loss: 0.5990 - val_accuracy: 0.9167\n",
            "Epoch 163/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.5906 - accuracy: 0.9375 - val_loss: 0.5977 - val_accuracy: 0.9167\n",
            "Epoch 164/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.5890 - accuracy: 0.9167 - val_loss: 0.5925 - val_accuracy: 0.9583\n",
            "Epoch 165/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.5870 - accuracy: 0.9375 - val_loss: 0.5901 - val_accuracy: 0.9583\n",
            "Epoch 166/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.5888 - accuracy: 0.9271 - val_loss: 0.5861 - val_accuracy: 0.9583\n",
            "Epoch 167/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.5870 - accuracy: 0.9271 - val_loss: 0.5841 - val_accuracy: 0.9583\n",
            "Epoch 168/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.5843 - accuracy: 0.9375 - val_loss: 0.5877 - val_accuracy: 0.9583\n",
            "Epoch 169/1000\n",
            "96/96 [==============================] - 0s 81us/step - loss: 0.5811 - accuracy: 0.9583 - val_loss: 0.5864 - val_accuracy: 0.9583\n",
            "Epoch 170/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.5800 - accuracy: 0.9688 - val_loss: 0.5861 - val_accuracy: 0.9583\n",
            "Epoch 171/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.5787 - accuracy: 0.9583 - val_loss: 0.5851 - val_accuracy: 0.9583\n",
            "Epoch 172/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.5798 - accuracy: 0.9583 - val_loss: 0.5830 - val_accuracy: 0.9583\n",
            "Epoch 173/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.5774 - accuracy: 0.9479 - val_loss: 0.5844 - val_accuracy: 0.9167\n",
            "Epoch 174/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.5758 - accuracy: 0.9479 - val_loss: 0.5843 - val_accuracy: 0.9167\n",
            "Epoch 175/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.5800 - accuracy: 0.9479 - val_loss: 0.5840 - val_accuracy: 0.9583\n",
            "Epoch 176/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.5743 - accuracy: 0.9479 - val_loss: 0.5829 - val_accuracy: 0.9583\n",
            "Epoch 177/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.5718 - accuracy: 0.9583 - val_loss: 0.5817 - val_accuracy: 0.9167\n",
            "Epoch 178/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.5705 - accuracy: 0.9688 - val_loss: 0.5815 - val_accuracy: 0.9583\n",
            "Epoch 179/1000\n",
            "96/96 [==============================] - 0s 77us/step - loss: 0.5693 - accuracy: 0.9688 - val_loss: 0.5805 - val_accuracy: 0.9583\n",
            "Epoch 180/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.5683 - accuracy: 0.9479 - val_loss: 0.5762 - val_accuracy: 0.9167\n",
            "Epoch 181/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.5670 - accuracy: 0.9792 - val_loss: 0.5772 - val_accuracy: 0.9167\n",
            "Epoch 182/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.5658 - accuracy: 0.9583 - val_loss: 0.5747 - val_accuracy: 0.9167\n",
            "Epoch 183/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.5685 - accuracy: 0.8958 - val_loss: 0.5679 - val_accuracy: 0.9583\n",
            "Epoch 184/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.5639 - accuracy: 0.9375 - val_loss: 0.5670 - val_accuracy: 0.9583\n",
            "Epoch 185/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.5626 - accuracy: 0.9688 - val_loss: 0.5703 - val_accuracy: 0.9167\n",
            "Epoch 186/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.5610 - accuracy: 0.9688 - val_loss: 0.5692 - val_accuracy: 0.9583\n",
            "Epoch 187/1000\n",
            "96/96 [==============================] - 0s 77us/step - loss: 0.5621 - accuracy: 0.9479 - val_loss: 0.5652 - val_accuracy: 0.9583\n",
            "Epoch 188/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.5599 - accuracy: 0.9479 - val_loss: 0.5657 - val_accuracy: 0.9583\n",
            "Epoch 189/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.5592 - accuracy: 0.9583 - val_loss: 0.5683 - val_accuracy: 0.9167\n",
            "Epoch 190/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.5567 - accuracy: 0.9688 - val_loss: 0.5680 - val_accuracy: 0.9583\n",
            "Epoch 191/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.5549 - accuracy: 0.9583 - val_loss: 0.5653 - val_accuracy: 0.9167\n",
            "Epoch 192/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.5550 - accuracy: 0.9583 - val_loss: 0.5645 - val_accuracy: 0.9167\n",
            "Epoch 193/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.5529 - accuracy: 0.9688 - val_loss: 0.5638 - val_accuracy: 0.9167\n",
            "Epoch 194/1000\n",
            "96/96 [==============================] - 0s 76us/step - loss: 0.5542 - accuracy: 0.9271 - val_loss: 0.5654 - val_accuracy: 0.9583\n",
            "Epoch 195/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.5522 - accuracy: 0.9479 - val_loss: 0.5625 - val_accuracy: 0.9167\n",
            "Epoch 196/1000\n",
            "96/96 [==============================] - 0s 124us/step - loss: 0.5499 - accuracy: 0.9688 - val_loss: 0.5595 - val_accuracy: 0.9167\n",
            "Epoch 197/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.5495 - accuracy: 0.9583 - val_loss: 0.5603 - val_accuracy: 0.9167\n",
            "Epoch 198/1000\n",
            "96/96 [==============================] - 0s 135us/step - loss: 0.5496 - accuracy: 0.9271 - val_loss: 0.5558 - val_accuracy: 0.9583\n",
            "Epoch 199/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.5495 - accuracy: 0.9479 - val_loss: 0.5594 - val_accuracy: 0.9583\n",
            "Epoch 200/1000\n",
            "96/96 [==============================] - 0s 125us/step - loss: 0.5460 - accuracy: 0.9792 - val_loss: 0.5580 - val_accuracy: 0.9583\n",
            "Epoch 201/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.5523 - accuracy: 0.9271 - val_loss: 0.5606 - val_accuracy: 0.9583\n",
            "Epoch 202/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.5470 - accuracy: 0.8958 - val_loss: 0.5523 - val_accuracy: 0.9583\n",
            "Epoch 203/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.5426 - accuracy: 0.9792 - val_loss: 0.5537 - val_accuracy: 0.9167\n",
            "Epoch 204/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.5430 - accuracy: 0.9375 - val_loss: 0.5531 - val_accuracy: 0.9167\n",
            "Epoch 205/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.5434 - accuracy: 0.9167 - val_loss: 0.5477 - val_accuracy: 0.9583\n",
            "Epoch 206/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.5484 - accuracy: 0.9271 - val_loss: 0.5480 - val_accuracy: 0.9583\n",
            "Epoch 207/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.5382 - accuracy: 0.9688 - val_loss: 0.5481 - val_accuracy: 0.9583\n",
            "Epoch 208/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.5371 - accuracy: 0.9688 - val_loss: 0.5480 - val_accuracy: 0.9167\n",
            "Epoch 209/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.5369 - accuracy: 0.9375 - val_loss: 0.5452 - val_accuracy: 0.9583\n",
            "Epoch 210/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.5351 - accuracy: 0.9792 - val_loss: 0.5456 - val_accuracy: 0.9583\n",
            "Epoch 211/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.5346 - accuracy: 0.9688 - val_loss: 0.5437 - val_accuracy: 0.9583\n",
            "Epoch 212/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.5351 - accuracy: 0.9583 - val_loss: 0.5470 - val_accuracy: 0.9583\n",
            "Epoch 213/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.5330 - accuracy: 0.9688 - val_loss: 0.5446 - val_accuracy: 0.9167\n",
            "Epoch 214/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.5332 - accuracy: 0.9479 - val_loss: 0.5409 - val_accuracy: 0.9583\n",
            "Epoch 215/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.5347 - accuracy: 0.9688 - val_loss: 0.5417 - val_accuracy: 0.9583\n",
            "Epoch 216/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.5305 - accuracy: 0.9375 - val_loss: 0.5382 - val_accuracy: 0.9583\n",
            "Epoch 217/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.5297 - accuracy: 0.9375 - val_loss: 0.5361 - val_accuracy: 0.9583\n",
            "Epoch 218/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.5321 - accuracy: 0.9271 - val_loss: 0.5418 - val_accuracy: 0.9583\n",
            "Epoch 219/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.5271 - accuracy: 0.9479 - val_loss: 0.5390 - val_accuracy: 0.9167\n",
            "Epoch 220/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.5262 - accuracy: 0.9583 - val_loss: 0.5365 - val_accuracy: 0.9583\n",
            "Epoch 221/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.5262 - accuracy: 0.9583 - val_loss: 0.5337 - val_accuracy: 0.9583\n",
            "Epoch 222/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.5276 - accuracy: 0.9375 - val_loss: 0.5380 - val_accuracy: 0.9583\n",
            "Epoch 223/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.5228 - accuracy: 0.9479 - val_loss: 0.5364 - val_accuracy: 0.9167\n",
            "Epoch 224/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.5222 - accuracy: 0.9583 - val_loss: 0.5356 - val_accuracy: 0.9167\n",
            "Epoch 225/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.5223 - accuracy: 0.9688 - val_loss: 0.5356 - val_accuracy: 0.9583\n",
            "Epoch 226/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.5200 - accuracy: 0.9479 - val_loss: 0.5336 - val_accuracy: 0.9167\n",
            "Epoch 227/1000\n",
            "96/96 [==============================] - 0s 150us/step - loss: 0.5199 - accuracy: 0.9792 - val_loss: 0.5340 - val_accuracy: 0.9583\n",
            "Epoch 228/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.5192 - accuracy: 0.9792 - val_loss: 0.5334 - val_accuracy: 0.9583\n",
            "Epoch 229/1000\n",
            "96/96 [==============================] - 0s 114us/step - loss: 0.5225 - accuracy: 0.9062 - val_loss: 0.5257 - val_accuracy: 0.9583\n",
            "Epoch 230/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.5177 - accuracy: 0.9688 - val_loss: 0.5261 - val_accuracy: 0.9583\n",
            "Epoch 231/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.5225 - accuracy: 0.9375 - val_loss: 0.5222 - val_accuracy: 0.9583\n",
            "Epoch 232/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.5172 - accuracy: 0.9583 - val_loss: 0.5232 - val_accuracy: 0.9583\n",
            "Epoch 233/1000\n",
            "96/96 [==============================] - 0s 116us/step - loss: 0.5155 - accuracy: 0.9583 - val_loss: 0.5215 - val_accuracy: 0.9583\n",
            "Epoch 234/1000\n",
            "96/96 [==============================] - 0s 76us/step - loss: 0.5140 - accuracy: 0.9688 - val_loss: 0.5210 - val_accuracy: 0.9583\n",
            "Epoch 235/1000\n",
            "96/96 [==============================] - 0s 75us/step - loss: 0.5127 - accuracy: 0.9688 - val_loss: 0.5239 - val_accuracy: 0.9583\n",
            "Epoch 236/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.5114 - accuracy: 0.9583 - val_loss: 0.5223 - val_accuracy: 0.9583\n",
            "Epoch 237/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.5108 - accuracy: 0.9688 - val_loss: 0.5237 - val_accuracy: 0.9167\n",
            "Epoch 238/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.5101 - accuracy: 0.9792 - val_loss: 0.5240 - val_accuracy: 0.9167\n",
            "Epoch 239/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.5089 - accuracy: 0.9375 - val_loss: 0.5213 - val_accuracy: 0.9583\n",
            "Epoch 240/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.5089 - accuracy: 0.9583 - val_loss: 0.5190 - val_accuracy: 0.9583\n",
            "Epoch 241/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.5088 - accuracy: 0.9688 - val_loss: 0.5182 - val_accuracy: 0.9583\n",
            "Epoch 242/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.5095 - accuracy: 0.9583 - val_loss: 0.5209 - val_accuracy: 0.9167\n",
            "Epoch 243/1000\n",
            "96/96 [==============================] - 0s 73us/step - loss: 0.5092 - accuracy: 0.9167 - val_loss: 0.5146 - val_accuracy: 0.9583\n",
            "Epoch 244/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.5047 - accuracy: 0.9792 - val_loss: 0.5155 - val_accuracy: 0.9583\n",
            "Epoch 245/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.5066 - accuracy: 0.9688 - val_loss: 0.5180 - val_accuracy: 0.9167\n",
            "Epoch 246/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.5041 - accuracy: 0.9271 - val_loss: 0.5148 - val_accuracy: 0.9583\n",
            "Epoch 247/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.5023 - accuracy: 0.9688 - val_loss: 0.5141 - val_accuracy: 0.9583\n",
            "Epoch 248/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.5014 - accuracy: 0.9688 - val_loss: 0.5133 - val_accuracy: 0.9583\n",
            "Epoch 249/1000\n",
            "96/96 [==============================] - 0s 126us/step - loss: 0.5011 - accuracy: 0.9792 - val_loss: 0.5149 - val_accuracy: 0.9167\n",
            "Epoch 250/1000\n",
            "96/96 [==============================] - 0s 163us/step - loss: 0.5023 - accuracy: 0.9583 - val_loss: 0.5135 - val_accuracy: 0.9583\n",
            "Epoch 251/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.5014 - accuracy: 0.9688 - val_loss: 0.5112 - val_accuracy: 0.9583\n",
            "Epoch 252/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.5022 - accuracy: 0.9583 - val_loss: 0.5131 - val_accuracy: 0.9167\n",
            "Epoch 253/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.5017 - accuracy: 0.9375 - val_loss: 0.5084 - val_accuracy: 0.9583\n",
            "Epoch 254/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.4975 - accuracy: 0.9792 - val_loss: 0.5082 - val_accuracy: 0.9583\n",
            "Epoch 255/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.4976 - accuracy: 0.9688 - val_loss: 0.5113 - val_accuracy: 0.9167\n",
            "Epoch 256/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.4961 - accuracy: 0.9688 - val_loss: 0.5117 - val_accuracy: 0.9583\n",
            "Epoch 257/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.4970 - accuracy: 0.9688 - val_loss: 0.5135 - val_accuracy: 0.9583\n",
            "Epoch 258/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.4939 - accuracy: 0.9688 - val_loss: 0.5099 - val_accuracy: 0.9583\n",
            "Epoch 259/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.4928 - accuracy: 0.9583 - val_loss: 0.5072 - val_accuracy: 0.9583\n",
            "Epoch 260/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.4925 - accuracy: 0.9375 - val_loss: 0.5043 - val_accuracy: 0.9583\n",
            "Epoch 261/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4940 - accuracy: 0.9583 - val_loss: 0.5031 - val_accuracy: 0.9583\n",
            "Epoch 262/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.4905 - accuracy: 0.9688 - val_loss: 0.5025 - val_accuracy: 0.9583\n",
            "Epoch 263/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.4914 - accuracy: 0.9792 - val_loss: 0.5022 - val_accuracy: 0.9583\n",
            "Epoch 264/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.4896 - accuracy: 0.9688 - val_loss: 0.5027 - val_accuracy: 0.9583\n",
            "Epoch 265/1000\n",
            "96/96 [==============================] - 0s 119us/step - loss: 0.4889 - accuracy: 0.9583 - val_loss: 0.5002 - val_accuracy: 0.9583\n",
            "Epoch 266/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.4891 - accuracy: 0.9792 - val_loss: 0.4985 - val_accuracy: 0.9583\n",
            "Epoch 267/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.4874 - accuracy: 0.9688 - val_loss: 0.4981 - val_accuracy: 0.9583\n",
            "Epoch 268/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.4864 - accuracy: 0.9583 - val_loss: 0.4970 - val_accuracy: 0.9583\n",
            "Epoch 269/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.4853 - accuracy: 0.9688 - val_loss: 0.4977 - val_accuracy: 0.9583\n",
            "Epoch 270/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.4855 - accuracy: 0.9583 - val_loss: 0.4954 - val_accuracy: 0.9583\n",
            "Epoch 271/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.4845 - accuracy: 0.9583 - val_loss: 0.4942 - val_accuracy: 0.9583\n",
            "Epoch 272/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.4863 - accuracy: 0.9583 - val_loss: 0.4994 - val_accuracy: 0.9167\n",
            "Epoch 273/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.4828 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.9583\n",
            "Epoch 274/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.4817 - accuracy: 0.9583 - val_loss: 0.4950 - val_accuracy: 0.9583\n",
            "Epoch 275/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.4827 - accuracy: 0.9792 - val_loss: 0.4955 - val_accuracy: 0.9583\n",
            "Epoch 276/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.4803 - accuracy: 0.9583 - val_loss: 0.4941 - val_accuracy: 0.9583\n",
            "Epoch 277/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.4801 - accuracy: 0.9583 - val_loss: 0.4929 - val_accuracy: 0.9583\n",
            "Epoch 278/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.4792 - accuracy: 0.9688 - val_loss: 0.4938 - val_accuracy: 0.9583\n",
            "Epoch 279/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.4790 - accuracy: 0.9583 - val_loss: 0.4922 - val_accuracy: 0.9583\n",
            "Epoch 280/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.4787 - accuracy: 0.9479 - val_loss: 0.4935 - val_accuracy: 0.9167\n",
            "Epoch 281/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4772 - accuracy: 0.9792 - val_loss: 0.4934 - val_accuracy: 0.9167\n",
            "Epoch 282/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.4771 - accuracy: 0.9688 - val_loss: 0.4944 - val_accuracy: 0.9583\n",
            "Epoch 283/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.4754 - accuracy: 0.9583 - val_loss: 0.4913 - val_accuracy: 0.9583\n",
            "Epoch 284/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.4756 - accuracy: 0.9688 - val_loss: 0.4908 - val_accuracy: 0.9583\n",
            "Epoch 285/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.4751 - accuracy: 0.9583 - val_loss: 0.4902 - val_accuracy: 0.9583\n",
            "Epoch 286/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4765 - accuracy: 0.9688 - val_loss: 0.4872 - val_accuracy: 0.9583\n",
            "Epoch 287/1000\n",
            "96/96 [==============================] - 0s 136us/step - loss: 0.4752 - accuracy: 0.9583 - val_loss: 0.4861 - val_accuracy: 0.9583\n",
            "Epoch 288/1000\n",
            "96/96 [==============================] - 0s 145us/step - loss: 0.4736 - accuracy: 0.9792 - val_loss: 0.4884 - val_accuracy: 0.9167\n",
            "Epoch 289/1000\n",
            "96/96 [==============================] - 0s 128us/step - loss: 0.4726 - accuracy: 0.9688 - val_loss: 0.4878 - val_accuracy: 0.9167\n",
            "Epoch 290/1000\n",
            "96/96 [==============================] - 0s 76us/step - loss: 0.4705 - accuracy: 0.9688 - val_loss: 0.4863 - val_accuracy: 0.9583\n",
            "Epoch 291/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.4759 - accuracy: 0.9479 - val_loss: 0.4857 - val_accuracy: 0.9583\n",
            "Epoch 292/1000\n",
            "96/96 [==============================] - 0s 114us/step - loss: 0.4721 - accuracy: 0.9375 - val_loss: 0.4808 - val_accuracy: 0.9583\n",
            "Epoch 293/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.4722 - accuracy: 0.9583 - val_loss: 0.4856 - val_accuracy: 0.9167\n",
            "Epoch 294/1000\n",
            "96/96 [==============================] - 0s 81us/step - loss: 0.4711 - accuracy: 0.9583 - val_loss: 0.4833 - val_accuracy: 0.9583\n",
            "Epoch 295/1000\n",
            "96/96 [==============================] - 0s 78us/step - loss: 0.4730 - accuracy: 0.9583 - val_loss: 0.4859 - val_accuracy: 0.9583\n",
            "Epoch 296/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.4666 - accuracy: 0.9479 - val_loss: 0.4843 - val_accuracy: 0.9167\n",
            "Epoch 297/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4701 - accuracy: 0.9583 - val_loss: 0.4795 - val_accuracy: 0.9583\n",
            "Epoch 298/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.4690 - accuracy: 0.9688 - val_loss: 0.4839 - val_accuracy: 0.9583\n",
            "Epoch 299/1000\n",
            "96/96 [==============================] - 0s 80us/step - loss: 0.4731 - accuracy: 0.9271 - val_loss: 0.4862 - val_accuracy: 0.9583\n",
            "Epoch 300/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.4645 - accuracy: 0.9688 - val_loss: 0.4823 - val_accuracy: 0.9583\n",
            "Epoch 301/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.4636 - accuracy: 0.9688 - val_loss: 0.4805 - val_accuracy: 0.9167\n",
            "Epoch 302/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4629 - accuracy: 0.9792 - val_loss: 0.4797 - val_accuracy: 0.9583\n",
            "Epoch 303/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.4629 - accuracy: 0.9583 - val_loss: 0.4764 - val_accuracy: 0.9583\n",
            "Epoch 304/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.4624 - accuracy: 0.9792 - val_loss: 0.4766 - val_accuracy: 0.9583\n",
            "Epoch 305/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.4610 - accuracy: 0.9479 - val_loss: 0.4748 - val_accuracy: 0.9583\n",
            "Epoch 306/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.4603 - accuracy: 0.9792 - val_loss: 0.4740 - val_accuracy: 0.9583\n",
            "Epoch 307/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.4606 - accuracy: 0.9792 - val_loss: 0.4733 - val_accuracy: 0.9583\n",
            "Epoch 308/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.4613 - accuracy: 0.9583 - val_loss: 0.4760 - val_accuracy: 0.9583\n",
            "Epoch 309/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.4606 - accuracy: 0.9688 - val_loss: 0.4747 - val_accuracy: 0.9583\n",
            "Epoch 310/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.4590 - accuracy: 0.9583 - val_loss: 0.4713 - val_accuracy: 0.9583\n",
            "Epoch 311/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.4576 - accuracy: 0.9688 - val_loss: 0.4703 - val_accuracy: 0.9583\n",
            "Epoch 312/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4579 - accuracy: 0.9792 - val_loss: 0.4734 - val_accuracy: 0.9583\n",
            "Epoch 313/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.4570 - accuracy: 0.9479 - val_loss: 0.4696 - val_accuracy: 0.9583\n",
            "Epoch 314/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.4569 - accuracy: 0.9688 - val_loss: 0.4716 - val_accuracy: 0.9583\n",
            "Epoch 315/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.4551 - accuracy: 0.9583 - val_loss: 0.4700 - val_accuracy: 0.9583\n",
            "Epoch 316/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.4551 - accuracy: 0.9688 - val_loss: 0.4680 - val_accuracy: 0.9583\n",
            "Epoch 317/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.4539 - accuracy: 0.9792 - val_loss: 0.4669 - val_accuracy: 0.9583\n",
            "Epoch 318/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.4535 - accuracy: 0.9583 - val_loss: 0.4655 - val_accuracy: 0.9583\n",
            "Epoch 319/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.4523 - accuracy: 0.9688 - val_loss: 0.4653 - val_accuracy: 0.9583\n",
            "Epoch 320/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.4534 - accuracy: 0.9583 - val_loss: 0.4664 - val_accuracy: 0.9583\n",
            "Epoch 321/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.4518 - accuracy: 0.9792 - val_loss: 0.4684 - val_accuracy: 0.9583\n",
            "Epoch 322/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.4525 - accuracy: 0.9583 - val_loss: 0.4662 - val_accuracy: 0.9583\n",
            "Epoch 323/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4547 - accuracy: 0.9479 - val_loss: 0.4624 - val_accuracy: 0.9583\n",
            "Epoch 324/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.4497 - accuracy: 0.9792 - val_loss: 0.4620 - val_accuracy: 0.9583\n",
            "Epoch 325/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.4489 - accuracy: 0.9688 - val_loss: 0.4616 - val_accuracy: 0.9583\n",
            "Epoch 326/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.4520 - accuracy: 0.9583 - val_loss: 0.4646 - val_accuracy: 0.9583\n",
            "Epoch 327/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.4474 - accuracy: 0.9792 - val_loss: 0.4643 - val_accuracy: 0.9583\n",
            "Epoch 328/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.4478 - accuracy: 0.9688 - val_loss: 0.4646 - val_accuracy: 0.9583\n",
            "Epoch 329/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.4467 - accuracy: 0.9688 - val_loss: 0.4621 - val_accuracy: 0.9583\n",
            "Epoch 330/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.4464 - accuracy: 0.9479 - val_loss: 0.4597 - val_accuracy: 0.9583\n",
            "Epoch 331/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.4454 - accuracy: 0.9792 - val_loss: 0.4596 - val_accuracy: 0.9583\n",
            "Epoch 332/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.4456 - accuracy: 0.9792 - val_loss: 0.4608 - val_accuracy: 0.9583\n",
            "Epoch 333/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.4477 - accuracy: 0.9688 - val_loss: 0.4637 - val_accuracy: 0.9583\n",
            "Epoch 334/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.4451 - accuracy: 0.9583 - val_loss: 0.4583 - val_accuracy: 0.9583\n",
            "Epoch 335/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.4434 - accuracy: 0.9792 - val_loss: 0.4590 - val_accuracy: 0.9583\n",
            "Epoch 336/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.4441 - accuracy: 0.9688 - val_loss: 0.4569 - val_accuracy: 0.9583\n",
            "Epoch 337/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.4417 - accuracy: 0.9792 - val_loss: 0.4577 - val_accuracy: 0.9583\n",
            "Epoch 338/1000\n",
            "96/96 [==============================] - 0s 138us/step - loss: 0.4413 - accuracy: 0.9792 - val_loss: 0.4572 - val_accuracy: 0.9583\n",
            "Epoch 339/1000\n",
            "96/96 [==============================] - 0s 80us/step - loss: 0.4550 - accuracy: 0.9167 - val_loss: 0.4536 - val_accuracy: 0.9583\n",
            "Epoch 340/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.4425 - accuracy: 0.9688 - val_loss: 0.4519 - val_accuracy: 0.9583\n",
            "Epoch 341/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.4397 - accuracy: 0.9792 - val_loss: 0.4544 - val_accuracy: 0.9583\n",
            "Epoch 342/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.4387 - accuracy: 0.9792 - val_loss: 0.4543 - val_accuracy: 0.9583\n",
            "Epoch 343/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.4413 - accuracy: 0.9583 - val_loss: 0.4504 - val_accuracy: 0.9583\n",
            "Epoch 344/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.4380 - accuracy: 0.9792 - val_loss: 0.4515 - val_accuracy: 0.9583\n",
            "Epoch 345/1000\n",
            "96/96 [==============================] - 0s 80us/step - loss: 0.4384 - accuracy: 0.9792 - val_loss: 0.4541 - val_accuracy: 0.9583\n",
            "Epoch 346/1000\n",
            "96/96 [==============================] - 0s 121us/step - loss: 0.4442 - accuracy: 0.9167 - val_loss: 0.4514 - val_accuracy: 0.9583\n",
            "Epoch 347/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.4363 - accuracy: 0.9688 - val_loss: 0.4509 - val_accuracy: 0.9583\n",
            "Epoch 348/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.4365 - accuracy: 0.9688 - val_loss: 0.4530 - val_accuracy: 0.9583\n",
            "Epoch 349/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.4350 - accuracy: 0.9688 - val_loss: 0.4519 - val_accuracy: 0.9583\n",
            "Epoch 350/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.4377 - accuracy: 0.9583 - val_loss: 0.4531 - val_accuracy: 0.9583\n",
            "Epoch 351/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.4367 - accuracy: 0.9479 - val_loss: 0.4544 - val_accuracy: 0.9583\n",
            "Epoch 352/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.4382 - accuracy: 0.9583 - val_loss: 0.4542 - val_accuracy: 0.9583\n",
            "Epoch 353/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.4345 - accuracy: 0.9479 - val_loss: 0.4485 - val_accuracy: 0.9583\n",
            "Epoch 354/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4329 - accuracy: 0.9792 - val_loss: 0.4495 - val_accuracy: 0.9583\n",
            "Epoch 355/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.4318 - accuracy: 0.9688 - val_loss: 0.4488 - val_accuracy: 0.9583\n",
            "Epoch 356/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.4345 - accuracy: 0.9479 - val_loss: 0.4521 - val_accuracy: 0.9583\n",
            "Epoch 357/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.4308 - accuracy: 0.9479 - val_loss: 0.4493 - val_accuracy: 0.9583\n",
            "Epoch 358/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.4317 - accuracy: 0.9583 - val_loss: 0.4473 - val_accuracy: 0.9583\n",
            "Epoch 359/1000\n",
            "96/96 [==============================] - 0s 80us/step - loss: 0.4322 - accuracy: 0.9688 - val_loss: 0.4504 - val_accuracy: 0.9583\n",
            "Epoch 360/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.4339 - accuracy: 0.9479 - val_loss: 0.4478 - val_accuracy: 0.9583\n",
            "Epoch 361/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4311 - accuracy: 0.9688 - val_loss: 0.4454 - val_accuracy: 0.9583\n",
            "Epoch 362/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.4299 - accuracy: 0.9583 - val_loss: 0.4420 - val_accuracy: 0.9583\n",
            "Epoch 363/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.4276 - accuracy: 0.9792 - val_loss: 0.4428 - val_accuracy: 0.9583\n",
            "Epoch 364/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.4272 - accuracy: 0.9792 - val_loss: 0.4436 - val_accuracy: 0.9583\n",
            "Epoch 365/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.4276 - accuracy: 0.9792 - val_loss: 0.4440 - val_accuracy: 0.9583\n",
            "Epoch 366/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.4302 - accuracy: 0.9583 - val_loss: 0.4457 - val_accuracy: 0.9583\n",
            "Epoch 367/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.4298 - accuracy: 0.9375 - val_loss: 0.4406 - val_accuracy: 0.9583\n",
            "Epoch 368/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.4260 - accuracy: 0.9792 - val_loss: 0.4412 - val_accuracy: 0.9583\n",
            "Epoch 369/1000\n",
            "96/96 [==============================] - 0s 114us/step - loss: 0.4272 - accuracy: 0.9792 - val_loss: 0.4385 - val_accuracy: 0.9583\n",
            "Epoch 370/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.4295 - accuracy: 0.9375 - val_loss: 0.4391 - val_accuracy: 0.9583\n",
            "Epoch 371/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.4272 - accuracy: 0.9583 - val_loss: 0.4401 - val_accuracy: 0.9583\n",
            "Epoch 372/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4228 - accuracy: 0.9688 - val_loss: 0.4402 - val_accuracy: 0.9583\n",
            "Epoch 373/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.4249 - accuracy: 0.9583 - val_loss: 0.4394 - val_accuracy: 0.9583\n",
            "Epoch 374/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.4221 - accuracy: 0.9688 - val_loss: 0.4383 - val_accuracy: 0.9583\n",
            "Epoch 375/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.4229 - accuracy: 0.9688 - val_loss: 0.4382 - val_accuracy: 0.9583\n",
            "Epoch 376/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.4207 - accuracy: 0.9688 - val_loss: 0.4377 - val_accuracy: 0.9583\n",
            "Epoch 377/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.4222 - accuracy: 0.9792 - val_loss: 0.4345 - val_accuracy: 0.9583\n",
            "Epoch 378/1000\n",
            "96/96 [==============================] - 0s 127us/step - loss: 0.4197 - accuracy: 0.9792 - val_loss: 0.4355 - val_accuracy: 0.9583\n",
            "Epoch 379/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.4203 - accuracy: 0.9583 - val_loss: 0.4335 - val_accuracy: 0.9583\n",
            "Epoch 380/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.4206 - accuracy: 0.9479 - val_loss: 0.4315 - val_accuracy: 0.9583\n",
            "Epoch 381/1000\n",
            "96/96 [==============================] - 0s 143us/step - loss: 0.4219 - accuracy: 0.9479 - val_loss: 0.4306 - val_accuracy: 0.9583\n",
            "Epoch 382/1000\n",
            "96/96 [==============================] - 0s 142us/step - loss: 0.4182 - accuracy: 0.9792 - val_loss: 0.4335 - val_accuracy: 0.9583\n",
            "Epoch 383/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.4197 - accuracy: 0.9688 - val_loss: 0.4329 - val_accuracy: 0.9583\n",
            "Epoch 384/1000\n",
            "96/96 [==============================] - 0s 144us/step - loss: 0.4224 - accuracy: 0.9479 - val_loss: 0.4351 - val_accuracy: 0.9583\n",
            "Epoch 385/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.4175 - accuracy: 0.9792 - val_loss: 0.4343 - val_accuracy: 0.9583\n",
            "Epoch 386/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.4160 - accuracy: 0.9792 - val_loss: 0.4340 - val_accuracy: 0.9583\n",
            "Epoch 387/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.4156 - accuracy: 0.9583 - val_loss: 0.4322 - val_accuracy: 0.9583\n",
            "Epoch 388/1000\n",
            "96/96 [==============================] - 0s 143us/step - loss: 0.4206 - accuracy: 0.9583 - val_loss: 0.4339 - val_accuracy: 0.9583\n",
            "Epoch 389/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.4152 - accuracy: 0.9583 - val_loss: 0.4332 - val_accuracy: 0.9583\n",
            "Epoch 390/1000\n",
            "96/96 [==============================] - 0s 79us/step - loss: 0.4147 - accuracy: 0.9792 - val_loss: 0.4339 - val_accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.4153 - accuracy: 0.9583 - val_loss: 0.4335 - val_accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.4142 - accuracy: 0.9688 - val_loss: 0.4337 - val_accuracy: 0.9583\n",
            "Epoch 393/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.4146 - accuracy: 0.9688 - val_loss: 0.4305 - val_accuracy: 0.9583\n",
            "Epoch 394/1000\n",
            "96/96 [==============================] - 0s 120us/step - loss: 0.4137 - accuracy: 0.9688 - val_loss: 0.4313 - val_accuracy: 0.9583\n",
            "Epoch 395/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.4118 - accuracy: 0.9479 - val_loss: 0.4291 - val_accuracy: 0.9583\n",
            "Epoch 396/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.4120 - accuracy: 0.9688 - val_loss: 0.4265 - val_accuracy: 0.9583\n",
            "Epoch 397/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4140 - accuracy: 0.9583 - val_loss: 0.4294 - val_accuracy: 0.9583\n",
            "Epoch 398/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.4101 - accuracy: 0.9688 - val_loss: 0.4281 - val_accuracy: 0.9583\n",
            "Epoch 399/1000\n",
            "96/96 [==============================] - 0s 81us/step - loss: 0.4101 - accuracy: 0.9688 - val_loss: 0.4266 - val_accuracy: 0.9583\n",
            "Epoch 400/1000\n",
            "96/96 [==============================] - 0s 118us/step - loss: 0.4094 - accuracy: 0.9792 - val_loss: 0.4262 - val_accuracy: 0.9583\n",
            "Epoch 401/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.4092 - accuracy: 0.9583 - val_loss: 0.4251 - val_accuracy: 0.9583\n",
            "Epoch 402/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.4097 - accuracy: 0.9792 - val_loss: 0.4271 - val_accuracy: 0.9583\n",
            "Epoch 403/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.4083 - accuracy: 0.9583 - val_loss: 0.4275 - val_accuracy: 0.9583\n",
            "Epoch 404/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.4094 - accuracy: 0.9792 - val_loss: 0.4286 - val_accuracy: 0.9583\n",
            "Epoch 405/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.4070 - accuracy: 0.9688 - val_loss: 0.4249 - val_accuracy: 0.9583\n",
            "Epoch 406/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.4080 - accuracy: 0.9583 - val_loss: 0.4217 - val_accuracy: 0.9583\n",
            "Epoch 407/1000\n",
            "96/96 [==============================] - 0s 126us/step - loss: 0.4061 - accuracy: 0.9792 - val_loss: 0.4213 - val_accuracy: 0.9583\n",
            "Epoch 408/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.4057 - accuracy: 0.9792 - val_loss: 0.4231 - val_accuracy: 0.9583\n",
            "Epoch 409/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.4057 - accuracy: 0.9792 - val_loss: 0.4243 - val_accuracy: 0.9583\n",
            "Epoch 410/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.4050 - accuracy: 0.9479 - val_loss: 0.4215 - val_accuracy: 0.9583\n",
            "Epoch 411/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4042 - accuracy: 0.9688 - val_loss: 0.4198 - val_accuracy: 0.9583\n",
            "Epoch 412/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.4051 - accuracy: 0.9688 - val_loss: 0.4191 - val_accuracy: 0.9583\n",
            "Epoch 413/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.4033 - accuracy: 0.9792 - val_loss: 0.4207 - val_accuracy: 0.9583\n",
            "Epoch 414/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.4053 - accuracy: 0.9792 - val_loss: 0.4196 - val_accuracy: 0.9583\n",
            "Epoch 415/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.4027 - accuracy: 0.9792 - val_loss: 0.4210 - val_accuracy: 0.9583\n",
            "Epoch 416/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.4020 - accuracy: 0.9688 - val_loss: 0.4195 - val_accuracy: 0.9583\n",
            "Epoch 417/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.4029 - accuracy: 0.9792 - val_loss: 0.4215 - val_accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.4009 - accuracy: 0.9688 - val_loss: 0.4204 - val_accuracy: 0.9583\n",
            "Epoch 419/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.4015 - accuracy: 0.9375 - val_loss: 0.4170 - val_accuracy: 0.9583\n",
            "Epoch 420/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.4004 - accuracy: 0.9792 - val_loss: 0.4182 - val_accuracy: 0.9583\n",
            "Epoch 421/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.3999 - accuracy: 0.9688 - val_loss: 0.4157 - val_accuracy: 0.9583\n",
            "Epoch 422/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.3989 - accuracy: 0.9792 - val_loss: 0.4159 - val_accuracy: 0.9583\n",
            "Epoch 423/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.3998 - accuracy: 0.9583 - val_loss: 0.4149 - val_accuracy: 0.9583\n",
            "Epoch 424/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.3999 - accuracy: 0.9688 - val_loss: 0.4154 - val_accuracy: 0.9583\n",
            "Epoch 425/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3978 - accuracy: 0.9688 - val_loss: 0.4144 - val_accuracy: 0.9583\n",
            "Epoch 426/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.3989 - accuracy: 0.9583 - val_loss: 0.4146 - val_accuracy: 0.9583\n",
            "Epoch 427/1000\n",
            "96/96 [==============================] - 0s 154us/step - loss: 0.4000 - accuracy: 0.9479 - val_loss: 0.4104 - val_accuracy: 0.9583\n",
            "Epoch 428/1000\n",
            "96/96 [==============================] - 0s 139us/step - loss: 0.3981 - accuracy: 0.9688 - val_loss: 0.4120 - val_accuracy: 0.9583\n",
            "Epoch 429/1000\n",
            "96/96 [==============================] - 0s 78us/step - loss: 0.3964 - accuracy: 0.9792 - val_loss: 0.4114 - val_accuracy: 0.9583\n",
            "Epoch 430/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.3976 - accuracy: 0.9688 - val_loss: 0.4130 - val_accuracy: 0.9583\n",
            "Epoch 431/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3995 - accuracy: 0.9583 - val_loss: 0.4161 - val_accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.3946 - accuracy: 0.9583 - val_loss: 0.4133 - val_accuracy: 0.9583\n",
            "Epoch 433/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3945 - accuracy: 0.9688 - val_loss: 0.4131 - val_accuracy: 0.9583\n",
            "Epoch 434/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3996 - accuracy: 0.9375 - val_loss: 0.4079 - val_accuracy: 0.9583\n",
            "Epoch 435/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.3939 - accuracy: 0.9792 - val_loss: 0.4076 - val_accuracy: 0.9583\n",
            "Epoch 436/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.3971 - accuracy: 0.9583 - val_loss: 0.4092 - val_accuracy: 0.9583\n",
            "Epoch 437/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3954 - accuracy: 0.9583 - val_loss: 0.4130 - val_accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3927 - accuracy: 0.9583 - val_loss: 0.4127 - val_accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3926 - accuracy: 0.9688 - val_loss: 0.4113 - val_accuracy: 0.9583\n",
            "Epoch 440/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3912 - accuracy: 0.9688 - val_loss: 0.4098 - val_accuracy: 0.9583\n",
            "Epoch 441/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3911 - accuracy: 0.9792 - val_loss: 0.4081 - val_accuracy: 0.9583\n",
            "Epoch 442/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.3901 - accuracy: 0.9792 - val_loss: 0.4083 - val_accuracy: 0.9583\n",
            "Epoch 443/1000\n",
            "96/96 [==============================] - 0s 78us/step - loss: 0.3905 - accuracy: 0.9792 - val_loss: 0.4092 - val_accuracy: 0.9583\n",
            "Epoch 444/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3893 - accuracy: 0.9583 - val_loss: 0.4082 - val_accuracy: 0.9583\n",
            "Epoch 445/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.3891 - accuracy: 0.9792 - val_loss: 0.4081 - val_accuracy: 0.9583\n",
            "Epoch 446/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.3903 - accuracy: 0.9583 - val_loss: 0.4042 - val_accuracy: 0.9583\n",
            "Epoch 447/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.3953 - accuracy: 0.9271 - val_loss: 0.4044 - val_accuracy: 0.9583\n",
            "Epoch 448/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.3878 - accuracy: 0.9792 - val_loss: 0.4057 - val_accuracy: 0.9583\n",
            "Epoch 449/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3877 - accuracy: 0.9792 - val_loss: 0.4067 - val_accuracy: 0.9583\n",
            "Epoch 450/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.3904 - accuracy: 0.9583 - val_loss: 0.4079 - val_accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "96/96 [==============================] - 0s 115us/step - loss: 0.3885 - accuracy: 0.9792 - val_loss: 0.4077 - val_accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3889 - accuracy: 0.9583 - val_loss: 0.4076 - val_accuracy: 0.9583\n",
            "Epoch 453/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3896 - accuracy: 0.9583 - val_loss: 0.4055 - val_accuracy: 0.9583\n",
            "Epoch 454/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.3856 - accuracy: 0.9688 - val_loss: 0.4030 - val_accuracy: 0.9583\n",
            "Epoch 455/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.3880 - accuracy: 0.9583 - val_loss: 0.4048 - val_accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3847 - accuracy: 0.9688 - val_loss: 0.4035 - val_accuracy: 0.9583\n",
            "Epoch 457/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.3853 - accuracy: 0.9688 - val_loss: 0.4049 - val_accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.3844 - accuracy: 0.9583 - val_loss: 0.4015 - val_accuracy: 0.9583\n",
            "Epoch 459/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.3829 - accuracy: 0.9688 - val_loss: 0.4006 - val_accuracy: 0.9583\n",
            "Epoch 460/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.3831 - accuracy: 0.9792 - val_loss: 0.3995 - val_accuracy: 0.9583\n",
            "Epoch 461/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.3831 - accuracy: 0.9688 - val_loss: 0.3975 - val_accuracy: 0.9583\n",
            "Epoch 462/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.3819 - accuracy: 0.9792 - val_loss: 0.3982 - val_accuracy: 0.9583\n",
            "Epoch 463/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.3827 - accuracy: 0.9896 - val_loss: 0.3973 - val_accuracy: 0.9583\n",
            "Epoch 464/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3809 - accuracy: 0.9792 - val_loss: 0.3979 - val_accuracy: 0.9583\n",
            "Epoch 465/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.3804 - accuracy: 0.9792 - val_loss: 0.3977 - val_accuracy: 0.9583\n",
            "Epoch 466/1000\n",
            "96/96 [==============================] - 0s 84us/step - loss: 0.3816 - accuracy: 0.9583 - val_loss: 0.3970 - val_accuracy: 0.9583\n",
            "Epoch 467/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.3806 - accuracy: 0.9792 - val_loss: 0.3965 - val_accuracy: 0.9583\n",
            "Epoch 468/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.3808 - accuracy: 0.9792 - val_loss: 0.3986 - val_accuracy: 0.9583\n",
            "Epoch 469/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.3791 - accuracy: 0.9688 - val_loss: 0.3965 - val_accuracy: 0.9583\n",
            "Epoch 470/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.3785 - accuracy: 0.9583 - val_loss: 0.3953 - val_accuracy: 0.9583\n",
            "Epoch 471/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3781 - accuracy: 0.9792 - val_loss: 0.3960 - val_accuracy: 0.9583\n",
            "Epoch 472/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.3785 - accuracy: 0.9688 - val_loss: 0.3946 - val_accuracy: 0.9583\n",
            "Epoch 473/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.3780 - accuracy: 0.9792 - val_loss: 0.3953 - val_accuracy: 0.9583\n",
            "Epoch 474/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.3773 - accuracy: 0.9792 - val_loss: 0.3961 - val_accuracy: 0.9583\n",
            "Epoch 475/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.3765 - accuracy: 0.9792 - val_loss: 0.3954 - val_accuracy: 0.9583\n",
            "Epoch 476/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.3759 - accuracy: 0.9688 - val_loss: 0.3940 - val_accuracy: 0.9583\n",
            "Epoch 477/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.3757 - accuracy: 0.9792 - val_loss: 0.3940 - val_accuracy: 0.9583\n",
            "Epoch 478/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.3770 - accuracy: 0.9688 - val_loss: 0.3939 - val_accuracy: 0.9583\n",
            "Epoch 479/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.3762 - accuracy: 0.9688 - val_loss: 0.3906 - val_accuracy: 0.9583\n",
            "Epoch 480/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.3753 - accuracy: 0.9583 - val_loss: 0.3898 - val_accuracy: 0.9583\n",
            "Epoch 481/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3748 - accuracy: 0.9792 - val_loss: 0.3910 - val_accuracy: 0.9583\n",
            "Epoch 482/1000\n",
            "96/96 [==============================] - 0s 84us/step - loss: 0.3738 - accuracy: 0.9792 - val_loss: 0.3912 - val_accuracy: 0.9583\n",
            "Epoch 483/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.3734 - accuracy: 0.9583 - val_loss: 0.3897 - val_accuracy: 0.9583\n",
            "Epoch 484/1000\n",
            "96/96 [==============================] - 0s 81us/step - loss: 0.3746 - accuracy: 0.9688 - val_loss: 0.3876 - val_accuracy: 0.9583\n",
            "Epoch 485/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.3726 - accuracy: 0.9792 - val_loss: 0.3890 - val_accuracy: 0.9583\n",
            "Epoch 486/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3734 - accuracy: 0.9792 - val_loss: 0.3890 - val_accuracy: 0.9583\n",
            "Epoch 487/1000\n",
            "96/96 [==============================] - 0s 81us/step - loss: 0.3721 - accuracy: 0.9792 - val_loss: 0.3900 - val_accuracy: 0.9583\n",
            "Epoch 488/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.3713 - accuracy: 0.9792 - val_loss: 0.3892 - val_accuracy: 0.9583\n",
            "Epoch 489/1000\n",
            "96/96 [==============================] - 0s 125us/step - loss: 0.3718 - accuracy: 0.9792 - val_loss: 0.3881 - val_accuracy: 0.9583\n",
            "Epoch 490/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.3731 - accuracy: 0.9688 - val_loss: 0.3875 - val_accuracy: 0.9583\n",
            "Epoch 491/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.3716 - accuracy: 0.9792 - val_loss: 0.3864 - val_accuracy: 0.9583\n",
            "Epoch 492/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.3732 - accuracy: 0.9792 - val_loss: 0.3889 - val_accuracy: 0.9583\n",
            "Epoch 493/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3730 - accuracy: 0.9688 - val_loss: 0.3847 - val_accuracy: 0.9583\n",
            "Epoch 494/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.3691 - accuracy: 0.9792 - val_loss: 0.3858 - val_accuracy: 0.9583\n",
            "Epoch 495/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3701 - accuracy: 0.9792 - val_loss: 0.3880 - val_accuracy: 0.9583\n",
            "Epoch 496/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.3692 - accuracy: 0.9688 - val_loss: 0.3888 - val_accuracy: 1.0000\n",
            "Epoch 497/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.3689 - accuracy: 0.9583 - val_loss: 0.3880 - val_accuracy: 1.0000\n",
            "Epoch 498/1000\n",
            "96/96 [==============================] - 0s 78us/step - loss: 0.3681 - accuracy: 0.9583 - val_loss: 0.3868 - val_accuracy: 0.9583\n",
            "Epoch 499/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.3673 - accuracy: 0.9583 - val_loss: 0.3845 - val_accuracy: 0.9583\n",
            "Epoch 500/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.3671 - accuracy: 0.9792 - val_loss: 0.3857 - val_accuracy: 0.9583\n",
            "Epoch 501/1000\n",
            "96/96 [==============================] - 0s 125us/step - loss: 0.3695 - accuracy: 0.9583 - val_loss: 0.3839 - val_accuracy: 0.9583\n",
            "Epoch 502/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.3662 - accuracy: 0.9792 - val_loss: 0.3828 - val_accuracy: 0.9583\n",
            "Epoch 503/1000\n",
            "96/96 [==============================] - 0s 130us/step - loss: 0.3664 - accuracy: 0.9792 - val_loss: 0.3822 - val_accuracy: 0.9583\n",
            "Epoch 504/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3693 - accuracy: 0.9375 - val_loss: 0.3785 - val_accuracy: 0.9583\n",
            "Epoch 505/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.3675 - accuracy: 0.9688 - val_loss: 0.3777 - val_accuracy: 0.9583\n",
            "Epoch 506/1000\n",
            "96/96 [==============================] - 0s 132us/step - loss: 0.3648 - accuracy: 0.9792 - val_loss: 0.3793 - val_accuracy: 0.9583\n",
            "Epoch 507/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.3651 - accuracy: 0.9688 - val_loss: 0.3783 - val_accuracy: 0.9583\n",
            "Epoch 508/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3660 - accuracy: 0.9688 - val_loss: 0.3768 - val_accuracy: 0.9583\n",
            "Epoch 509/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3646 - accuracy: 0.9688 - val_loss: 0.3804 - val_accuracy: 0.9583\n",
            "Epoch 510/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3642 - accuracy: 0.9792 - val_loss: 0.3803 - val_accuracy: 0.9583\n",
            "Epoch 511/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3628 - accuracy: 0.9583 - val_loss: 0.3796 - val_accuracy: 0.9583\n",
            "Epoch 512/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3659 - accuracy: 0.9688 - val_loss: 0.3775 - val_accuracy: 0.9583\n",
            "Epoch 513/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3629 - accuracy: 0.9792 - val_loss: 0.3788 - val_accuracy: 0.9583\n",
            "Epoch 514/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.3617 - accuracy: 0.9792 - val_loss: 0.3799 - val_accuracy: 0.9583\n",
            "Epoch 515/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3631 - accuracy: 0.9688 - val_loss: 0.3791 - val_accuracy: 0.9583\n",
            "Epoch 516/1000\n",
            "96/96 [==============================] - 0s 84us/step - loss: 0.3618 - accuracy: 0.9479 - val_loss: 0.3766 - val_accuracy: 0.9583\n",
            "Epoch 517/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.3612 - accuracy: 0.9688 - val_loss: 0.3755 - val_accuracy: 0.9583\n",
            "Epoch 518/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3602 - accuracy: 0.9792 - val_loss: 0.3769 - val_accuracy: 0.9583\n",
            "Epoch 519/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.3594 - accuracy: 0.9792 - val_loss: 0.3770 - val_accuracy: 0.9583\n",
            "Epoch 520/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.3590 - accuracy: 0.9792 - val_loss: 0.3765 - val_accuracy: 0.9583\n",
            "Epoch 521/1000\n",
            "96/96 [==============================] - 0s 162us/step - loss: 0.3605 - accuracy: 0.9792 - val_loss: 0.3786 - val_accuracy: 0.9583\n",
            "Epoch 522/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3600 - accuracy: 0.9583 - val_loss: 0.3785 - val_accuracy: 0.9583\n",
            "Epoch 523/1000\n",
            "96/96 [==============================] - 0s 115us/step - loss: 0.3601 - accuracy: 0.9688 - val_loss: 0.3767 - val_accuracy: 0.9583\n",
            "Epoch 524/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.3601 - accuracy: 0.9375 - val_loss: 0.3728 - val_accuracy: 0.9583\n",
            "Epoch 525/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.3584 - accuracy: 0.9792 - val_loss: 0.3735 - val_accuracy: 0.9583\n",
            "Epoch 526/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.3570 - accuracy: 0.9792 - val_loss: 0.3737 - val_accuracy: 0.9583\n",
            "Epoch 527/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3585 - accuracy: 0.9688 - val_loss: 0.3736 - val_accuracy: 0.9583\n",
            "Epoch 528/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.3579 - accuracy: 0.9688 - val_loss: 0.3725 - val_accuracy: 0.9583\n",
            "Epoch 529/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3573 - accuracy: 0.9583 - val_loss: 0.3706 - val_accuracy: 0.9583\n",
            "Epoch 530/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.3563 - accuracy: 0.9792 - val_loss: 0.3723 - val_accuracy: 0.9583\n",
            "Epoch 531/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.3554 - accuracy: 0.9792 - val_loss: 0.3716 - val_accuracy: 0.9583\n",
            "Epoch 532/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3550 - accuracy: 0.9792 - val_loss: 0.3714 - val_accuracy: 0.9583\n",
            "Epoch 533/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.3549 - accuracy: 0.9792 - val_loss: 0.3703 - val_accuracy: 0.9583\n",
            "Epoch 534/1000\n",
            "96/96 [==============================] - 0s 75us/step - loss: 0.3586 - accuracy: 0.9688 - val_loss: 0.3688 - val_accuracy: 0.9583\n",
            "Epoch 535/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3540 - accuracy: 0.9792 - val_loss: 0.3696 - val_accuracy: 0.9583\n",
            "Epoch 536/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3547 - accuracy: 0.9792 - val_loss: 0.3719 - val_accuracy: 0.9583\n",
            "Epoch 537/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.3540 - accuracy: 0.9583 - val_loss: 0.3693 - val_accuracy: 0.9583\n",
            "Epoch 538/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.3536 - accuracy: 0.9688 - val_loss: 0.3686 - val_accuracy: 0.9583\n",
            "Epoch 539/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.3526 - accuracy: 0.9688 - val_loss: 0.3686 - val_accuracy: 0.9583\n",
            "Epoch 540/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.3519 - accuracy: 0.9792 - val_loss: 0.3685 - val_accuracy: 0.9583\n",
            "Epoch 541/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3518 - accuracy: 0.9792 - val_loss: 0.3678 - val_accuracy: 0.9583\n",
            "Epoch 542/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.3536 - accuracy: 0.9688 - val_loss: 0.3658 - val_accuracy: 0.9583\n",
            "Epoch 543/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3518 - accuracy: 0.9792 - val_loss: 0.3661 - val_accuracy: 0.9583\n",
            "Epoch 544/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.3513 - accuracy: 0.9792 - val_loss: 0.3656 - val_accuracy: 0.9583\n",
            "Epoch 545/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.3503 - accuracy: 0.9792 - val_loss: 0.3657 - val_accuracy: 0.9583\n",
            "Epoch 546/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.3498 - accuracy: 0.9792 - val_loss: 0.3667 - val_accuracy: 0.9583\n",
            "Epoch 547/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3500 - accuracy: 0.9792 - val_loss: 0.3663 - val_accuracy: 0.9583\n",
            "Epoch 548/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.3494 - accuracy: 0.9792 - val_loss: 0.3668 - val_accuracy: 0.9583\n",
            "Epoch 549/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.3496 - accuracy: 0.9583 - val_loss: 0.3651 - val_accuracy: 0.9583\n",
            "Epoch 550/1000\n",
            "96/96 [==============================] - 0s 121us/step - loss: 0.3526 - accuracy: 0.9583 - val_loss: 0.3624 - val_accuracy: 0.9583\n",
            "Epoch 551/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.3481 - accuracy: 0.9792 - val_loss: 0.3637 - val_accuracy: 0.9583\n",
            "Epoch 552/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.3487 - accuracy: 0.9792 - val_loss: 0.3660 - val_accuracy: 0.9583\n",
            "Epoch 553/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.3473 - accuracy: 0.9792 - val_loss: 0.3650 - val_accuracy: 0.9583\n",
            "Epoch 554/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.3518 - accuracy: 0.9479 - val_loss: 0.3651 - val_accuracy: 0.9583\n",
            "Epoch 555/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.3473 - accuracy: 0.9688 - val_loss: 0.3640 - val_accuracy: 0.9583\n",
            "Epoch 556/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.3470 - accuracy: 0.9583 - val_loss: 0.3620 - val_accuracy: 0.9583\n",
            "Epoch 557/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3482 - accuracy: 0.9688 - val_loss: 0.3636 - val_accuracy: 0.9583\n",
            "Epoch 558/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.3460 - accuracy: 0.9792 - val_loss: 0.3639 - val_accuracy: 0.9583\n",
            "Epoch 559/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3502 - accuracy: 0.9479 - val_loss: 0.3604 - val_accuracy: 0.9583\n",
            "Epoch 560/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3471 - accuracy: 0.9688 - val_loss: 0.3635 - val_accuracy: 0.9583\n",
            "Epoch 561/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.3459 - accuracy: 0.9688 - val_loss: 0.3612 - val_accuracy: 0.9583\n",
            "Epoch 562/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.3453 - accuracy: 0.9792 - val_loss: 0.3620 - val_accuracy: 0.9583\n",
            "Epoch 563/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.3464 - accuracy: 0.9792 - val_loss: 0.3603 - val_accuracy: 0.9583\n",
            "Epoch 564/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.3435 - accuracy: 0.9792 - val_loss: 0.3605 - val_accuracy: 0.9583\n",
            "Epoch 565/1000\n",
            "96/96 [==============================] - 0s 114us/step - loss: 0.3467 - accuracy: 0.9583 - val_loss: 0.3575 - val_accuracy: 0.9583\n",
            "Epoch 566/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.3430 - accuracy: 0.9792 - val_loss: 0.3577 - val_accuracy: 0.9583\n",
            "Epoch 567/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.3428 - accuracy: 0.9792 - val_loss: 0.3581 - val_accuracy: 0.9583\n",
            "Epoch 568/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.3481 - accuracy: 0.9583 - val_loss: 0.3591 - val_accuracy: 0.9583\n",
            "Epoch 569/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.3420 - accuracy: 0.9792 - val_loss: 0.3579 - val_accuracy: 0.9583\n",
            "Epoch 570/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3430 - accuracy: 0.9792 - val_loss: 0.3573 - val_accuracy: 0.9583\n",
            "Epoch 571/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.3439 - accuracy: 0.9792 - val_loss: 0.3600 - val_accuracy: 0.9583\n",
            "Epoch 572/1000\n",
            "96/96 [==============================] - 0s 80us/step - loss: 0.3417 - accuracy: 0.9688 - val_loss: 0.3591 - val_accuracy: 0.9583\n",
            "Epoch 573/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.3412 - accuracy: 0.9688 - val_loss: 0.3572 - val_accuracy: 0.9583\n",
            "Epoch 574/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.3406 - accuracy: 0.9792 - val_loss: 0.3582 - val_accuracy: 0.9583\n",
            "Epoch 575/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.3400 - accuracy: 0.9792 - val_loss: 0.3579 - val_accuracy: 0.9583\n",
            "Epoch 576/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3452 - accuracy: 0.9688 - val_loss: 0.3586 - val_accuracy: 0.9583\n",
            "Epoch 577/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.3392 - accuracy: 0.9688 - val_loss: 0.3577 - val_accuracy: 0.9583\n",
            "Epoch 578/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.3393 - accuracy: 0.9583 - val_loss: 0.3554 - val_accuracy: 0.9583\n",
            "Epoch 579/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.3389 - accuracy: 0.9583 - val_loss: 0.3541 - val_accuracy: 0.9583\n",
            "Epoch 580/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.3387 - accuracy: 0.9792 - val_loss: 0.3558 - val_accuracy: 0.9583\n",
            "Epoch 581/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.3397 - accuracy: 0.9688 - val_loss: 0.3539 - val_accuracy: 0.9583\n",
            "Epoch 582/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.3387 - accuracy: 0.9792 - val_loss: 0.3532 - val_accuracy: 0.9583\n",
            "Epoch 583/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.3378 - accuracy: 0.9792 - val_loss: 0.3546 - val_accuracy: 0.9583\n",
            "Epoch 584/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.3375 - accuracy: 0.9688 - val_loss: 0.3540 - val_accuracy: 0.9583\n",
            "Epoch 585/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.3366 - accuracy: 0.9688 - val_loss: 0.3529 - val_accuracy: 0.9583\n",
            "Epoch 586/1000\n",
            "96/96 [==============================] - 0s 115us/step - loss: 0.3381 - accuracy: 0.9688 - val_loss: 0.3544 - val_accuracy: 0.9583\n",
            "Epoch 587/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.3371 - accuracy: 0.9792 - val_loss: 0.3531 - val_accuracy: 0.9583\n",
            "Epoch 588/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.3358 - accuracy: 0.9792 - val_loss: 0.3533 - val_accuracy: 0.9583\n",
            "Epoch 589/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.3357 - accuracy: 0.9792 - val_loss: 0.3537 - val_accuracy: 0.9583\n",
            "Epoch 590/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.3355 - accuracy: 0.9792 - val_loss: 0.3541 - val_accuracy: 0.9583\n",
            "Epoch 591/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.3368 - accuracy: 0.9688 - val_loss: 0.3553 - val_accuracy: 1.0000\n",
            "Epoch 592/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.3379 - accuracy: 0.9583 - val_loss: 0.3541 - val_accuracy: 1.0000\n",
            "Epoch 593/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.3343 - accuracy: 0.9583 - val_loss: 0.3511 - val_accuracy: 0.9583\n",
            "Epoch 594/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.3338 - accuracy: 0.9688 - val_loss: 0.3507 - val_accuracy: 0.9583\n",
            "Epoch 595/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3336 - accuracy: 0.9583 - val_loss: 0.3494 - val_accuracy: 0.9583\n",
            "Epoch 596/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.3339 - accuracy: 0.9792 - val_loss: 0.3497 - val_accuracy: 0.9583\n",
            "Epoch 597/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.3331 - accuracy: 0.9792 - val_loss: 0.3498 - val_accuracy: 0.9583\n",
            "Epoch 598/1000\n",
            "96/96 [==============================] - 0s 78us/step - loss: 0.3352 - accuracy: 0.9792 - val_loss: 0.3491 - val_accuracy: 0.9583\n",
            "Epoch 599/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.3321 - accuracy: 0.9792 - val_loss: 0.3485 - val_accuracy: 0.9583\n",
            "Epoch 600/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.3342 - accuracy: 0.9688 - val_loss: 0.3503 - val_accuracy: 0.9583\n",
            "Epoch 601/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.3327 - accuracy: 0.9583 - val_loss: 0.3471 - val_accuracy: 0.9583\n",
            "Epoch 602/1000\n",
            "96/96 [==============================] - 0s 131us/step - loss: 0.3309 - accuracy: 0.9792 - val_loss: 0.3468 - val_accuracy: 0.9583\n",
            "Epoch 603/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.3314 - accuracy: 0.9583 - val_loss: 0.3457 - val_accuracy: 0.9583\n",
            "Epoch 604/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.3337 - accuracy: 0.9792 - val_loss: 0.3495 - val_accuracy: 0.9583\n",
            "Epoch 605/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3307 - accuracy: 0.9688 - val_loss: 0.3475 - val_accuracy: 0.9583\n",
            "Epoch 606/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3298 - accuracy: 0.9792 - val_loss: 0.3468 - val_accuracy: 0.9583\n",
            "Epoch 607/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3294 - accuracy: 0.9792 - val_loss: 0.3467 - val_accuracy: 0.9583\n",
            "Epoch 608/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3302 - accuracy: 0.9583 - val_loss: 0.3442 - val_accuracy: 0.9583\n",
            "Epoch 609/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3293 - accuracy: 0.9792 - val_loss: 0.3448 - val_accuracy: 0.9583\n",
            "Epoch 610/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.3305 - accuracy: 0.9792 - val_loss: 0.3454 - val_accuracy: 0.9583\n",
            "Epoch 611/1000\n",
            "96/96 [==============================] - 0s 171us/step - loss: 0.3287 - accuracy: 0.9583 - val_loss: 0.3436 - val_accuracy: 0.9583\n",
            "Epoch 612/1000\n",
            "96/96 [==============================] - 0s 127us/step - loss: 0.3279 - accuracy: 0.9792 - val_loss: 0.3434 - val_accuracy: 0.9583\n",
            "Epoch 613/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.3284 - accuracy: 0.9792 - val_loss: 0.3452 - val_accuracy: 0.9583\n",
            "Epoch 614/1000\n",
            "96/96 [==============================] - 0s 123us/step - loss: 0.3275 - accuracy: 0.9792 - val_loss: 0.3452 - val_accuracy: 0.9583\n",
            "Epoch 615/1000\n",
            "96/96 [==============================] - 0s 124us/step - loss: 0.3277 - accuracy: 0.9688 - val_loss: 0.3440 - val_accuracy: 0.9583\n",
            "Epoch 616/1000\n",
            "96/96 [==============================] - 0s 120us/step - loss: 0.3275 - accuracy: 0.9792 - val_loss: 0.3416 - val_accuracy: 0.9583\n",
            "Epoch 617/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.3284 - accuracy: 0.9792 - val_loss: 0.3433 - val_accuracy: 0.9583\n",
            "Epoch 618/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3259 - accuracy: 0.9792 - val_loss: 0.3425 - val_accuracy: 0.9583\n",
            "Epoch 619/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3270 - accuracy: 0.9792 - val_loss: 0.3433 - val_accuracy: 0.9583\n",
            "Epoch 620/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.3281 - accuracy: 0.9792 - val_loss: 0.3453 - val_accuracy: 1.0000\n",
            "Epoch 621/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3258 - accuracy: 0.9583 - val_loss: 0.3430 - val_accuracy: 0.9583\n",
            "Epoch 622/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3251 - accuracy: 0.9688 - val_loss: 0.3421 - val_accuracy: 0.9583\n",
            "Epoch 623/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.3262 - accuracy: 0.9688 - val_loss: 0.3400 - val_accuracy: 0.9583\n",
            "Epoch 624/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.3251 - accuracy: 0.9792 - val_loss: 0.3414 - val_accuracy: 0.9583\n",
            "Epoch 625/1000\n",
            "96/96 [==============================] - 0s 143us/step - loss: 0.3284 - accuracy: 0.9583 - val_loss: 0.3379 - val_accuracy: 0.9583\n",
            "Epoch 626/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3244 - accuracy: 0.9688 - val_loss: 0.3403 - val_accuracy: 0.9583\n",
            "Epoch 627/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.3233 - accuracy: 0.9792 - val_loss: 0.3395 - val_accuracy: 0.9583\n",
            "Epoch 628/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.3260 - accuracy: 0.9792 - val_loss: 0.3386 - val_accuracy: 0.9583\n",
            "Epoch 629/1000\n",
            "96/96 [==============================] - 0s 116us/step - loss: 0.3228 - accuracy: 0.9792 - val_loss: 0.3379 - val_accuracy: 0.9583\n",
            "Epoch 630/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.3222 - accuracy: 0.9792 - val_loss: 0.3378 - val_accuracy: 0.9583\n",
            "Epoch 631/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.3230 - accuracy: 0.9583 - val_loss: 0.3362 - val_accuracy: 0.9583\n",
            "Epoch 632/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.3223 - accuracy: 0.9792 - val_loss: 0.3358 - val_accuracy: 0.9583\n",
            "Epoch 633/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.3241 - accuracy: 0.9688 - val_loss: 0.3388 - val_accuracy: 0.9583\n",
            "Epoch 634/1000\n",
            "96/96 [==============================] - 0s 139us/step - loss: 0.3220 - accuracy: 0.9792 - val_loss: 0.3398 - val_accuracy: 0.9583\n",
            "Epoch 635/1000\n",
            "96/96 [==============================] - 0s 121us/step - loss: 0.3212 - accuracy: 0.9688 - val_loss: 0.3387 - val_accuracy: 0.9583\n",
            "Epoch 636/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.3208 - accuracy: 0.9792 - val_loss: 0.3386 - val_accuracy: 0.9583\n",
            "Epoch 637/1000\n",
            "96/96 [==============================] - 0s 127us/step - loss: 0.3204 - accuracy: 0.9792 - val_loss: 0.3385 - val_accuracy: 0.9583\n",
            "Epoch 638/1000\n",
            "96/96 [==============================] - 0s 114us/step - loss: 0.3210 - accuracy: 0.9583 - val_loss: 0.3359 - val_accuracy: 0.9583\n",
            "Epoch 639/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.3200 - accuracy: 0.9583 - val_loss: 0.3345 - val_accuracy: 0.9583\n",
            "Epoch 640/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.3205 - accuracy: 0.9792 - val_loss: 0.3351 - val_accuracy: 0.9583\n",
            "Epoch 641/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.3200 - accuracy: 0.9688 - val_loss: 0.3346 - val_accuracy: 0.9583\n",
            "Epoch 642/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.3187 - accuracy: 0.9792 - val_loss: 0.3339 - val_accuracy: 0.9583\n",
            "Epoch 643/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.3201 - accuracy: 0.9792 - val_loss: 0.3363 - val_accuracy: 0.9583\n",
            "Epoch 644/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3198 - accuracy: 0.9583 - val_loss: 0.3339 - val_accuracy: 0.9583\n",
            "Epoch 645/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.3176 - accuracy: 0.9792 - val_loss: 0.3341 - val_accuracy: 0.9583\n",
            "Epoch 646/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.3176 - accuracy: 0.9792 - val_loss: 0.3347 - val_accuracy: 0.9583\n",
            "Epoch 647/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.3178 - accuracy: 0.9583 - val_loss: 0.3329 - val_accuracy: 0.9583\n",
            "Epoch 648/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.3171 - accuracy: 0.9792 - val_loss: 0.3319 - val_accuracy: 0.9583\n",
            "Epoch 649/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3179 - accuracy: 0.9792 - val_loss: 0.3335 - val_accuracy: 0.9583\n",
            "Epoch 650/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.3176 - accuracy: 0.9792 - val_loss: 0.3349 - val_accuracy: 0.9583\n",
            "Epoch 651/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.3176 - accuracy: 0.9688 - val_loss: 0.3327 - val_accuracy: 0.9583\n",
            "Epoch 652/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.3157 - accuracy: 0.9792 - val_loss: 0.3317 - val_accuracy: 0.9583\n",
            "Epoch 653/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.3172 - accuracy: 0.9688 - val_loss: 0.3325 - val_accuracy: 0.9583\n",
            "Epoch 654/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.3151 - accuracy: 0.9688 - val_loss: 0.3311 - val_accuracy: 0.9583\n",
            "Epoch 655/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.3147 - accuracy: 0.9792 - val_loss: 0.3311 - val_accuracy: 0.9583\n",
            "Epoch 656/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.3152 - accuracy: 0.9792 - val_loss: 0.3323 - val_accuracy: 0.9583\n",
            "Epoch 657/1000\n",
            "96/96 [==============================] - 0s 81us/step - loss: 0.3150 - accuracy: 0.9583 - val_loss: 0.3299 - val_accuracy: 0.9583\n",
            "Epoch 658/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.3144 - accuracy: 0.9583 - val_loss: 0.3293 - val_accuracy: 0.9583\n",
            "Epoch 659/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3140 - accuracy: 0.9792 - val_loss: 0.3284 - val_accuracy: 0.9583\n",
            "Epoch 660/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.3142 - accuracy: 0.9688 - val_loss: 0.3273 - val_accuracy: 0.9583\n",
            "Epoch 661/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.3129 - accuracy: 0.9792 - val_loss: 0.3278 - val_accuracy: 0.9583\n",
            "Epoch 662/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3136 - accuracy: 0.9792 - val_loss: 0.3288 - val_accuracy: 0.9583\n",
            "Epoch 663/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.3130 - accuracy: 0.9792 - val_loss: 0.3298 - val_accuracy: 0.9583\n",
            "Epoch 664/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.3121 - accuracy: 0.9792 - val_loss: 0.3292 - val_accuracy: 0.9583\n",
            "Epoch 665/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.3126 - accuracy: 0.9792 - val_loss: 0.3292 - val_accuracy: 0.9583\n",
            "Epoch 666/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.3116 - accuracy: 0.9792 - val_loss: 0.3277 - val_accuracy: 0.9583\n",
            "Epoch 667/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.3134 - accuracy: 0.9688 - val_loss: 0.3251 - val_accuracy: 0.9583\n",
            "Epoch 668/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3111 - accuracy: 0.9792 - val_loss: 0.3268 - val_accuracy: 0.9583\n",
            "Epoch 669/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.3136 - accuracy: 0.9792 - val_loss: 0.3261 - val_accuracy: 0.9583\n",
            "Epoch 670/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.3104 - accuracy: 0.9792 - val_loss: 0.3257 - val_accuracy: 0.9583\n",
            "Epoch 671/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.3113 - accuracy: 0.9583 - val_loss: 0.3240 - val_accuracy: 0.9583\n",
            "Epoch 672/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.3098 - accuracy: 0.9792 - val_loss: 0.3254 - val_accuracy: 0.9583\n",
            "Epoch 673/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3094 - accuracy: 0.9792 - val_loss: 0.3252 - val_accuracy: 0.9583\n",
            "Epoch 674/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.3096 - accuracy: 0.9688 - val_loss: 0.3243 - val_accuracy: 0.9583\n",
            "Epoch 675/1000\n",
            "96/96 [==============================] - 0s 90us/step - loss: 0.3093 - accuracy: 0.9792 - val_loss: 0.3247 - val_accuracy: 0.9583\n",
            "Epoch 676/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.3102 - accuracy: 0.9688 - val_loss: 0.3227 - val_accuracy: 0.9583\n",
            "Epoch 677/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3095 - accuracy: 0.9688 - val_loss: 0.3219 - val_accuracy: 0.9583\n",
            "Epoch 678/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.3095 - accuracy: 0.9688 - val_loss: 0.3244 - val_accuracy: 0.9583\n",
            "Epoch 679/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.3082 - accuracy: 0.9688 - val_loss: 0.3230 - val_accuracy: 0.9583\n",
            "Epoch 680/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.3080 - accuracy: 0.9792 - val_loss: 0.3227 - val_accuracy: 0.9583\n",
            "Epoch 681/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3076 - accuracy: 0.9792 - val_loss: 0.3218 - val_accuracy: 0.9583\n",
            "Epoch 682/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.3083 - accuracy: 0.9792 - val_loss: 0.3237 - val_accuracy: 0.9583\n",
            "Epoch 683/1000\n",
            "96/96 [==============================] - 0s 115us/step - loss: 0.3076 - accuracy: 0.9792 - val_loss: 0.3248 - val_accuracy: 0.9583\n",
            "Epoch 684/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.3069 - accuracy: 0.9792 - val_loss: 0.3239 - val_accuracy: 0.9583\n",
            "Epoch 685/1000\n",
            "96/96 [==============================] - 0s 135us/step - loss: 0.3060 - accuracy: 0.9792 - val_loss: 0.3230 - val_accuracy: 0.9583\n",
            "Epoch 686/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.3058 - accuracy: 0.9792 - val_loss: 0.3228 - val_accuracy: 0.9583\n",
            "Epoch 687/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.3055 - accuracy: 0.9792 - val_loss: 0.3221 - val_accuracy: 0.9583\n",
            "Epoch 688/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.3056 - accuracy: 0.9792 - val_loss: 0.3217 - val_accuracy: 0.9583\n",
            "Epoch 689/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.3053 - accuracy: 0.9792 - val_loss: 0.3219 - val_accuracy: 0.9583\n",
            "Epoch 690/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.3049 - accuracy: 0.9792 - val_loss: 0.3220 - val_accuracy: 0.9583\n",
            "Epoch 691/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.3045 - accuracy: 0.9792 - val_loss: 0.3215 - val_accuracy: 0.9583\n",
            "Epoch 692/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.3049 - accuracy: 0.9792 - val_loss: 0.3213 - val_accuracy: 0.9583\n",
            "Epoch 693/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.3090 - accuracy: 0.9688 - val_loss: 0.3227 - val_accuracy: 0.9583\n",
            "Epoch 694/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.3058 - accuracy: 0.9583 - val_loss: 0.3192 - val_accuracy: 0.9583\n",
            "Epoch 695/1000\n",
            "96/96 [==============================] - 0s 78us/step - loss: 0.3055 - accuracy: 0.9583 - val_loss: 0.3170 - val_accuracy: 0.9583\n",
            "Epoch 696/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.3037 - accuracy: 0.9792 - val_loss: 0.3189 - val_accuracy: 0.9583\n",
            "Epoch 697/1000\n",
            "96/96 [==============================] - 0s 79us/step - loss: 0.3039 - accuracy: 0.9688 - val_loss: 0.3178 - val_accuracy: 0.9583\n",
            "Epoch 698/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.3032 - accuracy: 0.9792 - val_loss: 0.3195 - val_accuracy: 0.9583\n",
            "Epoch 699/1000\n",
            "96/96 [==============================] - 0s 126us/step - loss: 0.3030 - accuracy: 0.9792 - val_loss: 0.3179 - val_accuracy: 0.9583\n",
            "Epoch 700/1000\n",
            "96/96 [==============================] - 0s 77us/step - loss: 0.3028 - accuracy: 0.9688 - val_loss: 0.3165 - val_accuracy: 0.9583\n",
            "Epoch 701/1000\n",
            "96/96 [==============================] - 0s 70us/step - loss: 0.3035 - accuracy: 0.9688 - val_loss: 0.3178 - val_accuracy: 0.9583\n",
            "Epoch 702/1000\n",
            "96/96 [==============================] - 0s 75us/step - loss: 0.3013 - accuracy: 0.9792 - val_loss: 0.3174 - val_accuracy: 0.9583\n",
            "Epoch 703/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.3016 - accuracy: 0.9792 - val_loss: 0.3173 - val_accuracy: 0.9583\n",
            "Epoch 704/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.3015 - accuracy: 0.9792 - val_loss: 0.3175 - val_accuracy: 0.9583\n",
            "Epoch 705/1000\n",
            "96/96 [==============================] - 0s 132us/step - loss: 0.3034 - accuracy: 0.9688 - val_loss: 0.3193 - val_accuracy: 0.9583\n",
            "Epoch 706/1000\n",
            "96/96 [==============================] - 0s 123us/step - loss: 0.3006 - accuracy: 0.9688 - val_loss: 0.3166 - val_accuracy: 0.9583\n",
            "Epoch 707/1000\n",
            "96/96 [==============================] - 0s 74us/step - loss: 0.3006 - accuracy: 0.9792 - val_loss: 0.3170 - val_accuracy: 0.9583\n",
            "Epoch 708/1000\n",
            "96/96 [==============================] - 0s 73us/step - loss: 0.3012 - accuracy: 0.9792 - val_loss: 0.3177 - val_accuracy: 0.9583\n",
            "Epoch 709/1000\n",
            "96/96 [==============================] - 0s 65us/step - loss: 0.3013 - accuracy: 0.9792 - val_loss: 0.3162 - val_accuracy: 0.9583\n",
            "Epoch 710/1000\n",
            "96/96 [==============================] - 0s 77us/step - loss: 0.2993 - accuracy: 0.9688 - val_loss: 0.3146 - val_accuracy: 0.9583\n",
            "Epoch 711/1000\n",
            "96/96 [==============================] - 0s 118us/step - loss: 0.2989 - accuracy: 0.9792 - val_loss: 0.3153 - val_accuracy: 0.9583\n",
            "Epoch 712/1000\n",
            "96/96 [==============================] - 0s 128us/step - loss: 0.2985 - accuracy: 0.9792 - val_loss: 0.3145 - val_accuracy: 0.9583\n",
            "Epoch 713/1000\n",
            "96/96 [==============================] - 0s 126us/step - loss: 0.3002 - accuracy: 0.9688 - val_loss: 0.3155 - val_accuracy: 0.9583\n",
            "Epoch 714/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.2980 - accuracy: 0.9792 - val_loss: 0.3149 - val_accuracy: 0.9583\n",
            "Epoch 715/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.3014 - accuracy: 0.9688 - val_loss: 0.3128 - val_accuracy: 0.9583\n",
            "Epoch 716/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.2979 - accuracy: 0.9688 - val_loss: 0.3119 - val_accuracy: 0.9583\n",
            "Epoch 717/1000\n",
            "96/96 [==============================] - 0s 118us/step - loss: 0.2989 - accuracy: 0.9583 - val_loss: 0.3121 - val_accuracy: 0.9583\n",
            "Epoch 718/1000\n",
            "96/96 [==============================] - 0s 114us/step - loss: 0.2971 - accuracy: 0.9792 - val_loss: 0.3129 - val_accuracy: 0.9583\n",
            "Epoch 719/1000\n",
            "96/96 [==============================] - 0s 120us/step - loss: 0.2966 - accuracy: 0.9792 - val_loss: 0.3126 - val_accuracy: 0.9583\n",
            "Epoch 720/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.2963 - accuracy: 0.9792 - val_loss: 0.3126 - val_accuracy: 0.9583\n",
            "Epoch 721/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.2965 - accuracy: 0.9792 - val_loss: 0.3130 - val_accuracy: 0.9583\n",
            "Epoch 722/1000\n",
            "96/96 [==============================] - 0s 117us/step - loss: 0.2969 - accuracy: 0.9583 - val_loss: 0.3108 - val_accuracy: 0.9583\n",
            "Epoch 723/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.2976 - accuracy: 0.9583 - val_loss: 0.3090 - val_accuracy: 0.9583\n",
            "Epoch 724/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.2972 - accuracy: 0.9583 - val_loss: 0.3082 - val_accuracy: 0.9583\n",
            "Epoch 725/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.2952 - accuracy: 0.9792 - val_loss: 0.3089 - val_accuracy: 0.9583\n",
            "Epoch 726/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.2963 - accuracy: 0.9688 - val_loss: 0.3108 - val_accuracy: 0.9583\n",
            "Epoch 727/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.2944 - accuracy: 0.9792 - val_loss: 0.3103 - val_accuracy: 0.9583\n",
            "Epoch 728/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.2947 - accuracy: 0.9792 - val_loss: 0.3103 - val_accuracy: 0.9583\n",
            "Epoch 729/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.2956 - accuracy: 0.9792 - val_loss: 0.3098 - val_accuracy: 0.9583\n",
            "Epoch 730/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.2951 - accuracy: 0.9688 - val_loss: 0.3091 - val_accuracy: 0.9583\n",
            "Epoch 731/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.2934 - accuracy: 0.9792 - val_loss: 0.3090 - val_accuracy: 0.9583\n",
            "Epoch 732/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.2962 - accuracy: 0.9688 - val_loss: 0.3069 - val_accuracy: 0.9583\n",
            "Epoch 733/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.2933 - accuracy: 0.9792 - val_loss: 0.3080 - val_accuracy: 0.9583\n",
            "Epoch 734/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.2939 - accuracy: 0.9792 - val_loss: 0.3097 - val_accuracy: 0.9583\n",
            "Epoch 735/1000\n",
            "96/96 [==============================] - 0s 76us/step - loss: 0.2931 - accuracy: 0.9792 - val_loss: 0.3102 - val_accuracy: 0.9583\n",
            "Epoch 736/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.2922 - accuracy: 0.9792 - val_loss: 0.3086 - val_accuracy: 0.9583\n",
            "Epoch 737/1000\n",
            "96/96 [==============================] - 0s 79us/step - loss: 0.2919 - accuracy: 0.9792 - val_loss: 0.3076 - val_accuracy: 0.9583\n",
            "Epoch 738/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.2934 - accuracy: 0.9792 - val_loss: 0.3064 - val_accuracy: 0.9583\n",
            "Epoch 739/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.2915 - accuracy: 0.9792 - val_loss: 0.3071 - val_accuracy: 0.9583\n",
            "Epoch 740/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.2912 - accuracy: 0.9792 - val_loss: 0.3065 - val_accuracy: 0.9583\n",
            "Epoch 741/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.2929 - accuracy: 0.9688 - val_loss: 0.3075 - val_accuracy: 0.9583\n",
            "Epoch 742/1000\n",
            "96/96 [==============================] - 0s 114us/step - loss: 0.2909 - accuracy: 0.9792 - val_loss: 0.3066 - val_accuracy: 0.9583\n",
            "Epoch 743/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.2905 - accuracy: 0.9792 - val_loss: 0.3058 - val_accuracy: 0.9583\n",
            "Epoch 744/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.2924 - accuracy: 0.9688 - val_loss: 0.3073 - val_accuracy: 0.9583\n",
            "Epoch 745/1000\n",
            "96/96 [==============================] - 0s 126us/step - loss: 0.2912 - accuracy: 0.9792 - val_loss: 0.3068 - val_accuracy: 0.9583\n",
            "Epoch 746/1000\n",
            "96/96 [==============================] - 0s 116us/step - loss: 0.2900 - accuracy: 0.9896 - val_loss: 0.3052 - val_accuracy: 0.9583\n",
            "Epoch 747/1000\n",
            "96/96 [==============================] - 0s 150us/step - loss: 0.2907 - accuracy: 0.9792 - val_loss: 0.3065 - val_accuracy: 0.9583\n",
            "Epoch 748/1000\n",
            "96/96 [==============================] - 0s 121us/step - loss: 0.2892 - accuracy: 0.9688 - val_loss: 0.3048 - val_accuracy: 0.9583\n",
            "Epoch 749/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.2888 - accuracy: 0.9792 - val_loss: 0.3048 - val_accuracy: 0.9583\n",
            "Epoch 750/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.2886 - accuracy: 0.9792 - val_loss: 0.3042 - val_accuracy: 0.9583\n",
            "Epoch 751/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.2894 - accuracy: 0.9688 - val_loss: 0.3027 - val_accuracy: 0.9583\n",
            "Epoch 752/1000\n",
            "96/96 [==============================] - 0s 118us/step - loss: 0.2882 - accuracy: 0.9792 - val_loss: 0.3024 - val_accuracy: 0.9583\n",
            "Epoch 753/1000\n",
            "96/96 [==============================] - 0s 120us/step - loss: 0.2931 - accuracy: 0.9792 - val_loss: 0.3002 - val_accuracy: 0.9583\n",
            "Epoch 754/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.2888 - accuracy: 0.9792 - val_loss: 0.3006 - val_accuracy: 0.9583\n",
            "Epoch 755/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.2888 - accuracy: 0.9792 - val_loss: 0.3030 - val_accuracy: 0.9583\n",
            "Epoch 756/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.2873 - accuracy: 0.9792 - val_loss: 0.3035 - val_accuracy: 0.9583\n",
            "Epoch 757/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.2872 - accuracy: 0.9792 - val_loss: 0.3036 - val_accuracy: 0.9583\n",
            "Epoch 758/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.2866 - accuracy: 0.9792 - val_loss: 0.3032 - val_accuracy: 0.9583\n",
            "Epoch 759/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.2868 - accuracy: 0.9792 - val_loss: 0.3016 - val_accuracy: 0.9583\n",
            "Epoch 760/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.2863 - accuracy: 0.9792 - val_loss: 0.3022 - val_accuracy: 0.9583\n",
            "Epoch 761/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.2860 - accuracy: 0.9792 - val_loss: 0.3022 - val_accuracy: 0.9583\n",
            "Epoch 762/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.2868 - accuracy: 0.9792 - val_loss: 0.3004 - val_accuracy: 0.9583\n",
            "Epoch 763/1000\n",
            "96/96 [==============================] - 0s 121us/step - loss: 0.2875 - accuracy: 0.9688 - val_loss: 0.2992 - val_accuracy: 0.9583\n",
            "Epoch 764/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.2850 - accuracy: 0.9792 - val_loss: 0.3000 - val_accuracy: 0.9583\n",
            "Epoch 765/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.2849 - accuracy: 0.9792 - val_loss: 0.2993 - val_accuracy: 0.9583\n",
            "Epoch 766/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.2849 - accuracy: 0.9792 - val_loss: 0.2993 - val_accuracy: 0.9583\n",
            "Epoch 767/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.2850 - accuracy: 0.9688 - val_loss: 0.2984 - val_accuracy: 0.9583\n",
            "Epoch 768/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.2854 - accuracy: 0.9688 - val_loss: 0.3004 - val_accuracy: 0.9583\n",
            "Epoch 769/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.2859 - accuracy: 0.9688 - val_loss: 0.2981 - val_accuracy: 0.9583\n",
            "Epoch 770/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.2854 - accuracy: 0.9792 - val_loss: 0.2988 - val_accuracy: 0.9583\n",
            "Epoch 771/1000\n",
            "96/96 [==============================] - 0s 84us/step - loss: 0.2833 - accuracy: 0.9792 - val_loss: 0.2985 - val_accuracy: 0.9583\n",
            "Epoch 772/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.2834 - accuracy: 0.9792 - val_loss: 0.2987 - val_accuracy: 0.9583\n",
            "Epoch 773/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.2847 - accuracy: 0.9792 - val_loss: 0.2991 - val_accuracy: 0.9583\n",
            "Epoch 774/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.2858 - accuracy: 0.9688 - val_loss: 0.2970 - val_accuracy: 0.9583\n",
            "Epoch 775/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.2828 - accuracy: 0.9792 - val_loss: 0.2981 - val_accuracy: 0.9583\n",
            "Epoch 776/1000\n",
            "96/96 [==============================] - 0s 119us/step - loss: 0.2835 - accuracy: 0.9792 - val_loss: 0.2983 - val_accuracy: 0.9583\n",
            "Epoch 777/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.2821 - accuracy: 0.9792 - val_loss: 0.2968 - val_accuracy: 0.9583\n",
            "Epoch 778/1000\n",
            "96/96 [==============================] - 0s 117us/step - loss: 0.2819 - accuracy: 0.9792 - val_loss: 0.2977 - val_accuracy: 0.9583\n",
            "Epoch 779/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.2821 - accuracy: 0.9792 - val_loss: 0.2982 - val_accuracy: 0.9583\n",
            "Epoch 780/1000\n",
            "96/96 [==============================] - 0s 123us/step - loss: 0.2811 - accuracy: 0.9792 - val_loss: 0.2968 - val_accuracy: 0.9583\n",
            "Epoch 781/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.2808 - accuracy: 0.9792 - val_loss: 0.2963 - val_accuracy: 0.9583\n",
            "Epoch 782/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.2806 - accuracy: 0.9792 - val_loss: 0.2964 - val_accuracy: 0.9583\n",
            "Epoch 783/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.2807 - accuracy: 0.9792 - val_loss: 0.2964 - val_accuracy: 0.9583\n",
            "Epoch 784/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.2828 - accuracy: 0.9688 - val_loss: 0.2966 - val_accuracy: 0.9583\n",
            "Epoch 785/1000\n",
            "96/96 [==============================] - 0s 144us/step - loss: 0.2805 - accuracy: 0.9792 - val_loss: 0.2955 - val_accuracy: 0.9583\n",
            "Epoch 786/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.2802 - accuracy: 0.9792 - val_loss: 0.2942 - val_accuracy: 0.9583\n",
            "Epoch 787/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.2815 - accuracy: 0.9792 - val_loss: 0.2942 - val_accuracy: 0.9583\n",
            "Epoch 788/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.2800 - accuracy: 0.9792 - val_loss: 0.2939 - val_accuracy: 0.9583\n",
            "Epoch 789/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.2818 - accuracy: 0.9792 - val_loss: 0.2939 - val_accuracy: 0.9583\n",
            "Epoch 790/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.2791 - accuracy: 0.9792 - val_loss: 0.2948 - val_accuracy: 0.9583\n",
            "Epoch 791/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.2789 - accuracy: 0.9792 - val_loss: 0.2933 - val_accuracy: 0.9583\n",
            "Epoch 792/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.2804 - accuracy: 0.9688 - val_loss: 0.2921 - val_accuracy: 0.9583\n",
            "Epoch 793/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.2827 - accuracy: 0.9792 - val_loss: 0.2919 - val_accuracy: 0.9583\n",
            "Epoch 794/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.2815 - accuracy: 0.9688 - val_loss: 0.2933 - val_accuracy: 0.9583\n",
            "Epoch 795/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.2774 - accuracy: 0.9792 - val_loss: 0.2927 - val_accuracy: 0.9583\n",
            "Epoch 796/1000\n",
            "96/96 [==============================] - 0s 115us/step - loss: 0.2798 - accuracy: 0.9688 - val_loss: 0.2907 - val_accuracy: 0.9583\n",
            "Epoch 797/1000\n",
            "96/96 [==============================] - 0s 81us/step - loss: 0.2789 - accuracy: 0.9688 - val_loss: 0.2899 - val_accuracy: 0.9583\n",
            "Epoch 798/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.2785 - accuracy: 0.9688 - val_loss: 0.2926 - val_accuracy: 0.9583\n",
            "Epoch 799/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.2773 - accuracy: 0.9792 - val_loss: 0.2930 - val_accuracy: 0.9583\n",
            "Epoch 800/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.2784 - accuracy: 0.9792 - val_loss: 0.2903 - val_accuracy: 0.9583\n",
            "Epoch 801/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.2764 - accuracy: 0.9792 - val_loss: 0.2914 - val_accuracy: 0.9583\n",
            "Epoch 802/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.2768 - accuracy: 0.9792 - val_loss: 0.2897 - val_accuracy: 0.9583\n",
            "Epoch 803/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.2775 - accuracy: 0.9688 - val_loss: 0.2893 - val_accuracy: 0.9583\n",
            "Epoch 804/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.2752 - accuracy: 0.9792 - val_loss: 0.2897 - val_accuracy: 0.9583\n",
            "Epoch 805/1000\n",
            "96/96 [==============================] - 0s 117us/step - loss: 0.2752 - accuracy: 0.9792 - val_loss: 0.2900 - val_accuracy: 0.9583\n",
            "Epoch 806/1000\n",
            "96/96 [==============================] - 0s 115us/step - loss: 0.2753 - accuracy: 0.9792 - val_loss: 0.2896 - val_accuracy: 0.9583\n",
            "Epoch 807/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.2745 - accuracy: 0.9792 - val_loss: 0.2897 - val_accuracy: 0.9583\n",
            "Epoch 808/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.2765 - accuracy: 0.9792 - val_loss: 0.2878 - val_accuracy: 0.9583\n",
            "Epoch 809/1000\n",
            "96/96 [==============================] - 0s 116us/step - loss: 0.2742 - accuracy: 0.9792 - val_loss: 0.2886 - val_accuracy: 0.9583\n",
            "Epoch 810/1000\n",
            "96/96 [==============================] - 0s 154us/step - loss: 0.2741 - accuracy: 0.9792 - val_loss: 0.2891 - val_accuracy: 0.9583\n",
            "Epoch 811/1000\n",
            "96/96 [==============================] - 0s 116us/step - loss: 0.2741 - accuracy: 0.9688 - val_loss: 0.2880 - val_accuracy: 0.9583\n",
            "Epoch 812/1000\n",
            "96/96 [==============================] - 0s 118us/step - loss: 0.2745 - accuracy: 0.9792 - val_loss: 0.2875 - val_accuracy: 0.9583\n",
            "Epoch 813/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.2744 - accuracy: 0.9792 - val_loss: 0.2880 - val_accuracy: 0.9583\n",
            "Epoch 814/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.2747 - accuracy: 0.9583 - val_loss: 0.2861 - val_accuracy: 0.9583\n",
            "Epoch 815/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.2729 - accuracy: 0.9792 - val_loss: 0.2862 - val_accuracy: 0.9583\n",
            "Epoch 816/1000\n",
            "96/96 [==============================] - 0s 126us/step - loss: 0.2724 - accuracy: 0.9792 - val_loss: 0.2864 - val_accuracy: 0.9583\n",
            "Epoch 817/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.2722 - accuracy: 0.9792 - val_loss: 0.2866 - val_accuracy: 0.9583\n",
            "Epoch 818/1000\n",
            "96/96 [==============================] - 0s 81us/step - loss: 0.2733 - accuracy: 0.9792 - val_loss: 0.2877 - val_accuracy: 0.9583\n",
            "Epoch 819/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.2718 - accuracy: 0.9792 - val_loss: 0.2866 - val_accuracy: 0.9583\n",
            "Epoch 820/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.2721 - accuracy: 0.9792 - val_loss: 0.2873 - val_accuracy: 0.9583\n",
            "Epoch 821/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.2720 - accuracy: 0.9792 - val_loss: 0.2873 - val_accuracy: 0.9583\n",
            "Epoch 822/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.2715 - accuracy: 0.9688 - val_loss: 0.2861 - val_accuracy: 0.9583\n",
            "Epoch 823/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.2714 - accuracy: 0.9792 - val_loss: 0.2867 - val_accuracy: 0.9583\n",
            "Epoch 824/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.2708 - accuracy: 0.9792 - val_loss: 0.2859 - val_accuracy: 0.9583\n",
            "Epoch 825/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.2749 - accuracy: 0.9688 - val_loss: 0.2836 - val_accuracy: 0.9583\n",
            "Epoch 826/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.2722 - accuracy: 0.9792 - val_loss: 0.2856 - val_accuracy: 0.9583\n",
            "Epoch 827/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.2703 - accuracy: 0.9792 - val_loss: 0.2858 - val_accuracy: 0.9583\n",
            "Epoch 828/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.2715 - accuracy: 0.9792 - val_loss: 0.2863 - val_accuracy: 0.9583\n",
            "Epoch 829/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.2701 - accuracy: 0.9792 - val_loss: 0.2863 - val_accuracy: 0.9583\n",
            "Epoch 830/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.2701 - accuracy: 0.9792 - val_loss: 0.2854 - val_accuracy: 0.9583\n",
            "Epoch 831/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.2696 - accuracy: 0.9583 - val_loss: 0.2839 - val_accuracy: 0.9583\n",
            "Epoch 832/1000\n",
            "96/96 [==============================] - 0s 84us/step - loss: 0.2737 - accuracy: 0.9688 - val_loss: 0.2831 - val_accuracy: 0.9583\n",
            "Epoch 833/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.2692 - accuracy: 0.9792 - val_loss: 0.2820 - val_accuracy: 0.9583\n",
            "Epoch 834/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.2717 - accuracy: 0.9688 - val_loss: 0.2851 - val_accuracy: 0.9583\n",
            "Epoch 835/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.2682 - accuracy: 0.9792 - val_loss: 0.2844 - val_accuracy: 0.9583\n",
            "Epoch 836/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.2681 - accuracy: 0.9792 - val_loss: 0.2834 - val_accuracy: 0.9583\n",
            "Epoch 837/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.2676 - accuracy: 0.9792 - val_loss: 0.2831 - val_accuracy: 0.9583\n",
            "Epoch 838/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.2677 - accuracy: 0.9792 - val_loss: 0.2823 - val_accuracy: 0.9583\n",
            "Epoch 839/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.2674 - accuracy: 0.9792 - val_loss: 0.2816 - val_accuracy: 0.9583\n",
            "Epoch 840/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.2669 - accuracy: 0.9792 - val_loss: 0.2813 - val_accuracy: 0.9583\n",
            "Epoch 841/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.2678 - accuracy: 0.9688 - val_loss: 0.2810 - val_accuracy: 0.9583\n",
            "Epoch 842/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.2674 - accuracy: 0.9688 - val_loss: 0.2799 - val_accuracy: 0.9583\n",
            "Epoch 843/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.2671 - accuracy: 0.9688 - val_loss: 0.2816 - val_accuracy: 0.9583\n",
            "Epoch 844/1000\n",
            "96/96 [==============================] - 0s 78us/step - loss: 0.2661 - accuracy: 0.9792 - val_loss: 0.2811 - val_accuracy: 0.9583\n",
            "Epoch 845/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.2668 - accuracy: 0.9792 - val_loss: 0.2822 - val_accuracy: 0.9583\n",
            "Epoch 846/1000\n",
            "96/96 [==============================] - 0s 116us/step - loss: 0.2656 - accuracy: 0.9792 - val_loss: 0.2813 - val_accuracy: 0.9583\n",
            "Epoch 847/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.2665 - accuracy: 0.9792 - val_loss: 0.2809 - val_accuracy: 0.9583\n",
            "Epoch 848/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.2666 - accuracy: 0.9792 - val_loss: 0.2820 - val_accuracy: 0.9583\n",
            "Epoch 849/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.2651 - accuracy: 0.9792 - val_loss: 0.2809 - val_accuracy: 0.9583\n",
            "Epoch 850/1000\n",
            "96/96 [==============================] - 0s 114us/step - loss: 0.2683 - accuracy: 0.9688 - val_loss: 0.2780 - val_accuracy: 0.9583\n",
            "Epoch 851/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.2645 - accuracy: 0.9792 - val_loss: 0.2784 - val_accuracy: 0.9583\n",
            "Epoch 852/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.2655 - accuracy: 0.9688 - val_loss: 0.2777 - val_accuracy: 0.9583\n",
            "Epoch 853/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.2659 - accuracy: 0.9792 - val_loss: 0.2793 - val_accuracy: 0.9583\n",
            "Epoch 854/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.2650 - accuracy: 0.9688 - val_loss: 0.2779 - val_accuracy: 0.9583\n",
            "Epoch 855/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.2653 - accuracy: 0.9688 - val_loss: 0.2768 - val_accuracy: 0.9583\n",
            "Epoch 856/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.2641 - accuracy: 0.9792 - val_loss: 0.2766 - val_accuracy: 0.9583\n",
            "Epoch 857/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.2639 - accuracy: 0.9792 - val_loss: 0.2781 - val_accuracy: 0.9583\n",
            "Epoch 858/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.2669 - accuracy: 0.9792 - val_loss: 0.2765 - val_accuracy: 0.9583\n",
            "Epoch 859/1000\n",
            "96/96 [==============================] - 0s 74us/step - loss: 0.2631 - accuracy: 0.9792 - val_loss: 0.2776 - val_accuracy: 0.9583\n",
            "Epoch 860/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.2628 - accuracy: 0.9792 - val_loss: 0.2780 - val_accuracy: 0.9583\n",
            "Epoch 861/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.2638 - accuracy: 0.9792 - val_loss: 0.2764 - val_accuracy: 0.9583\n",
            "Epoch 862/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.2624 - accuracy: 0.9792 - val_loss: 0.2771 - val_accuracy: 0.9583\n",
            "Epoch 863/1000\n",
            "96/96 [==============================] - 0s 115us/step - loss: 0.2619 - accuracy: 0.9792 - val_loss: 0.2766 - val_accuracy: 0.9583\n",
            "Epoch 864/1000\n",
            "96/96 [==============================] - 0s 134us/step - loss: 0.2616 - accuracy: 0.9792 - val_loss: 0.2766 - val_accuracy: 0.9583\n",
            "Epoch 865/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.2621 - accuracy: 0.9688 - val_loss: 0.2754 - val_accuracy: 0.9583\n",
            "Epoch 866/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.2613 - accuracy: 0.9792 - val_loss: 0.2753 - val_accuracy: 0.9583\n",
            "Epoch 867/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.2619 - accuracy: 0.9792 - val_loss: 0.2751 - val_accuracy: 0.9583\n",
            "Epoch 868/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.2610 - accuracy: 0.9792 - val_loss: 0.2756 - val_accuracy: 0.9583\n",
            "Epoch 869/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.2609 - accuracy: 0.9792 - val_loss: 0.2755 - val_accuracy: 0.9583\n",
            "Epoch 870/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.2613 - accuracy: 0.9792 - val_loss: 0.2757 - val_accuracy: 0.9583\n",
            "Epoch 871/1000\n",
            "96/96 [==============================] - 0s 124us/step - loss: 0.2600 - accuracy: 0.9792 - val_loss: 0.2752 - val_accuracy: 0.9583\n",
            "Epoch 872/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.2613 - accuracy: 0.9688 - val_loss: 0.2734 - val_accuracy: 0.9583\n",
            "Epoch 873/1000\n",
            "96/96 [==============================] - 0s 167us/step - loss: 0.2611 - accuracy: 0.9688 - val_loss: 0.2751 - val_accuracy: 0.9583\n",
            "Epoch 874/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.2608 - accuracy: 0.9792 - val_loss: 0.2745 - val_accuracy: 0.9583\n",
            "Epoch 875/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.2598 - accuracy: 0.9792 - val_loss: 0.2738 - val_accuracy: 0.9583\n",
            "Epoch 876/1000\n",
            "96/96 [==============================] - 0s 132us/step - loss: 0.2592 - accuracy: 0.9792 - val_loss: 0.2741 - val_accuracy: 0.9583\n",
            "Epoch 877/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.2593 - accuracy: 0.9792 - val_loss: 0.2746 - val_accuracy: 0.9583\n",
            "Epoch 878/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.2604 - accuracy: 0.9583 - val_loss: 0.2736 - val_accuracy: 0.9583\n",
            "Epoch 879/1000\n",
            "96/96 [==============================] - 0s 114us/step - loss: 0.2593 - accuracy: 0.9792 - val_loss: 0.2745 - val_accuracy: 0.9583\n",
            "Epoch 880/1000\n",
            "96/96 [==============================] - 0s 126us/step - loss: 0.2588 - accuracy: 0.9688 - val_loss: 0.2732 - val_accuracy: 0.9583\n",
            "Epoch 881/1000\n",
            "96/96 [==============================] - 0s 79us/step - loss: 0.2580 - accuracy: 0.9792 - val_loss: 0.2732 - val_accuracy: 0.9583\n",
            "Epoch 882/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.2579 - accuracy: 0.9792 - val_loss: 0.2722 - val_accuracy: 0.9583\n",
            "Epoch 883/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.2576 - accuracy: 0.9792 - val_loss: 0.2722 - val_accuracy: 0.9583\n",
            "Epoch 884/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.2573 - accuracy: 0.9792 - val_loss: 0.2720 - val_accuracy: 0.9583\n",
            "Epoch 885/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.2577 - accuracy: 0.9792 - val_loss: 0.2718 - val_accuracy: 0.9583\n",
            "Epoch 886/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.2581 - accuracy: 0.9792 - val_loss: 0.2720 - val_accuracy: 0.9583\n",
            "Epoch 887/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.2567 - accuracy: 0.9792 - val_loss: 0.2717 - val_accuracy: 0.9583\n",
            "Epoch 888/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.2572 - accuracy: 0.9792 - val_loss: 0.2716 - val_accuracy: 0.9583\n",
            "Epoch 889/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.2586 - accuracy: 0.9792 - val_loss: 0.2722 - val_accuracy: 0.9583\n",
            "Epoch 890/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.2567 - accuracy: 0.9688 - val_loss: 0.2709 - val_accuracy: 0.9583\n",
            "Epoch 891/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.2559 - accuracy: 0.9792 - val_loss: 0.2706 - val_accuracy: 0.9583\n",
            "Epoch 892/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.2583 - accuracy: 0.9792 - val_loss: 0.2720 - val_accuracy: 0.9583\n",
            "Epoch 893/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.2575 - accuracy: 0.9583 - val_loss: 0.2698 - val_accuracy: 0.9583\n",
            "Epoch 894/1000\n",
            "96/96 [==============================] - 0s 112us/step - loss: 0.2558 - accuracy: 0.9792 - val_loss: 0.2702 - val_accuracy: 0.9583\n",
            "Epoch 895/1000\n",
            "96/96 [==============================] - 0s 96us/step - loss: 0.2552 - accuracy: 0.9792 - val_loss: 0.2692 - val_accuracy: 0.9583\n",
            "Epoch 896/1000\n",
            "96/96 [==============================] - 0s 102us/step - loss: 0.2549 - accuracy: 0.9792 - val_loss: 0.2693 - val_accuracy: 0.9583\n",
            "Epoch 897/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.2566 - accuracy: 0.9792 - val_loss: 0.2676 - val_accuracy: 0.9583\n",
            "Epoch 898/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.2549 - accuracy: 0.9688 - val_loss: 0.2687 - val_accuracy: 0.9583\n",
            "Epoch 899/1000\n",
            "96/96 [==============================] - 0s 99us/step - loss: 0.2549 - accuracy: 0.9792 - val_loss: 0.2696 - val_accuracy: 0.9583\n",
            "Epoch 900/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.2549 - accuracy: 0.9792 - val_loss: 0.2701 - val_accuracy: 0.9583\n",
            "Epoch 901/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.2543 - accuracy: 0.9792 - val_loss: 0.2683 - val_accuracy: 0.9583\n",
            "Epoch 902/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.2541 - accuracy: 0.9792 - val_loss: 0.2674 - val_accuracy: 0.9583\n",
            "Epoch 903/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.2534 - accuracy: 0.9792 - val_loss: 0.2677 - val_accuracy: 0.9583\n",
            "Epoch 904/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.2541 - accuracy: 0.9896 - val_loss: 0.2664 - val_accuracy: 0.9583\n",
            "Epoch 905/1000\n",
            "96/96 [==============================] - 0s 78us/step - loss: 0.2538 - accuracy: 0.9792 - val_loss: 0.2679 - val_accuracy: 0.9583\n",
            "Epoch 906/1000\n",
            "96/96 [==============================] - 0s 115us/step - loss: 0.2535 - accuracy: 0.9688 - val_loss: 0.2666 - val_accuracy: 0.9583\n",
            "Epoch 907/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.2532 - accuracy: 0.9792 - val_loss: 0.2667 - val_accuracy: 0.9583\n",
            "Epoch 908/1000\n",
            "96/96 [==============================] - 0s 74us/step - loss: 0.2525 - accuracy: 0.9792 - val_loss: 0.2666 - val_accuracy: 0.9583\n",
            "Epoch 909/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.2530 - accuracy: 0.9896 - val_loss: 0.2654 - val_accuracy: 0.9583\n",
            "Epoch 910/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.2528 - accuracy: 0.9792 - val_loss: 0.2650 - val_accuracy: 0.9583\n",
            "Epoch 911/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.2536 - accuracy: 0.9792 - val_loss: 0.2640 - val_accuracy: 0.9583\n",
            "Epoch 912/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.2522 - accuracy: 0.9792 - val_loss: 0.2647 - val_accuracy: 0.9583\n",
            "Epoch 913/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.2513 - accuracy: 0.9792 - val_loss: 0.2649 - val_accuracy: 0.9583\n",
            "Epoch 914/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.2513 - accuracy: 0.9792 - val_loss: 0.2652 - val_accuracy: 0.9583\n",
            "Epoch 915/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.2517 - accuracy: 0.9792 - val_loss: 0.2646 - val_accuracy: 0.9583\n",
            "Epoch 916/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.2510 - accuracy: 0.9792 - val_loss: 0.2643 - val_accuracy: 0.9583\n",
            "Epoch 917/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.2515 - accuracy: 0.9688 - val_loss: 0.2655 - val_accuracy: 0.9583\n",
            "Epoch 918/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.2508 - accuracy: 0.9792 - val_loss: 0.2657 - val_accuracy: 0.9583\n",
            "Epoch 919/1000\n",
            "96/96 [==============================] - 0s 114us/step - loss: 0.2501 - accuracy: 0.9792 - val_loss: 0.2649 - val_accuracy: 0.9583\n",
            "Epoch 920/1000\n",
            "96/96 [==============================] - 0s 106us/step - loss: 0.2504 - accuracy: 0.9792 - val_loss: 0.2638 - val_accuracy: 0.9583\n",
            "Epoch 921/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.2500 - accuracy: 0.9792 - val_loss: 0.2634 - val_accuracy: 0.9583\n",
            "Epoch 922/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.2496 - accuracy: 0.9792 - val_loss: 0.2639 - val_accuracy: 0.9583\n",
            "Epoch 923/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.2494 - accuracy: 0.9792 - val_loss: 0.2637 - val_accuracy: 0.9583\n",
            "Epoch 924/1000\n",
            "96/96 [==============================] - 0s 137us/step - loss: 0.2515 - accuracy: 0.9688 - val_loss: 0.2646 - val_accuracy: 0.9583\n",
            "Epoch 925/1000\n",
            "96/96 [==============================] - 0s 114us/step - loss: 0.2493 - accuracy: 0.9792 - val_loss: 0.2647 - val_accuracy: 0.9583\n",
            "Epoch 926/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.2498 - accuracy: 0.9792 - val_loss: 0.2652 - val_accuracy: 0.9583\n",
            "Epoch 927/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.2512 - accuracy: 0.9792 - val_loss: 0.2661 - val_accuracy: 0.9583\n",
            "Epoch 928/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.2489 - accuracy: 0.9792 - val_loss: 0.2652 - val_accuracy: 0.9583\n",
            "Epoch 929/1000\n",
            "96/96 [==============================] - 0s 131us/step - loss: 0.2492 - accuracy: 0.9792 - val_loss: 0.2645 - val_accuracy: 0.9583\n",
            "Epoch 930/1000\n",
            "96/96 [==============================] - 0s 100us/step - loss: 0.2483 - accuracy: 0.9792 - val_loss: 0.2640 - val_accuracy: 0.9583\n",
            "Epoch 931/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.2480 - accuracy: 0.9688 - val_loss: 0.2623 - val_accuracy: 0.9583\n",
            "Epoch 932/1000\n",
            "96/96 [==============================] - 0s 89us/step - loss: 0.2482 - accuracy: 0.9792 - val_loss: 0.2616 - val_accuracy: 0.9583\n",
            "Epoch 933/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.2475 - accuracy: 0.9792 - val_loss: 0.2612 - val_accuracy: 0.9583\n",
            "Epoch 934/1000\n",
            "96/96 [==============================] - 0s 113us/step - loss: 0.2482 - accuracy: 0.9792 - val_loss: 0.2608 - val_accuracy: 0.9583\n",
            "Epoch 935/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.2485 - accuracy: 0.9792 - val_loss: 0.2623 - val_accuracy: 0.9583\n",
            "Epoch 936/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.2468 - accuracy: 0.9792 - val_loss: 0.2619 - val_accuracy: 0.9583\n",
            "Epoch 937/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.2467 - accuracy: 0.9792 - val_loss: 0.2614 - val_accuracy: 0.9583\n",
            "Epoch 938/1000\n",
            "96/96 [==============================] - 0s 74us/step - loss: 0.2475 - accuracy: 0.9688 - val_loss: 0.2599 - val_accuracy: 0.9583\n",
            "Epoch 939/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.2468 - accuracy: 0.9792 - val_loss: 0.2606 - val_accuracy: 0.9583\n",
            "Epoch 940/1000\n",
            "96/96 [==============================] - 0s 85us/step - loss: 0.2473 - accuracy: 0.9792 - val_loss: 0.2591 - val_accuracy: 0.9583\n",
            "Epoch 941/1000\n",
            "96/96 [==============================] - 0s 104us/step - loss: 0.2461 - accuracy: 0.9792 - val_loss: 0.2600 - val_accuracy: 0.9583\n",
            "Epoch 942/1000\n",
            "96/96 [==============================] - 0s 94us/step - loss: 0.2456 - accuracy: 0.9792 - val_loss: 0.2602 - val_accuracy: 0.9583\n",
            "Epoch 943/1000\n",
            "96/96 [==============================] - 0s 126us/step - loss: 0.2466 - accuracy: 0.9792 - val_loss: 0.2603 - val_accuracy: 0.9583\n",
            "Epoch 944/1000\n",
            "96/96 [==============================] - 0s 149us/step - loss: 0.2466 - accuracy: 0.9792 - val_loss: 0.2607 - val_accuracy: 0.9583\n",
            "Epoch 945/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.2460 - accuracy: 0.9688 - val_loss: 0.2591 - val_accuracy: 0.9583\n",
            "Epoch 946/1000\n",
            "96/96 [==============================] - 0s 95us/step - loss: 0.2454 - accuracy: 0.9792 - val_loss: 0.2584 - val_accuracy: 0.9583\n",
            "Epoch 947/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.2448 - accuracy: 0.9792 - val_loss: 0.2591 - val_accuracy: 0.9583\n",
            "Epoch 948/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.2445 - accuracy: 0.9792 - val_loss: 0.2584 - val_accuracy: 0.9583\n",
            "Epoch 949/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.2454 - accuracy: 0.9792 - val_loss: 0.2582 - val_accuracy: 0.9583\n",
            "Epoch 950/1000\n",
            "96/96 [==============================] - 0s 125us/step - loss: 0.2453 - accuracy: 0.9792 - val_loss: 0.2577 - val_accuracy: 0.9583\n",
            "Epoch 951/1000\n",
            "96/96 [==============================] - 0s 131us/step - loss: 0.2456 - accuracy: 0.9792 - val_loss: 0.2589 - val_accuracy: 0.9583\n",
            "Epoch 952/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.2443 - accuracy: 0.9792 - val_loss: 0.2587 - val_accuracy: 0.9583\n",
            "Epoch 953/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.2448 - accuracy: 0.9792 - val_loss: 0.2571 - val_accuracy: 0.9583\n",
            "Epoch 954/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.2436 - accuracy: 0.9792 - val_loss: 0.2578 - val_accuracy: 0.9583\n",
            "Epoch 955/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.2448 - accuracy: 0.9792 - val_loss: 0.2590 - val_accuracy: 0.9583\n",
            "Epoch 956/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.2434 - accuracy: 0.9792 - val_loss: 0.2588 - val_accuracy: 0.9583\n",
            "Epoch 957/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.2446 - accuracy: 0.9792 - val_loss: 0.2588 - val_accuracy: 0.9583\n",
            "Epoch 958/1000\n",
            "96/96 [==============================] - 0s 84us/step - loss: 0.2426 - accuracy: 0.9792 - val_loss: 0.2577 - val_accuracy: 0.9583\n",
            "Epoch 959/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.2435 - accuracy: 0.9792 - val_loss: 0.2581 - val_accuracy: 0.9583\n",
            "Epoch 960/1000\n",
            "96/96 [==============================] - 0s 80us/step - loss: 0.2434 - accuracy: 0.9792 - val_loss: 0.2579 - val_accuracy: 0.9583\n",
            "Epoch 961/1000\n",
            "96/96 [==============================] - 0s 163us/step - loss: 0.2424 - accuracy: 0.9688 - val_loss: 0.2564 - val_accuracy: 0.9583\n",
            "Epoch 962/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.2436 - accuracy: 0.9792 - val_loss: 0.2565 - val_accuracy: 0.9583\n",
            "Epoch 963/1000\n",
            "96/96 [==============================] - 0s 84us/step - loss: 0.2421 - accuracy: 0.9792 - val_loss: 0.2557 - val_accuracy: 0.9583\n",
            "Epoch 964/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.2414 - accuracy: 0.9792 - val_loss: 0.2555 - val_accuracy: 0.9583\n",
            "Epoch 965/1000\n",
            "96/96 [==============================] - 0s 108us/step - loss: 0.2418 - accuracy: 0.9792 - val_loss: 0.2546 - val_accuracy: 0.9583\n",
            "Epoch 966/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.2411 - accuracy: 0.9792 - val_loss: 0.2545 - val_accuracy: 0.9583\n",
            "Epoch 967/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.2416 - accuracy: 0.9792 - val_loss: 0.2545 - val_accuracy: 0.9583\n",
            "Epoch 968/1000\n",
            "96/96 [==============================] - 0s 119us/step - loss: 0.2407 - accuracy: 0.9792 - val_loss: 0.2548 - val_accuracy: 0.9583\n",
            "Epoch 969/1000\n",
            "96/96 [==============================] - 0s 91us/step - loss: 0.2408 - accuracy: 0.9792 - val_loss: 0.2540 - val_accuracy: 0.9583\n",
            "Epoch 970/1000\n",
            "96/96 [==============================] - 0s 75us/step - loss: 0.2419 - accuracy: 0.9688 - val_loss: 0.2531 - val_accuracy: 0.9583\n",
            "Epoch 971/1000\n",
            "96/96 [==============================] - 0s 79us/step - loss: 0.2403 - accuracy: 0.9792 - val_loss: 0.2540 - val_accuracy: 0.9583\n",
            "Epoch 972/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.2404 - accuracy: 0.9792 - val_loss: 0.2541 - val_accuracy: 0.9583\n",
            "Epoch 973/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.2408 - accuracy: 0.9792 - val_loss: 0.2537 - val_accuracy: 0.9583\n",
            "Epoch 974/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.2398 - accuracy: 0.9792 - val_loss: 0.2541 - val_accuracy: 0.9583\n",
            "Epoch 975/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.2397 - accuracy: 0.9792 - val_loss: 0.2532 - val_accuracy: 0.9583\n",
            "Epoch 976/1000\n",
            "96/96 [==============================] - 0s 78us/step - loss: 0.2402 - accuracy: 0.9792 - val_loss: 0.2536 - val_accuracy: 0.9583\n",
            "Epoch 977/1000\n",
            "96/96 [==============================] - 0s 107us/step - loss: 0.2390 - accuracy: 0.9792 - val_loss: 0.2534 - val_accuracy: 0.9583\n",
            "Epoch 978/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.2398 - accuracy: 0.9792 - val_loss: 0.2541 - val_accuracy: 0.9583\n",
            "Epoch 979/1000\n",
            "96/96 [==============================] - 0s 92us/step - loss: 0.2398 - accuracy: 0.9688 - val_loss: 0.2529 - val_accuracy: 0.9583\n",
            "Epoch 980/1000\n",
            "96/96 [==============================] - 0s 81us/step - loss: 0.2386 - accuracy: 0.9792 - val_loss: 0.2531 - val_accuracy: 0.9583\n",
            "Epoch 981/1000\n",
            "96/96 [==============================] - 0s 86us/step - loss: 0.2390 - accuracy: 0.9792 - val_loss: 0.2536 - val_accuracy: 0.9583\n",
            "Epoch 982/1000\n",
            "96/96 [==============================] - 0s 83us/step - loss: 0.2383 - accuracy: 0.9792 - val_loss: 0.2532 - val_accuracy: 0.9583\n",
            "Epoch 983/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.2397 - accuracy: 0.9792 - val_loss: 0.2533 - val_accuracy: 0.9583\n",
            "Epoch 984/1000\n",
            "96/96 [==============================] - 0s 88us/step - loss: 0.2384 - accuracy: 0.9792 - val_loss: 0.2534 - val_accuracy: 0.9583\n",
            "Epoch 985/1000\n",
            "96/96 [==============================] - 0s 123us/step - loss: 0.2381 - accuracy: 0.9792 - val_loss: 0.2528 - val_accuracy: 0.9583\n",
            "Epoch 986/1000\n",
            "96/96 [==============================] - 0s 115us/step - loss: 0.2388 - accuracy: 0.9688 - val_loss: 0.2515 - val_accuracy: 0.9583\n",
            "Epoch 987/1000\n",
            "96/96 [==============================] - 0s 87us/step - loss: 0.2384 - accuracy: 0.9688 - val_loss: 0.2508 - val_accuracy: 0.9583\n",
            "Epoch 988/1000\n",
            "96/96 [==============================] - 0s 98us/step - loss: 0.2382 - accuracy: 0.9792 - val_loss: 0.2499 - val_accuracy: 0.9583\n",
            "Epoch 989/1000\n",
            "96/96 [==============================] - 0s 93us/step - loss: 0.2376 - accuracy: 0.9792 - val_loss: 0.2500 - val_accuracy: 0.9583\n",
            "Epoch 990/1000\n",
            "96/96 [==============================] - 0s 81us/step - loss: 0.2396 - accuracy: 0.9792 - val_loss: 0.2515 - val_accuracy: 0.9583\n",
            "Epoch 991/1000\n",
            "96/96 [==============================] - 0s 123us/step - loss: 0.2363 - accuracy: 0.9792 - val_loss: 0.2508 - val_accuracy: 0.9583\n",
            "Epoch 992/1000\n",
            "96/96 [==============================] - 0s 110us/step - loss: 0.2365 - accuracy: 0.9792 - val_loss: 0.2511 - val_accuracy: 0.9583\n",
            "Epoch 993/1000\n",
            "96/96 [==============================] - 0s 82us/step - loss: 0.2364 - accuracy: 0.9792 - val_loss: 0.2510 - val_accuracy: 0.9583\n",
            "Epoch 994/1000\n",
            "96/96 [==============================] - 0s 101us/step - loss: 0.2373 - accuracy: 0.9792 - val_loss: 0.2517 - val_accuracy: 0.9583\n",
            "Epoch 995/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.2358 - accuracy: 0.9792 - val_loss: 0.2506 - val_accuracy: 0.9583\n",
            "Epoch 996/1000\n",
            "96/96 [==============================] - 0s 105us/step - loss: 0.2365 - accuracy: 0.9896 - val_loss: 0.2495 - val_accuracy: 0.9583\n",
            "Epoch 997/1000\n",
            "96/96 [==============================] - 0s 97us/step - loss: 0.2360 - accuracy: 0.9896 - val_loss: 0.2485 - val_accuracy: 0.9583\n",
            "Epoch 998/1000\n",
            "96/96 [==============================] - 0s 109us/step - loss: 0.2352 - accuracy: 0.9792 - val_loss: 0.2488 - val_accuracy: 0.9583\n",
            "Epoch 999/1000\n",
            "96/96 [==============================] - 0s 103us/step - loss: 0.2351 - accuracy: 0.9792 - val_loss: 0.2489 - val_accuracy: 0.9583\n",
            "Epoch 1000/1000\n",
            "96/96 [==============================] - 0s 111us/step - loss: 0.2351 - accuracy: 0.9792 - val_loss: 0.2492 - val_accuracy: 0.9583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f2cc65a7160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ariHGSpl6IPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7e97d0c3-6eaf-405b-96cd-620a4efebc81"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(model.history.history[\"accuracy\"])\n",
        "plt.plot(model.history.history[\"val_accuracy\"])\n",
        "plt.title(\"Model Accuracy Iris Dataset\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend([\"Train\", \"Validation\"], loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umDEwoPn6Qlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6b4f08d9-002a-43d2-9899-b7198d2482be"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(model.history.history[\"loss\"])\n",
        "plt.plot(model.history.history[\"val_loss\"])\n",
        "plt.title(\"Model Loss Iris Dataset\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend([\"Train\", \"Validation\"], loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szXFybyH9UMJ",
        "colab_type": "text"
      },
      "source": [
        "Activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWVPPDAe9XkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array([\n",
        "    [9, 2, 5, 0, 0],\n",
        "    [7, 5, 0, 0, 0]       \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_ijzlBV9kn2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0cbb8b53-e78b-40b5-c716-4755950e96c3"
      },
      "source": [
        "s = 1/(1 + np.exp(-x))\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.99987661 0.88079708 0.99330715 0.5        0.5       ]\n",
            " [0.99908895 0.99330715 0.5        0.5        0.5       ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mirGCWAj9qKQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "b25026d8-ad24-463c-915b-10b345d2b9e3"
      },
      "source": [
        "x_exp = np.exp(x)\n",
        "x_sum = np.sum(x_exp, axis=1, keepdims=True)\n",
        "s = x_exp / x_sum\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n",
            "  1.21052389e-04]\n",
            " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
            "  8.01252314e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvAukxHhAGzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try out different activation functions and note the accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tQRltD0AQo4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "022e1f8d-37d4-4993-8ca5-0cd1ffaab18e"
      },
      "source": [
        "# Tanh H\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.linspace(-5, 5)\n",
        "x = np.tanh(x)\n",
        "plt.plot(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2cc6561c88>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpizBK2QD_Pa",
        "colab_type": "text"
      },
      "source": [
        "Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUsSPGV_EYYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "358d534c-0a8e-4c6e-b732-1afa12ec5f3a"
      },
      "source": [
        "from keras import models \n",
        "from keras.layers import Dense \n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "X_train = X_train.reshape((50000, 32*32*3))\n",
        "X_test = X_test.reshape((10000, 32*32*3))\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "# Normalize \n",
        "X_train = X_train.astype('float32')/255\n",
        "X_test =  X_test.astype('float32')/255\n",
        "\n",
        "# Cateogorical to one hot encoded \n",
        "\n",
        "y_test = to_categorical(y_test, 10)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "\n",
        "# Model Developing \n",
        "# A simple logistic regression\n",
        "model = Sequential()\n",
        "#creation of first hidden layer with 10 nodes and sigmoid activation \n",
        "# Z[1] = W[1]X + b\n",
        "# A[1] = sigmoid(Z[1])\n",
        "model.add(Dense(units=100, activation='relu', input_dim=3072, kernel_initializer=\"random_uniform\", bias_initializer=\"random_uniform\"))    # kernel_initializer=\"zeros\", bias_initializer=\"zeros\", \n",
        "model.add(Dense(units=10, activation='softmax', kernel_initializer=\"random_uniform\", bias_initializer=\"random_uniform\"))    # kernel_initializer=\"zeros\", bias_initializer=\"zeros\", \n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,y_train, epochs=20, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3072)\n",
            "(10000, 3072)\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "40000/40000 [==============================] - 6s 158us/step - loss: 2.0109 - accuracy: 0.2795 - val_loss: 1.8867 - val_accuracy: 0.3221\n",
            "Epoch 2/20\n",
            "40000/40000 [==============================] - 7s 178us/step - loss: 1.8167 - accuracy: 0.3553 - val_loss: 1.7929 - val_accuracy: 0.3662\n",
            "Epoch 3/20\n",
            "40000/40000 [==============================] - 5s 125us/step - loss: 1.7329 - accuracy: 0.3899 - val_loss: 1.7444 - val_accuracy: 0.3805\n",
            "Epoch 4/20\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.6750 - accuracy: 0.4099 - val_loss: 1.6726 - val_accuracy: 0.4139\n",
            "Epoch 5/20\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.6302 - accuracy: 0.4274 - val_loss: 1.6407 - val_accuracy: 0.4245\n",
            "Epoch 6/20\n",
            "40000/40000 [==============================] - 5s 131us/step - loss: 1.5983 - accuracy: 0.4381 - val_loss: 1.6125 - val_accuracy: 0.4349\n",
            "Epoch 7/20\n",
            "40000/40000 [==============================] - 5s 130us/step - loss: 1.5676 - accuracy: 0.4487 - val_loss: 1.6513 - val_accuracy: 0.4070\n",
            "Epoch 8/20\n",
            "40000/40000 [==============================] - 5s 129us/step - loss: 1.5419 - accuracy: 0.4585 - val_loss: 1.5876 - val_accuracy: 0.4412\n",
            "Epoch 9/20\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.5202 - accuracy: 0.4625 - val_loss: 1.5659 - val_accuracy: 0.4503\n",
            "Epoch 10/20\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.4993 - accuracy: 0.4713 - val_loss: 1.5638 - val_accuracy: 0.4538\n",
            "Epoch 11/20\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.4807 - accuracy: 0.4783 - val_loss: 1.5374 - val_accuracy: 0.4592\n",
            "Epoch 12/20\n",
            "40000/40000 [==============================] - 5s 129us/step - loss: 1.4642 - accuracy: 0.4868 - val_loss: 1.5317 - val_accuracy: 0.4611\n",
            "Epoch 13/20\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.4476 - accuracy: 0.4917 - val_loss: 1.5288 - val_accuracy: 0.4673\n",
            "Epoch 14/20\n",
            "40000/40000 [==============================] - 5s 129us/step - loss: 1.4350 - accuracy: 0.4936 - val_loss: 1.5030 - val_accuracy: 0.4792\n",
            "Epoch 15/20\n",
            "40000/40000 [==============================] - 5s 125us/step - loss: 1.4191 - accuracy: 0.5003 - val_loss: 1.4947 - val_accuracy: 0.4786\n",
            "Epoch 16/20\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.4064 - accuracy: 0.5049 - val_loss: 1.4946 - val_accuracy: 0.4756\n",
            "Epoch 17/20\n",
            "40000/40000 [==============================] - 5s 128us/step - loss: 1.3948 - accuracy: 0.5068 - val_loss: 1.5006 - val_accuracy: 0.4748\n",
            "Epoch 18/20\n",
            "40000/40000 [==============================] - 5s 129us/step - loss: 1.3833 - accuracy: 0.5142 - val_loss: 1.4962 - val_accuracy: 0.4719\n",
            "Epoch 19/20\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.3718 - accuracy: 0.5181 - val_loss: 1.5030 - val_accuracy: 0.4770\n",
            "Epoch 20/20\n",
            "40000/40000 [==============================] - 5s 127us/step - loss: 1.3595 - accuracy: 0.5219 - val_loss: 1.4703 - val_accuracy: 0.4889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f2ccf0fdd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro2fLw1oF3th",
        "colab_type": "text"
      },
      "source": [
        "We can set the kernel initializations to all \"ones\"\n",
        "\n",
        "We can set them to constant values as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRoh-Uj7GBYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting all ones \n",
        "initial = keras.initializers.Constant(value=1)\n",
        "model = Sequential()\n",
        "#creation of first hidden layer with 10 nodes and sigmoid activation \n",
        "# Z[1] = W[1]X + b\n",
        "# A[1] = sigmoid(Z[1])\n",
        "model.add(Dense(units=100, activation='relu', input_dim=3072, kernel_initializer=initial, bias_initializer=initial))    # kernel_initializer=\"zeros\", bias_initializer=\"zeros\", \n",
        "model.add(Dense(units=10, activation='softmax', kernel_initializer=initial, bias_initializer=initial))    # kernel_initializer=\"zeros\", bias_initializer=\"zeros\", \n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,y_train, epochs=20, validation_split=0.2)\n",
        "\n",
        "# setting to a constal value\n",
        "\n",
        "initial = keras.initializers.Constant(value=0.45)\n",
        "model = Sequential()\n",
        "#creation of first hidden layer with 10 nodes and sigmoid activation \n",
        "# Z[1] = W[1]X + b\n",
        "# A[1] = sigmoid(Z[1])\n",
        "model.add(Dense(units=100, activation='relu', input_dim=3072, kernel_initializer=initial, bias_initializer=initial))    # kernel_initializer=\"zeros\", bias_initializer=\"zeros\", \n",
        "model.add(Dense(units=10, activation='softmax', kernel_initializer=initial, bias_initializer=initial))    # kernel_initializer=\"zeros\", bias_initializer=\"zeros\", \n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,y_train, epochs=20, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Pick values from normal distribution\n",
        "\n",
        "initial = keras.initializers.RandomNormal(mean=0.0, stddev=0.25)\n",
        "model = Sequential()\n",
        "#creation of first hidden layer with 10 nodes and sigmoid activation \n",
        "# Z[1] = W[1]X + b\n",
        "# A[1] = sigmoid(Z[1])\n",
        "model.add(Dense(units=100, activation='relu', input_dim=3072, kernel_initializer=initial, bias_initializer=initial))    # kernel_initializer=\"zeros\", bias_initializer=\"zeros\", \n",
        "model.add(Dense(units=10, activation='softmax', kernel_initializer=initial, bias_initializer=initial))    # kernel_initializer=\"zeros\", bias_initializer=\"zeros\", \n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,y_train, epochs=20, validation_split=0.2)\n",
        "\n",
        "# Taking values from the random interval \n",
        "\n",
        "initial = keras.initializers.RandomUniform(minvalue=-0.05, maxvalue=0.05)\n",
        "model = Sequential()\n",
        "#creation of first hidden layer with 10 nodes and sigmoid activation \n",
        "# Z[1] = W[1]X + b\n",
        "# A[1] = sigmoid(Z[1])\n",
        "model.add(Dense(units=100, activation='relu', input_dim=3072, kernel_initializer=initial, bias_initializer=initial))    # kernel_initializer=\"zeros\", bias_initializer=\"zeros\", \n",
        "model.add(Dense(units=10, activation='softmax', kernel_initializer=initial, bias_initializer=initial))    # kernel_initializer=\"zeros\", bias_initializer=\"zeros\", \n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,y_train, epochs=20, validation_split=0.2)\n",
        "\n",
        "\n",
        "\n",
        "# Truncated Normal Distribution, any value beyond 99.5 or 2 std deviations \n",
        "\n",
        "\n",
        "initial = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.1)\n",
        "model = Sequential()\n",
        "#creation of first hidden layer with 10 nodes and sigmoid activation \n",
        "# Z[1] = W[1]X + b\n",
        "# A[1] = sigmoid(Z[1])\n",
        "model.add(Dense(units=100, activation='relu', input_dim=3072, kernel_initializer=initial, bias_initializer=initial))    # kernel_initializer=\"zeros\", bias_initializer=\"zeros\", \n",
        "model.add(Dense(units=10, activation='softmax', kernel_initializer=initial, bias_initializer=initial))    # kernel_initializer=\"zeros\", bias_initializer=\"zeros\", \n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,y_train, epochs=20, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}